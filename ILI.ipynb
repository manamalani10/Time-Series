{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ILI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ8BItJxAJkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13454300-7795-44b7-e308-9793dcfede00"
      },
      "source": [
        "!git clone https://github.com/LiamMaclean216/Pytorch-Transfomer.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Pytorch-Transfomer'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 37 (delta 9), reused 34 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (37/37), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnAKCzMnAZl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a14f8f-6289-4245-a3bc-9cf91a8d1c78"
      },
      "source": [
        "!python3  Transformer.ipynb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'Transformer.ipynb': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPgL9TkKNhFj"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmkqRLe4WjWl"
      },
      "source": [
        "\n",
        "def a_norm(Q, K):\n",
        "    m = torch.matmul(Q, K.transpose(2,1).float())\n",
        "    m /= torch.sqrt(torch.tensor(Q.shape[-1]).float())\n",
        "    \n",
        "    return torch.softmax(m , -1) ### shape after  this is [15,6,6]\n",
        "\n",
        "def attention(Q, K, V):\n",
        "    #Attention(Q, K, V) = norm(QK)V\n",
        "    a = a_norm(Q, K) #(batch_size, dim_attn, seq_length)\n",
        "    print(f\"a_norm {a.shape}\")\n",
        "    print(f\"attention +{torch.matmul(a,  V).shape}\")\n",
        "    \n",
        "    return  torch.matmul(a,  V) #(batch_size, seq_length, seq_length) ##shape is[15,6,10]\n",
        "\n",
        "class AttentionBlock(torch.nn.Module):\n",
        "    def __init__(self, dim_val, dim_attn):\n",
        "        super(AttentionBlock, self).__init__()\n",
        "        self.value = Value(dim_val, dim_val)\n",
        "        self.key = Key(dim_val, dim_attn)\n",
        "        self.query = Query(dim_val, dim_attn)\n",
        "    \n",
        "    def forward(self, x, kv = None):\n",
        "        if(kv is None):\n",
        "            #Attention with x connected to Q,K and V (For encoder)\n",
        "            return attention(self.query(x), self.key(x), self.value(x))\n",
        "        \n",
        "        #Attention with x as Q, external vector kv as K an V (For decoder)\n",
        "        return attention(self.query(x), self.key(kv), self.value(kv))\n",
        "    \n",
        "class MultiHeadAttentionBlock(torch.nn.Module):\n",
        "    def __init__(self, dim_val, dim_attn, n_heads):\n",
        "        super(MultiHeadAttentionBlock, self).__init__()\n",
        "        self.heads = []\n",
        "        for i in range(n_heads):\n",
        "            self.heads.append(AttentionBlock(dim_val, dim_attn))\n",
        "        \n",
        "        self.heads = nn.ModuleList(self.heads)\n",
        "        \n",
        "        self.fc = nn.Linear(n_heads * dim_val, dim_val, bias = False)\n",
        "                      \n",
        "        \n",
        "    def forward(self, x, kv = None):\n",
        "        a = []\n",
        "        for h in self.heads:\n",
        "            a.append(h(x, kv = kv))\n",
        "        #print(f\"shape before Multihead {a.shape}\")\n",
        "        a = torch.stack(a, dim = -1) #combine heads\n",
        "        a = a.flatten(start_dim = 2) #flatten all head outputs\n",
        "        print(f\"shape after Multihead+{a.shape}\")\n",
        "        x = self.fc(a)\n",
        "        print(f\"shape after  linear layer in Multihead+{x.shape}\")\n",
        "        \n",
        "        return x\n",
        "    \n",
        "class Value(torch.nn.Module):\n",
        "    def __init__(self, dim_input, dim_val):\n",
        "        super(Value, self).__init__()\n",
        "        self.dim_val = dim_val\n",
        "        \n",
        "        self.fc1 = nn.Linear(dim_input, dim_val, bias = False)\n",
        "        #self.fc2 = nn.Linear(5, dim_val)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        print(f\"Value-+{x.shape}\")\n",
        "        #x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class Key(torch.nn.Module):\n",
        "    def __init__(self, dim_input, dim_attn):\n",
        "        super(Key, self).__init__()\n",
        "        self.dim_attn = dim_attn\n",
        "        \n",
        "        self.fc1 = nn.Linear(dim_input, dim_attn, bias = False)\n",
        "        #self.fc2 = nn.Linear(5, dim_attn)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        print(f\"Key-{x.shape}\")\n",
        "        #x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class Query(torch.nn.Module):\n",
        "    def __init__(self, dim_input, dim_attn):\n",
        "        super(Query, self).__init__()\n",
        "        self.dim_attn = dim_attn\n",
        "        \n",
        "        self.fc1 = nn.Linear(dim_input, dim_attn, bias = False)\n",
        "        #self.fc2 = nn.Linear(5, dim_attn)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        print(f\"beforeQuery-{x.shape}\")\n",
        "        x = self.fc1(x)\n",
        "        print(f\"Query-{x.shape}\")\n",
        "        #print(x.shape)\n",
        "        #x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "# https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        \n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        \n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)                            ####  PE(pos,2i)=sin(pos100002i/dmodel), PE(pos,2i+1)=cos(pos100002i/dmodel) which is according to widely used formula similar thing we are doing here\n",
        "        \n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        \n",
        "        self.register_buffer('pe', pe)                  ####doubt- what is this???\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(1), :]. squeeze(1)\n",
        "        return x     \n",
        "    \n",
        "def get_data(batch_size, input_sequence_length, output_sequence_length):\n",
        "    i = input_sequence_length + output_sequence_length\n",
        "    t = torch.zeros(batch_size,1).uniform_(0,20 - i).int()\n",
        "    print(f\"t {t}\")\n",
        "    b = torch.arange(-10, -10 + i).unsqueeze(0).repeat(batch_size,1) + t\n",
        "    print(f\"b before {torch.arange(-10, -10 + i).unsqueeze(0).repeat(batch_size,1)}\")#### 1st part of above b\n",
        "    print(f\"b after {b}\")\n",
        "    s = torch.sigmoid(b.float())\n",
        "    print(f\"s {s.shape}\")\n",
        "    return s[:, :input_sequence_length].unsqueeze(-1), s[:,-output_sequence_length:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Setosd-tYQj0"
      },
      "source": [
        "\n",
        "#hyperparams\n",
        "enc_seq_len = 6\n",
        "dec_seq_len = 2\n",
        "output_sequence_length = 1\n",
        "\n",
        "dim_val = 10\n",
        "dim_attn = 5\n",
        "lr = 0.002\n",
        "epochs = 20\n",
        "\n",
        "n_heads = 3 \n",
        "\n",
        "n_decoder_layers = 3\n",
        "n_encoder_layers = 3\n",
        "\n",
        "batch_size = 15\n",
        "\n",
        "#init network and optimizer\n",
        "t = Transformer(dim_val, dim_attn, 1,dec_seq_len,  output_sequence_length, n_decoder_layers, n_encoder_layers, n_heads)\n",
        "optimizer = torch.optim.Adam(t.parameters(), lr=lr)\n",
        "\n",
        "#keep track of loss for graph\n",
        "losses = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4nWa5xmUcWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c22dffea-4438-4d84-846c-8eafff89672c"
      },
      "source": [
        " X, Y = get_data(batch_size, enc_seq_len, output_sequence_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t tensor([[0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [2],\n",
            "        [8],\n",
            "        [2],\n",
            "        [0],\n",
            "        [7],\n",
            "        [8],\n",
            "        [9],\n",
            "        [3],\n",
            "        [6],\n",
            "        [7],\n",
            "        [2],\n",
            "        [5]], dtype=torch.int32)\n",
            "b before tensor([[-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4]])\n",
            "b after tensor([[-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [ -8,  -7,  -6,  -5,  -4,  -3,  -2],\n",
            "        [ -2,  -1,   0,   1,   2,   3,   4],\n",
            "        [ -8,  -7,  -6,  -5,  -4,  -3,  -2],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [ -3,  -2,  -1,   0,   1,   2,   3],\n",
            "        [ -2,  -1,   0,   1,   2,   3,   4],\n",
            "        [ -1,   0,   1,   2,   3,   4,   5],\n",
            "        [ -7,  -6,  -5,  -4,  -3,  -2,  -1],\n",
            "        [ -4,  -3,  -2,  -1,   0,   1,   2],\n",
            "        [ -3,  -2,  -1,   0,   1,   2,   3],\n",
            "        [ -8,  -7,  -6,  -5,  -4,  -3,  -2],\n",
            "        [ -5,  -4,  -3,  -2,  -1,   0,   1]])\n",
            "s torch.Size([15, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vApxdG_UzMU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f44b7175-f03e-4633-eeb9-dc0a258b8552"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 6, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwlnxLZcWuM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efedc2ae-e8e9-4e29-d9c4-b5b9805c8abd"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofKq83VmOWaf"
      },
      "source": [
        "\n",
        "class EncoderLayer(torch.nn.Module):\n",
        "    def __init__(self, dim_val, dim_attn, n_heads = 1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.attn = MultiHeadAttentionBlock(dim_val, dim_attn , n_heads)\n",
        "        self.fc1 = nn.Linear(dim_val, dim_val)\n",
        "        self.fc2 = nn.Linear(dim_val, dim_val)\n",
        "        self.norm1 = nn.LayerNorm(dim_val)\n",
        "        self.norm2 = nn.LayerNorm(dim_val)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        print(\"---------------ENCODER STARTING-------------------\")\n",
        "        a = self.attn(x)\n",
        "        x = self.norm1(x + a)\n",
        "        \n",
        "        a = self.fc1(F.elu(self.fc2(x)))\n",
        "        x = self.norm2(x + a)\n",
        "        print(f\"End Of Encoder shape{x.shape}\")\n",
        "        \n",
        "        return x\n",
        "\n",
        "class DecoderLayer(torch.nn.Module):\n",
        "    def __init__(self, dim_val, dim_attn, n_heads = 1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.attn1 = MultiHeadAttentionBlock(dim_val, dim_attn, n_heads)\n",
        "        self.attn2 = MultiHeadAttentionBlock(dim_val, dim_attn, n_heads)\n",
        "        self.fc1 = nn.Linear(dim_val, dim_val)\n",
        "        self.fc2 = nn.Linear(dim_val, dim_val)\n",
        "        \n",
        "        self.norm1 = nn.LayerNorm(dim_val)\n",
        "        self.norm2 = nn.LayerNorm(dim_val)\n",
        "        self.norm3 = nn.LayerNorm(dim_val)\n",
        "        \n",
        "    def forward(self, x, enc):\n",
        "        print(\"---------------DECODER STARTING-------------------\")\n",
        "        print(f\"Start of decoder shape {x.shape}\") \n",
        "        a = self.attn1(x)\n",
        "        x = self.norm1(a + x)\n",
        "        print(f\"Mid decoder shaper after 1st Attention and Normalization{x.shape}\")\n",
        "        a = self.attn2(x, kv = enc)\n",
        "        x = self.norm2(a + x)\n",
        "        print(f\"After 2nd Attention Decoder(Mixed Attention)\")\n",
        "        \n",
        "        a = self.fc1(F.elu(self.fc2(x)))\n",
        "        \n",
        "        x = self.norm3(x + a)\n",
        "        print(f\"End of decoder shape {x.shape}\")\n",
        "        return x\n",
        "\n",
        "class Transformer(torch.nn.Module):\n",
        "    def __init__(self, dim_val, dim_attn, input_size, dec_seq_len, out_seq_len, n_decoder_layers = 1, n_encoder_layers = 1, n_heads = 1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.dec_seq_len = dec_seq_len\n",
        "        \n",
        "        #Initiate encoder and Decoder layers\n",
        "        self.encs = []\n",
        "        for i in range(n_encoder_layers):\n",
        "            self.encs.append(EncoderLayer(dim_val, dim_attn, n_heads))\n",
        "        \n",
        "        self.decs = []\n",
        "        for i in range(n_decoder_layers):\n",
        "            self.decs.append(DecoderLayer(dim_val, dim_attn, n_heads))\n",
        "        \n",
        "        self.pos = PositionalEncoding(dim_val)\n",
        "        \n",
        "        #Dense layers for managing network inputs and outputs\n",
        "        self.enc_input_fc = nn.Linear(input_size, dim_val)\n",
        "        self.dec_input_fc = nn.Linear(input_size, dim_val)\n",
        "        self.out_fc = nn.Linear(dec_seq_len * dim_val, out_seq_len)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        #encoder\n",
        "        print(f\"after positional encoding shape{self.pos(self.enc_input_fc(x))}\")\n",
        "        e = self.encs[0](self.pos(self.enc_input_fc(x)))\n",
        "        for enc in self.encs[1:]:\n",
        "            e = enc(e)               ##### this means we are using output of  before for next n-head encoder\n",
        "        \n",
        "        #decoder\n",
        "        d = self.decs[0](self.dec_input_fc(x[:,-self.dec_seq_len:]), e)\n",
        "        for dec in self.decs[1:]:\n",
        "            d = dec(d, e)\n",
        "            \n",
        "        #output\n",
        "        x = self.out_fc(d.flatten(start_dim=1))\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkl_0r3NNqgh"
      },
      "source": [
        "\n",
        "#hyperparams\n",
        "enc_seq_len = 6\n",
        "dec_seq_len = 2\n",
        "output_sequence_length = 1\n",
        "\n",
        "dim_val = 10\n",
        "dim_attn = 5\n",
        "lr = 0.002\n",
        "epochs = 20\n",
        "\n",
        "n_heads = 3 \n",
        "\n",
        "n_decoder_layers = 3\n",
        "n_encoder_layers = 3\n",
        "\n",
        "batch_size = 15\n",
        "\n",
        "#init network and optimizer\n",
        "t = Transformer(dim_val, dim_attn, 1,dec_seq_len,  output_sequence_length, n_decoder_layers, n_encoder_layers, n_heads)\n",
        "optimizer = torch.optim.Adam(t.parameters(), lr=lr)\n",
        "\n",
        "#keep track of loss for graph\n",
        "losses = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBx4b5upPY9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44fb758c-1f9e-4a18-ae64-f57db163a8ef"
      },
      "source": [
        " X, Y = get_data(batch_size, enc_seq_len, output_sequence_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t tensor([[ 6],\n",
            "        [ 6],\n",
            "        [ 4],\n",
            "        [ 0],\n",
            "        [ 0],\n",
            "        [ 4],\n",
            "        [ 4],\n",
            "        [10],\n",
            "        [ 6],\n",
            "        [ 3],\n",
            "        [ 4],\n",
            "        [ 9],\n",
            "        [ 2],\n",
            "        [ 9],\n",
            "        [ 6]], dtype=torch.int32)\n",
            "b before tensor([[-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4]])\n",
            "b after tensor([[ -4,  -3,  -2,  -1,   0,   1,   2],\n",
            "        [ -4,  -3,  -2,  -1,   0,   1,   2],\n",
            "        [ -6,  -5,  -4,  -3,  -2,  -1,   0],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [ -6,  -5,  -4,  -3,  -2,  -1,   0],\n",
            "        [ -6,  -5,  -4,  -3,  -2,  -1,   0],\n",
            "        [  0,   1,   2,   3,   4,   5,   6],\n",
            "        [ -4,  -3,  -2,  -1,   0,   1,   2],\n",
            "        [ -7,  -6,  -5,  -4,  -3,  -2,  -1],\n",
            "        [ -6,  -5,  -4,  -3,  -2,  -1,   0],\n",
            "        [ -1,   0,   1,   2,   3,   4,   5],\n",
            "        [ -8,  -7,  -6,  -5,  -4,  -3,  -2],\n",
            "        [ -1,   0,   1,   2,   3,   4,   5],\n",
            "        [ -4,  -3,  -2,  -1,   0,   1,   2]])\n",
            "s torch.Size([15, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeG2WugEOLo1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecf2f425-f326-4fee-8ce7-3f40b46a5ccd"
      },
      "source": [
        "X[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0180],\n",
              "        [0.0474],\n",
              "        [0.1192],\n",
              "        [0.2689],\n",
              "        [0.5000],\n",
              "        [0.7311]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBltiVO5OYoT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c590ea6-8a4d-4444-856f-9368e31d9bae"
      },
      "source": [
        "X[0,-2:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5000],\n",
              "        [0.7311]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HAx8YaOX5hZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a6d8fa2-359e-40a1-be84-3de78335b6ee"
      },
      "source": [
        "t(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "after positional encoding shapetensor([[[ 9.0404e-01,  3.8186e-01, -4.9540e-01,  4.6904e-01,  8.1300e-01,\n",
            "           2.2632e-01,  1.0850e-01,  8.1098e-01,  8.0608e-01,  3.9217e-01],\n",
            "         [ 1.7446e+00, -1.0685e-01, -3.4407e-01,  4.7038e-01,  8.5251e-01,\n",
            "           2.3119e-01,  1.3936e-01,  7.8288e-01,  7.8224e-01,  3.6277e-01],\n",
            "         [ 1.8101e+00, -1.1340e+00, -2.0605e-01,  4.6693e-01,  9.1271e-01,\n",
            "           2.4288e-01,  2.0887e-01,  7.1437e-01,  7.2321e-01,  2.9111e-01],\n",
            "         [ 1.0371e+00, -1.8555e+00, -9.3062e-02,  4.7640e-01,  1.0110e+00,\n",
            "           2.6766e-01,  3.4957e-01,  5.7144e-01,  5.9938e-01,  1.4161e-01],\n",
            "         [ 1.3176e-01, -1.7469e+00, -9.5060e-03,  5.0192e-01,  1.1490e+00,\n",
            "           3.0613e-01,  5.6450e-01,  3.5090e-01,  4.0795e-01, -8.9078e-02],\n",
            "         [-7.7780e-02, -1.0373e+00,  5.9202e-02,  5.0724e-01,  1.2869e+00,\n",
            "           3.4397e-01,  7.7944e-01,  1.3035e-01,  2.1652e-01, -3.1977e-01]],\n",
            "\n",
            "        [[ 9.0404e-01,  3.8186e-01, -4.9540e-01,  4.6904e-01,  8.1300e-01,\n",
            "           2.2632e-01,  1.0850e-01,  8.1098e-01,  8.0608e-01,  3.9217e-01],\n",
            "         [ 1.7446e+00, -1.0685e-01, -3.4407e-01,  4.7038e-01,  8.5251e-01,\n",
            "           2.3119e-01,  1.3936e-01,  7.8288e-01,  7.8224e-01,  3.6277e-01],\n",
            "         [ 1.8101e+00, -1.1340e+00, -2.0605e-01,  4.6693e-01,  9.1271e-01,\n",
            "           2.4288e-01,  2.0887e-01,  7.1437e-01,  7.2321e-01,  2.9111e-01],\n",
            "         [ 1.0371e+00, -1.8555e+00, -9.3062e-02,  4.7640e-01,  1.0110e+00,\n",
            "           2.6766e-01,  3.4957e-01,  5.7144e-01,  5.9938e-01,  1.4161e-01],\n",
            "         [ 1.3176e-01, -1.7469e+00, -9.5060e-03,  5.0192e-01,  1.1490e+00,\n",
            "           3.0613e-01,  5.6450e-01,  3.5090e-01,  4.0795e-01, -8.9078e-02],\n",
            "         [-7.7780e-02, -1.0373e+00,  5.9202e-02,  5.0724e-01,  1.2869e+00,\n",
            "           3.4397e-01,  7.7944e-01,  1.3035e-01,  2.1652e-01, -3.1977e-01]],\n",
            "\n",
            "        [[ 9.0453e-01,  3.9716e-01, -4.9197e-01,  4.6173e-01,  8.0541e-01,\n",
            "           2.2359e-01,  9.4339e-02,  8.2579e-01,  8.1897e-01,  4.0765e-01],\n",
            "         [ 1.7459e+00, -6.6702e-02, -3.3507e-01,  4.5119e-01,  8.3259e-01,\n",
            "           2.2402e-01,  1.0217e-01,  8.2175e-01,  8.1610e-01,  4.0344e-01],\n",
            "         [ 1.8133e+00, -1.0343e+00, -1.8370e-01,  4.1922e-01,  8.6321e-01,\n",
            "           2.2506e-01,  1.1646e-01,  8.1095e-01,  8.0734e-01,  3.9217e-01],\n",
            "         [ 1.0442e+00, -1.6371e+00, -4.4142e-02,  3.7200e-01,  9.0268e-01,\n",
            "           2.2867e-01,  1.4732e-01,  7.8282e-01,  7.8350e-01,  3.6277e-01],\n",
            "         [ 1.4398e-01, -1.3715e+00,  7.4590e-02,  3.2244e-01,  9.6280e-01,\n",
            "           2.3910e-01,  2.1684e-01,  7.1427e-01,  7.2447e-01,  2.9111e-01],\n",
            "         [-6.2945e-02, -5.8183e-01,  1.6126e-01,  2.8943e-01,  1.0610e+00,\n",
            "           2.6262e-01,  3.5753e-01,  5.7132e-01,  6.0064e-01,  1.4161e-01]],\n",
            "\n",
            "        [[ 9.0461e-01,  3.9955e-01, -4.9143e-01,  4.6059e-01,  8.0422e-01,\n",
            "           2.2317e-01,  9.2123e-02,  8.2810e-01,  8.2099e-01,  4.1008e-01],\n",
            "         [ 1.7461e+00, -6.0227e-02, -3.3362e-01,  4.4809e-01,  8.2938e-01,\n",
            "           2.2286e-01,  9.6175e-02,  8.2802e-01,  8.2156e-01,  4.1000e-01],\n",
            "         [ 1.8139e+00, -1.0169e+00, -1.7980e-01,  4.1090e-01,  8.5458e-01,\n",
            "           2.2196e-01,  1.0035e-01,  8.2780e-01,  8.2201e-01,  4.0979e-01],\n",
            "         [ 1.0457e+00, -1.5913e+00, -3.3870e-02,  3.5007e-01,  8.7993e-01,\n",
            "           2.2048e-01,  1.0486e-01,  8.2721e-01,  8.2217e-01,  4.0921e-01],\n",
            "         [ 1.4773e-01, -1.2565e+00,  1.0037e-01,  2.6742e-01,  9.0572e-01,\n",
            "           2.1855e-01,  1.1026e-01,  8.2566e-01,  8.2150e-01,  4.0765e-01],\n",
            "         [-5.4526e-02, -3.2334e-01,  2.1917e-01,  1.6582e-01,  9.3274e-01,\n",
            "           2.1646e-01,  1.1810e-01,  8.2156e-01,  8.1862e-01,  4.0344e-01]],\n",
            "\n",
            "        [[ 9.0461e-01,  3.9955e-01, -4.9143e-01,  4.6059e-01,  8.0422e-01,\n",
            "           2.2317e-01,  9.2123e-02,  8.2810e-01,  8.2099e-01,  4.1008e-01],\n",
            "         [ 1.7461e+00, -6.0227e-02, -3.3362e-01,  4.4809e-01,  8.2938e-01,\n",
            "           2.2286e-01,  9.6175e-02,  8.2802e-01,  8.2156e-01,  4.1000e-01],\n",
            "         [ 1.8139e+00, -1.0169e+00, -1.7980e-01,  4.1090e-01,  8.5458e-01,\n",
            "           2.2196e-01,  1.0035e-01,  8.2780e-01,  8.2201e-01,  4.0979e-01],\n",
            "         [ 1.0457e+00, -1.5913e+00, -3.3870e-02,  3.5007e-01,  8.7993e-01,\n",
            "           2.2048e-01,  1.0486e-01,  8.2721e-01,  8.2217e-01,  4.0921e-01],\n",
            "         [ 1.4773e-01, -1.2565e+00,  1.0037e-01,  2.6742e-01,  9.0572e-01,\n",
            "           2.1855e-01,  1.1026e-01,  8.2566e-01,  8.2150e-01,  4.0765e-01],\n",
            "         [-5.4526e-02, -3.2334e-01,  2.1917e-01,  1.6582e-01,  9.3274e-01,\n",
            "           2.1646e-01,  1.1810e-01,  8.2156e-01,  8.1862e-01,  4.0344e-01]],\n",
            "\n",
            "        [[ 9.0453e-01,  3.9716e-01, -4.9197e-01,  4.6173e-01,  8.0541e-01,\n",
            "           2.2359e-01,  9.4339e-02,  8.2579e-01,  8.1897e-01,  4.0765e-01],\n",
            "         [ 1.7459e+00, -6.6702e-02, -3.3507e-01,  4.5119e-01,  8.3259e-01,\n",
            "           2.2402e-01,  1.0217e-01,  8.2175e-01,  8.1610e-01,  4.0344e-01],\n",
            "         [ 1.8133e+00, -1.0343e+00, -1.8370e-01,  4.1922e-01,  8.6321e-01,\n",
            "           2.2506e-01,  1.1646e-01,  8.1095e-01,  8.0734e-01,  3.9217e-01],\n",
            "         [ 1.0442e+00, -1.6371e+00, -4.4142e-02,  3.7200e-01,  9.0268e-01,\n",
            "           2.2867e-01,  1.4732e-01,  7.8282e-01,  7.8350e-01,  3.6277e-01],\n",
            "         [ 1.4398e-01, -1.3715e+00,  7.4590e-02,  3.2244e-01,  9.6280e-01,\n",
            "           2.3910e-01,  2.1684e-01,  7.1427e-01,  7.2447e-01,  2.9111e-01],\n",
            "         [-6.2945e-02, -5.8183e-01,  1.6126e-01,  2.8943e-01,  1.0610e+00,\n",
            "           2.6262e-01,  3.5753e-01,  5.7132e-01,  6.0064e-01,  1.4161e-01]],\n",
            "\n",
            "        [[ 9.0453e-01,  3.9716e-01, -4.9197e-01,  4.6173e-01,  8.0541e-01,\n",
            "           2.2359e-01,  9.4339e-02,  8.2579e-01,  8.1897e-01,  4.0765e-01],\n",
            "         [ 1.7459e+00, -6.6702e-02, -3.3507e-01,  4.5119e-01,  8.3259e-01,\n",
            "           2.2402e-01,  1.0217e-01,  8.2175e-01,  8.1610e-01,  4.0344e-01],\n",
            "         [ 1.8133e+00, -1.0343e+00, -1.8370e-01,  4.1922e-01,  8.6321e-01,\n",
            "           2.2506e-01,  1.1646e-01,  8.1095e-01,  8.0734e-01,  3.9217e-01],\n",
            "         [ 1.0442e+00, -1.6371e+00, -4.4142e-02,  3.7200e-01,  9.0268e-01,\n",
            "           2.2867e-01,  1.4732e-01,  7.8282e-01,  7.8350e-01,  3.6277e-01],\n",
            "         [ 1.4398e-01, -1.3715e+00,  7.4590e-02,  3.2244e-01,  9.6280e-01,\n",
            "           2.3910e-01,  2.1684e-01,  7.1427e-01,  7.2447e-01,  2.9111e-01],\n",
            "         [-6.2945e-02, -5.8183e-01,  1.6126e-01,  2.8943e-01,  1.0610e+00,\n",
            "           2.6262e-01,  3.5753e-01,  5.7132e-01,  6.0064e-01,  1.4161e-01]],\n",
            "\n",
            "        [[ 8.8856e-01, -9.3234e-02, -6.0184e-01,  6.9623e-01,  1.0487e+00,\n",
            "           3.1118e-01,  5.4858e-01,  3.5103e-01,  4.0543e-01, -8.9075e-02],\n",
            "         [ 1.7226e+00, -7.8068e-01, -4.9504e-01,  7.9260e-01,  1.1868e+00,\n",
            "           3.5153e-01,  7.6351e-01,  1.3054e-01,  2.1400e-01, -3.1976e-01],\n",
            "         [ 1.7856e+00, -1.8847e+00, -3.7424e-01,  8.2589e-01,  1.2851e+00,\n",
            "           3.7695e-01,  9.0420e-01, -1.2369e-02,  9.0166e-02, -4.6926e-01],\n",
            "         [ 1.0152e+00, -2.5293e+00, -2.4404e-01,  7.9862e-01,  1.3453e+00,\n",
            "           3.8801e-01,  9.7372e-01, -8.0901e-02,  3.1136e-02, -5.4092e-01],\n",
            "         [ 1.1629e-01, -2.2220e+00, -1.1595e-01,  7.2910e-01,  1.3847e+00,\n",
            "           3.9098e-01,  1.0046e+00, -1.0905e-01,  7.2961e-03, -5.7032e-01],\n",
            "         [-8.6198e-02, -1.2958e+00,  1.2867e-03,  6.3084e-01,  1.4152e+00,\n",
            "           3.9014e-01,  1.0189e+00, -1.1990e-01, -1.4600e-03, -5.8160e-01]],\n",
            "\n",
            "        [[ 9.0404e-01,  3.8186e-01, -4.9540e-01,  4.6904e-01,  8.1300e-01,\n",
            "           2.2632e-01,  1.0850e-01,  8.1098e-01,  8.0608e-01,  3.9217e-01],\n",
            "         [ 1.7446e+00, -1.0685e-01, -3.4407e-01,  4.7038e-01,  8.5251e-01,\n",
            "           2.3119e-01,  1.3936e-01,  7.8288e-01,  7.8224e-01,  3.6277e-01],\n",
            "         [ 1.8101e+00, -1.1340e+00, -2.0605e-01,  4.6693e-01,  9.1271e-01,\n",
            "           2.4288e-01,  2.0887e-01,  7.1437e-01,  7.2321e-01,  2.9111e-01],\n",
            "         [ 1.0371e+00, -1.8555e+00, -9.3062e-02,  4.7640e-01,  1.0110e+00,\n",
            "           2.6766e-01,  3.4957e-01,  5.7144e-01,  5.9938e-01,  1.4161e-01],\n",
            "         [ 1.3176e-01, -1.7469e+00, -9.5060e-03,  5.0192e-01,  1.1490e+00,\n",
            "           3.0613e-01,  5.6450e-01,  3.5090e-01,  4.0795e-01, -8.9078e-02],\n",
            "         [-7.7780e-02, -1.0373e+00,  5.9202e-02,  5.0724e-01,  1.2869e+00,\n",
            "           3.4397e-01,  7.7944e-01,  1.3035e-01,  2.1652e-01, -3.1977e-01]],\n",
            "\n",
            "        [[ 9.0458e-01,  3.9869e-01, -4.9162e-01,  4.6099e-01,  8.0465e-01,\n",
            "           2.2332e-01,  9.2913e-02,  8.2728e-01,  8.2027e-01,  4.0921e-01],\n",
            "         [ 1.7460e+00, -6.2542e-02, -3.3414e-01,  4.4920e-01,  8.3053e-01,\n",
            "           2.2328e-01,  9.8320e-02,  8.2578e-01,  8.1961e-01,  4.0765e-01],\n",
            "         [ 1.8137e+00, -1.0232e+00, -1.8120e-01,  4.1390e-01,  8.5769e-01,\n",
            "           2.2307e-01,  1.0615e-01,  8.2173e-01,  8.1673e-01,  4.0344e-01],\n",
            "         [ 1.0452e+00, -1.6081e+00, -3.7640e-02,  3.5812e-01,  8.8828e-01,\n",
            "           2.2349e-01,  1.2045e-01,  8.1091e-01,  8.0797e-01,  3.9216e-01],\n",
            "         [ 1.4629e-01, -1.3008e+00,  9.0441e-02,  2.8861e-01,  9.2770e-01,\n",
            "           2.2646e-01,  1.5130e-01,  7.8277e-01,  7.8413e-01,  3.6277e-01],\n",
            "         [-5.8138e-02, -4.3424e-01,  1.9433e-01,  2.1885e-01,  9.8775e-01,\n",
            "           2.3627e-01,  2.2082e-01,  7.1420e-01,  7.2510e-01,  2.9111e-01]],\n",
            "\n",
            "        [[ 9.0453e-01,  3.9716e-01, -4.9197e-01,  4.6173e-01,  8.0541e-01,\n",
            "           2.2359e-01,  9.4339e-02,  8.2579e-01,  8.1897e-01,  4.0765e-01],\n",
            "         [ 1.7459e+00, -6.6702e-02, -3.3507e-01,  4.5119e-01,  8.3259e-01,\n",
            "           2.2402e-01,  1.0217e-01,  8.2175e-01,  8.1610e-01,  4.0344e-01],\n",
            "         [ 1.8133e+00, -1.0343e+00, -1.8370e-01,  4.1922e-01,  8.6321e-01,\n",
            "           2.2506e-01,  1.1646e-01,  8.1095e-01,  8.0734e-01,  3.9217e-01],\n",
            "         [ 1.0442e+00, -1.6371e+00, -4.4142e-02,  3.7200e-01,  9.0268e-01,\n",
            "           2.2867e-01,  1.4732e-01,  7.8282e-01,  7.8350e-01,  3.6277e-01],\n",
            "         [ 1.4398e-01, -1.3715e+00,  7.4590e-02,  3.2244e-01,  9.6280e-01,\n",
            "           2.3910e-01,  2.1684e-01,  7.1427e-01,  7.2447e-01,  2.9111e-01],\n",
            "         [-6.2945e-02, -5.8183e-01,  1.6126e-01,  2.8943e-01,  1.0610e+00,\n",
            "           2.6262e-01,  3.5753e-01,  5.7132e-01,  6.0064e-01,  1.4161e-01]],\n",
            "\n",
            "        [[ 8.9598e-01,  1.3451e-01, -5.5082e-01,  5.8732e-01,  9.3571e-01,\n",
            "           2.7050e-01,  3.3762e-01,  5.7152e-01,  5.9748e-01,  1.4161e-01],\n",
            "         [ 1.7300e+00, -5.5293e-01, -4.4402e-01,  6.8369e-01,  1.0738e+00,\n",
            "           3.1086e-01,  5.5256e-01,  3.5102e-01,  4.0606e-01, -8.9075e-02],\n",
            "         [ 1.7904e+00, -1.7371e+00, -3.4117e-01,  7.5531e-01,  1.2119e+00,\n",
            "           3.5059e-01,  7.6749e-01,  1.3052e-01,  2.1463e-01, -3.1976e-01],\n",
            "         [ 1.0175e+00, -2.4586e+00, -2.2818e-01,  7.6479e-01,  1.3102e+00,\n",
            "           3.7537e-01,  9.0819e-01, -1.2409e-02,  9.0797e-02, -4.6926e-01],\n",
            "         [ 1.1723e-01, -2.1930e+00, -1.0945e-01,  7.1523e-01,  1.3703e+00,\n",
            "           3.8580e-01,  9.7770e-01, -8.0957e-02,  3.1767e-02, -5.4093e-01],\n",
            "         [-8.5836e-02, -1.2847e+00,  3.7808e-03,  6.2552e-01,  1.4097e+00,\n",
            "           3.8815e-01,  1.0086e+00, -1.0912e-01,  7.9271e-03, -5.7032e-01]],\n",
            "\n",
            "        [[ 9.0460e-01,  3.9926e-01, -4.9150e-01,  4.6072e-01,  8.0436e-01,\n",
            "           2.2322e-01,  9.2387e-02,  8.2783e-01,  8.2075e-01,  4.0979e-01],\n",
            "         [ 1.7461e+00, -6.1003e-02, -3.3380e-01,  4.4846e-01,  8.2976e-01,\n",
            "           2.2300e-01,  9.6894e-02,  8.2727e-01,  8.2090e-01,  4.0921e-01],\n",
            "         [ 1.8138e+00, -1.0190e+00, -1.8027e-01,  4.1191e-01,  8.5563e-01,\n",
            "           2.2233e-01,  1.0230e-01,  8.2576e-01,  8.2024e-01,  4.0765e-01],\n",
            "         [ 1.0455e+00, -1.5970e+00, -3.5146e-02,  3.5280e-01,  8.8276e-01,\n",
            "           2.2150e-01,  1.1013e-01,  8.2169e-01,  8.1736e-01,  4.0344e-01],\n",
            "         [ 1.4723e-01, -1.2718e+00,  9.6943e-02,  2.7473e-01,  9.1330e-01,\n",
            "           2.2128e-01,  1.2443e-01,  8.1086e-01,  8.0860e-01,  3.9216e-01],\n",
            "         [-5.5834e-02, -3.6349e-01,  2.1018e-01,  1.8502e-01,  9.5266e-01,\n",
            "           2.2363e-01,  1.5528e-01,  7.8269e-01,  7.8476e-01,  3.6277e-01]],\n",
            "\n",
            "        [[ 8.9598e-01,  1.3451e-01, -5.5082e-01,  5.8732e-01,  9.3571e-01,\n",
            "           2.7050e-01,  3.3762e-01,  5.7152e-01,  5.9748e-01,  1.4161e-01],\n",
            "         [ 1.7300e+00, -5.5293e-01, -4.4402e-01,  6.8369e-01,  1.0738e+00,\n",
            "           3.1086e-01,  5.5256e-01,  3.5102e-01,  4.0606e-01, -8.9075e-02],\n",
            "         [ 1.7904e+00, -1.7371e+00, -3.4117e-01,  7.5531e-01,  1.2119e+00,\n",
            "           3.5059e-01,  7.6749e-01,  1.3052e-01,  2.1463e-01, -3.1976e-01],\n",
            "         [ 1.0175e+00, -2.4586e+00, -2.2818e-01,  7.6479e-01,  1.3102e+00,\n",
            "           3.7537e-01,  9.0819e-01, -1.2409e-02,  9.0797e-02, -4.6926e-01],\n",
            "         [ 1.1723e-01, -2.1930e+00, -1.0945e-01,  7.1523e-01,  1.3703e+00,\n",
            "           3.8580e-01,  9.7770e-01, -8.0957e-02,  3.1767e-02, -5.4093e-01],\n",
            "         [-8.5836e-02, -1.2847e+00,  3.7808e-03,  6.2552e-01,  1.4097e+00,\n",
            "           3.8815e-01,  1.0086e+00, -1.0912e-01,  7.9271e-03, -5.7032e-01]],\n",
            "\n",
            "        [[ 9.0404e-01,  3.8186e-01, -4.9540e-01,  4.6904e-01,  8.1300e-01,\n",
            "           2.2632e-01,  1.0850e-01,  8.1098e-01,  8.0608e-01,  3.9217e-01],\n",
            "         [ 1.7446e+00, -1.0685e-01, -3.4407e-01,  4.7038e-01,  8.5251e-01,\n",
            "           2.3119e-01,  1.3936e-01,  7.8288e-01,  7.8224e-01,  3.6277e-01],\n",
            "         [ 1.8101e+00, -1.1340e+00, -2.0605e-01,  4.6693e-01,  9.1271e-01,\n",
            "           2.4288e-01,  2.0887e-01,  7.1437e-01,  7.2321e-01,  2.9111e-01],\n",
            "         [ 1.0371e+00, -1.8555e+00, -9.3062e-02,  4.7640e-01,  1.0110e+00,\n",
            "           2.6766e-01,  3.4957e-01,  5.7144e-01,  5.9938e-01,  1.4161e-01],\n",
            "         [ 1.3176e-01, -1.7469e+00, -9.5060e-03,  5.0192e-01,  1.1490e+00,\n",
            "           3.0613e-01,  5.6450e-01,  3.5090e-01,  4.0795e-01, -8.9078e-02],\n",
            "         [-7.7780e-02, -1.0373e+00,  5.9202e-02,  5.0724e-01,  1.2869e+00,\n",
            "           3.4397e-01,  7.7944e-01,  1.3035e-01,  2.1652e-01, -3.1977e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1677],\n",
              "        [-0.1677],\n",
              "        [-0.3439],\n",
              "        [-0.2986],\n",
              "        [-0.2986],\n",
              "        [-0.3439],\n",
              "        [-0.3439],\n",
              "        [ 0.0256],\n",
              "        [-0.1677],\n",
              "        [-0.3221],\n",
              "        [-0.3439],\n",
              "        [ 0.0190],\n",
              "        [-0.3074],\n",
              "        [ 0.0190],\n",
              "        [-0.1677]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3rn3sZlPh0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9b6b984-a222-4d15-ba31-a60392c2b608"
      },
      "source": [
        "Y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8808],\n",
              "        [0.8808],\n",
              "        [0.5000],\n",
              "        [0.0180],\n",
              "        [0.0180],\n",
              "        [0.5000],\n",
              "        [0.5000],\n",
              "        [0.9975],\n",
              "        [0.8808],\n",
              "        [0.2689],\n",
              "        [0.5000],\n",
              "        [0.9933],\n",
              "        [0.1192],\n",
              "        [0.9933],\n",
              "        [0.8808]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcKkVu0pPuVS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YJlyuOUPbjx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8ba5a561-3cde-46e9-f6ac-b9f2907eff50"
      },
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ion()\n",
        "\n",
        "fig.show()\n",
        "fig.canvas.draw()\n",
        "\n",
        "    \n",
        "for e in range(epochs):\n",
        "\n",
        "\n",
        "    out = []\n",
        "    \n",
        "    for b in range(-10- enc_seq_len, 10 - enc_seq_len):\n",
        "        optimizer.zero_grad()\n",
        "        X, Y = get_data(batch_size, enc_seq_len, output_sequence_length)\n",
        "        #print(X)\n",
        "        \n",
        "        #Forward pass and calculate loss\n",
        "        print(\"---------\")\n",
        "        net_out = t(X)\n",
        "        #print(net_out.shape,Y.shape)\n",
        "        loss = torch.mean((net_out - Y) ** 2)\n",
        "\n",
        "        #backwards pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #Track losses and draw rgaph\n",
        "        out.append([net_out.detach().numpy(), Y])\n",
        "        losses.append(loss)\n",
        "\n",
        "        ax.clear()\n",
        "        ax.plot(losses)\n",
        "        ax.set_title(\"Mean Squared Error\")\n",
        "        fig.canvas.draw()\n",
        "    print(f\"{loss}@{e}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "t tensor([[ 9],\n",
            "        [ 8],\n",
            "        [ 8],\n",
            "        [11],\n",
            "        [ 3],\n",
            "        [ 0],\n",
            "        [ 2],\n",
            "        [ 5],\n",
            "        [ 1],\n",
            "        [ 9],\n",
            "        [10],\n",
            "        [ 3],\n",
            "        [ 4],\n",
            "        [ 7],\n",
            "        [11]], dtype=torch.int32)\n",
            "b before tensor([[-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4]])\n",
            "b after tensor([[ -1,   0,   1,   2,   3,   4,   5],\n",
            "        [ -2,  -1,   0,   1,   2,   3,   4],\n",
            "        [ -2,  -1,   0,   1,   2,   3,   4],\n",
            "        [  1,   2,   3,   4,   5,   6,   7],\n",
            "        [ -7,  -6,  -5,  -4,  -3,  -2,  -1],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [ -8,  -7,  -6,  -5,  -4,  -3,  -2],\n",
            "        [ -5,  -4,  -3,  -2,  -1,   0,   1],\n",
            "        [ -9,  -8,  -7,  -6,  -5,  -4,  -3],\n",
            "        [ -1,   0,   1,   2,   3,   4,   5],\n",
            "        [  0,   1,   2,   3,   4,   5,   6],\n",
            "        [ -7,  -6,  -5,  -4,  -3,  -2,  -1],\n",
            "        [ -6,  -5,  -4,  -3,  -2,  -1,   0],\n",
            "        [ -3,  -2,  -1,   0,   1,   2,   3],\n",
            "        [  1,   2,   3,   4,   5,   6,   7]])\n",
            "s torch.Size([15, 7])\n",
            "---------\n",
            "after positional encoding shapetensor([[[ 9.1828e-01,  4.3790e-01, -5.2447e-01,  7.2537e-01,  1.0389e+00,\n",
            "           2.0968e-01,  2.6273e-01,  3.9118e-01,  6.4673e-01,  3.4957e-02],\n",
            "         [ 1.7735e+00, -2.1612e-01, -4.0120e-01,  8.3899e-01,  1.2154e+00,\n",
            "           1.9100e-01,  4.7833e-01,  1.5075e-01,  4.6290e-01, -2.2096e-01],\n",
            "         [ 1.8550e+00, -1.3669e+00, -2.8188e-01,  9.2786e-01,  1.3919e+00,\n",
            "           1.7170e-01,  6.9394e-01, -8.9697e-02,  2.7907e-01, -4.7688e-01],\n",
            "         [ 1.0957e+00, -2.0667e+00, -1.5822e-01,  9.4851e-01,  1.5150e+00,\n",
            "           1.5822e-01,  8.3507e-01, -2.4554e-01,  1.6016e-01, -6.4273e-01],\n",
            "         [ 2.0209e-01, -1.7907e+00, -3.4372e-02,  9.0431e-01,  1.5871e+00,\n",
            "           1.5031e-01,  9.0479e-01, -3.2028e-01,  1.0349e-01, -7.2224e-01],\n",
            "         [ 1.7152e-03, -8.7814e-01,  8.0960e-02,  8.1680e-01,  1.6313e+00,\n",
            "           1.4514e-01,  9.3573e-01, -3.5099e-01,  8.0622e-02, -7.5484e-01]],\n",
            "\n",
            "        [[ 9.0939e-01,  5.6384e-01, -5.0207e-01,  6.4361e-01,  9.4076e-01,\n",
            "           2.2158e-01,  1.2558e-01,  5.4698e-01,  7.6626e-01,  2.0081e-01],\n",
            "         [ 1.7598e+00, -2.1793e-02, -3.6664e-01,  7.1284e-01,  1.0640e+00,\n",
            "           2.0936e-01,  2.6671e-01,  3.9117e-01,  6.4736e-01,  3.4957e-02],\n",
            "         [ 1.8413e+00, -1.1726e+00, -2.4733e-01,  8.0170e-01,  1.2405e+00,\n",
            "           1.9006e-01,  4.8231e-01,  1.5072e-01,  4.6353e-01, -2.2096e-01],\n",
            "         [ 1.0869e+00, -1.9407e+00, -1.3583e-01,  8.6676e-01,  1.4169e+00,\n",
            "           1.7012e-01,  6.9792e-01, -8.9736e-02,  2.7970e-01, -4.7688e-01],\n",
            "         [ 1.9782e-01, -1.7303e+00, -2.3637e-02,  8.6512e-01,  1.5401e+00,\n",
            "           1.5601e-01,  8.3905e-01, -2.4560e-01,  1.6079e-01, -6.4274e-01],\n",
            "         [-3.3498e-05, -8.5338e-01,  8.5363e-02,  8.0073e-01,  1.6120e+00,\n",
            "           1.4748e-01,  9.0877e-01, -3.2035e-01,  1.0412e-01, -7.2224e-01]],\n",
            "\n",
            "        [[ 9.0939e-01,  5.6384e-01, -5.0207e-01,  6.4361e-01,  9.4076e-01,\n",
            "           2.2158e-01,  1.2558e-01,  5.4698e-01,  7.6626e-01,  2.0081e-01],\n",
            "         [ 1.7598e+00, -2.1793e-02, -3.6664e-01,  7.1284e-01,  1.0640e+00,\n",
            "           2.0936e-01,  2.6671e-01,  3.9117e-01,  6.4736e-01,  3.4957e-02],\n",
            "         [ 1.8413e+00, -1.1726e+00, -2.4733e-01,  8.0170e-01,  1.2405e+00,\n",
            "           1.9006e-01,  4.8231e-01,  1.5072e-01,  4.6353e-01, -2.2096e-01],\n",
            "         [ 1.0869e+00, -1.9407e+00, -1.3583e-01,  8.6676e-01,  1.4169e+00,\n",
            "           1.7012e-01,  6.9792e-01, -8.9736e-02,  2.7970e-01, -4.7688e-01],\n",
            "         [ 1.9782e-01, -1.7303e+00, -2.3637e-02,  8.6512e-01,  1.5401e+00,\n",
            "           1.5601e-01,  8.3905e-01, -2.4560e-01,  1.6079e-01, -6.4274e-01],\n",
            "         [-3.3498e-05, -8.5338e-01,  8.5363e-02,  8.0073e-01,  1.6120e+00,\n",
            "           1.4748e-01,  9.0877e-01, -3.2035e-01,  1.0412e-01, -7.2224e-01]],\n",
            "\n",
            "        [[ 9.4573e-01,  4.9255e-02, -5.9358e-01,  9.7768e-01,  1.3416e+00,\n",
            "           1.7296e-01,  6.8598e-01, -8.9665e-02,  2.7781e-01, -4.7688e-01],\n",
            "         [ 1.7961e+00, -5.3638e-01, -4.5815e-01,  1.0469e+00,  1.4649e+00,\n",
            "           1.6074e-01,  8.2710e-01, -2.4548e-01,  1.5890e-01, -6.4273e-01],\n",
            "         [ 1.8682e+00, -1.5532e+00, -3.1501e-01,  1.0488e+00,  1.5370e+00,\n",
            "           1.5409e-01,  8.9683e-01, -3.2019e-01,  1.0223e-01, -7.2223e-01],\n",
            "         [ 1.1018e+00, -2.1518e+00, -1.7336e-01,  1.0038e+00,  1.5814e+00,\n",
            "           1.5018e-01,  9.2777e-01, -3.5086e-01,  7.9360e-02, -7.5484e-01],\n",
            "         [ 2.0451e-01, -1.8249e+00, -4.0464e-02,  9.2655e-01,  1.6138e+00,\n",
            "           1.4707e-01,  9.4210e-01, -3.6267e-01,  7.0975e-02, -7.6735e-01],\n",
            "         [ 2.6367e-03, -8.9119e-01,  7.8640e-02,  8.2527e-01,  1.6415e+00,\n",
            "           1.4390e-01,  9.4994e-01, -3.6713e-01,  6.8237e-02, -7.7203e-01]],\n",
            "\n",
            "        [[ 9.0236e-01,  6.6332e-01, -4.8438e-01,  5.7903e-01,  8.6326e-01,\n",
            "           2.3098e-01,  1.7238e-02,  6.7007e-01,  8.6070e-01,  3.3183e-01],\n",
            "         [ 1.7439e+00,  2.0231e-01, -3.2679e-01,  5.6735e-01,  8.8939e-01,\n",
            "           2.3054e-01,  2.2650e-02,  6.6844e-01,  8.6008e-01,  3.3010e-01],\n",
            "         [ 1.8120e+00, -7.5769e-01, -1.7355e-01,  5.3237e-01,  9.1726e-01,\n",
            "           2.2926e-01,  3.0496e-02,  6.6402e-01,  8.5734e-01,  3.2542e-01],\n",
            "         [ 1.0445e+00, -1.3410e+00, -2.9178e-02,  4.7743e-01,  9.4973e-01,\n",
            "           2.2678e-01,  4.4820e-02,  6.5223e-01,  8.4896e-01,  3.1291e-01],\n",
            "         [ 1.4832e-01, -1.0294e+00,  1.0100e-01,  4.1012e-01,  9.9404e-01,\n",
            "           2.2224e-01,  7.5765e-02,  6.2154e-01,  8.2609e-01,  2.8030e-01],\n",
            "         [-4.9536e-02, -1.5250e-01,  2.1000e-01,  3.4572e-01,  1.0660e+00,\n",
            "           2.1370e-01,  1.4549e-01,  5.4679e-01,  7.6942e-01,  2.0080e-01]],\n",
            "\n",
            "        [[ 9.0231e-01,  6.6405e-01, -4.8425e-01,  5.7856e-01,  8.6269e-01,\n",
            "           2.3105e-01,  1.6445e-02,  6.7097e-01,  8.6139e-01,  3.3279e-01],\n",
            "         [ 1.7438e+00,  2.0429e-01, -3.2643e-01,  5.6607e-01,  8.8786e-01,\n",
            "           2.3073e-01,  2.0498e-02,  6.7088e-01,  8.6196e-01,  3.3270e-01],\n",
            "         [ 1.8116e+00, -7.5234e-01, -1.7260e-01,  5.2890e-01,  9.1309e-01,\n",
            "           2.2976e-01,  2.4673e-02,  6.7064e-01,  8.6242e-01,  3.3246e-01],\n",
            "         [ 1.0435e+00, -1.3267e+00, -2.6625e-02,  4.6811e-01,  9.3854e-01,\n",
            "           2.2814e-01,  2.9181e-02,  6.7000e-01,  8.6259e-01,  3.3182e-01],\n",
            "         [ 1.4565e-01, -9.9163e-01,  1.0772e-01,  3.8557e-01,  9.6458e-01,\n",
            "           2.2581e-01,  3.4592e-02,  6.6832e-01,  8.6198e-01,  3.3009e-01],\n",
            "         [-5.6219e-02, -5.7877e-02,  2.2683e-01,  2.8429e-01,  9.9231e-01,\n",
            "           2.2264e-01,  4.2438e-02,  6.6386e-01,  8.5924e-01,  3.2542e-01]],\n",
            "\n",
            "        [[ 9.0233e-01,  6.6381e-01, -4.8429e-01,  5.7871e-01,  8.6288e-01,\n",
            "           2.3103e-01,  1.6711e-02,  6.7067e-01,  8.6116e-01,  3.3246e-01],\n",
            "         [ 1.7438e+00,  2.0363e-01, -3.2655e-01,  5.6650e-01,  8.8837e-01,\n",
            "           2.3066e-01,  2.1219e-02,  6.7006e-01,  8.6133e-01,  3.3183e-01],\n",
            "         [ 1.8118e+00, -7.5414e-01, -1.7292e-01,  5.3006e-01,  9.1449e-01,\n",
            "           2.2959e-01,  2.6631e-02,  6.6841e-01,  8.6071e-01,  3.3010e-01],\n",
            "         [ 1.0438e+00, -1.3315e+00, -2.7489e-02,  4.7126e-01,  9.4233e-01,\n",
            "           2.2768e-01,  3.4477e-02,  6.6398e-01,  8.5798e-01,  3.2542e-01],\n",
            "         [ 1.4657e-01, -1.0047e+00,  1.0540e-01,  3.9404e-01,  9.7475e-01,\n",
            "           2.2458e-01,  4.8801e-02,  6.5218e-01,  8.4959e-01,  3.1291e-01],\n",
            "         [-5.3800e-02, -9.2134e-02,  2.2074e-01,  3.0653e-01,  1.0190e+00,\n",
            "           2.1941e-01,  7.9745e-02,  6.2147e-01,  8.2672e-01,  2.8030e-01]],\n",
            "\n",
            "        [[ 9.0271e-01,  6.5846e-01, -4.8524e-01,  5.8219e-01,  8.6704e-01,\n",
            "           2.3052e-01,  2.2534e-02,  6.6405e-01,  8.5608e-01,  3.2542e-01],\n",
            "         [ 1.7448e+00,  1.8927e-01, -3.2911e-01,  5.7582e-01,  8.9956e-01,\n",
            "           2.2931e-01,  3.6858e-02,  6.5229e-01,  8.4770e-01,  3.1291e-01],\n",
            "         [ 1.8144e+00, -7.9194e-01, -1.7964e-01,  5.5461e-01,  9.4395e-01,\n",
            "           2.2602e-01,  6.7803e-02,  6.2164e-01,  8.2483e-01,  2.8031e-01],\n",
            "         [ 1.0505e+00, -1.4262e+00, -4.4316e-02,  5.3269e-01,  1.0160e+00,\n",
            "           2.1874e-01,  1.3752e-01,  5.4691e-01,  7.6816e-01,  2.0081e-01],\n",
            "         [ 1.6148e-01, -1.2157e+00,  6.7872e-02,  5.3106e-01,  1.1392e+00,\n",
            "           2.0464e-01,  2.7865e-01,  3.9105e-01,  6.4925e-01,  3.4954e-02],\n",
            "         [-2.6917e-02, -4.7276e-01,  1.5305e-01,  5.5363e-01,  1.3155e+00,\n",
            "           1.8344e-01,  4.9426e-01,  1.5056e-01,  4.6542e-01, -2.2097e-01]],\n",
            "\n",
            "        [[ 9.0231e-01,  6.6399e-01, -4.8426e-01,  5.7860e-01,  8.6274e-01,\n",
            "           2.3104e-01,  1.6517e-02,  6.7089e-01,  8.6133e-01,  3.3270e-01],\n",
            "         [ 1.7438e+00,  2.0411e-01, -3.2647e-01,  5.6618e-01,  8.8799e-01,\n",
            "           2.3071e-01,  2.0692e-02,  6.7066e-01,  8.6179e-01,  3.3246e-01],\n",
            "         [ 1.8117e+00, -7.5282e-01, -1.7268e-01,  5.2921e-01,  9.1347e-01,\n",
            "           2.2972e-01,  2.5200e-02,  6.7004e-01,  8.6196e-01,  3.3183e-01],\n",
            "         [ 1.0436e+00, -1.3280e+00, -2.6858e-02,  4.6896e-01,  9.3956e-01,\n",
            "           2.2802e-01,  3.0611e-02,  6.6837e-01,  8.6134e-01,  3.3010e-01],\n",
            "         [ 1.4590e-01, -9.9518e-01,  1.0709e-01,  3.8788e-01,  9.6735e-01,\n",
            "           2.2548e-01,  3.8457e-02,  6.6393e-01,  8.5861e-01,  3.2542e-01],\n",
            "         [-5.5548e-02, -6.7375e-02,  2.2514e-01,  2.9046e-01,  9.9971e-01,\n",
            "           2.2175e-01,  5.2781e-02,  6.5210e-01,  8.5022e-01,  3.1291e-01]],\n",
            "\n",
            "        [[ 9.1828e-01,  4.3790e-01, -5.2447e-01,  7.2537e-01,  1.0389e+00,\n",
            "           2.0968e-01,  2.6273e-01,  3.9118e-01,  6.4673e-01,  3.4957e-02],\n",
            "         [ 1.7735e+00, -2.1612e-01, -4.0120e-01,  8.3899e-01,  1.2154e+00,\n",
            "           1.9100e-01,  4.7833e-01,  1.5075e-01,  4.6290e-01, -2.2096e-01],\n",
            "         [ 1.8550e+00, -1.3669e+00, -2.8188e-01,  9.2786e-01,  1.3919e+00,\n",
            "           1.7170e-01,  6.9394e-01, -8.9697e-02,  2.7907e-01, -4.7688e-01],\n",
            "         [ 1.0957e+00, -2.0667e+00, -1.5822e-01,  9.4851e-01,  1.5150e+00,\n",
            "           1.5822e-01,  8.3507e-01, -2.4554e-01,  1.6016e-01, -6.4273e-01],\n",
            "         [ 2.0209e-01, -1.7907e+00, -3.4372e-02,  9.0431e-01,  1.5871e+00,\n",
            "           1.5031e-01,  9.0479e-01, -3.2028e-01,  1.0349e-01, -7.2224e-01],\n",
            "         [ 1.7152e-03, -8.7814e-01,  8.0960e-02,  8.1680e-01,  1.6313e+00,\n",
            "           1.4514e-01,  9.3573e-01, -3.5099e-01,  8.0622e-02, -7.5484e-01]],\n",
            "\n",
            "        [[ 9.3201e-01,  2.4358e-01, -5.5902e-01,  8.5152e-01,  1.1903e+00,\n",
            "           1.9132e-01,  4.7435e-01,  1.5076e-01,  4.6227e-01, -2.2096e-01],\n",
            "         [ 1.7872e+00, -4.1044e-01, -4.3575e-01,  9.6514e-01,  1.3668e+00,\n",
            "           1.7264e-01,  6.8996e-01, -8.9673e-02,  2.7844e-01, -4.7688e-01],\n",
            "         [ 1.8639e+00, -1.4928e+00, -3.0428e-01,  1.0096e+00,  1.4900e+00,\n",
            "           1.5980e-01,  8.3109e-01, -2.4550e-01,  1.5953e-01, -6.4273e-01],\n",
            "         [ 1.1000e+00, -2.1270e+00, -1.6896e-01,  9.8770e-01,  1.5621e+00,\n",
            "           1.5252e-01,  9.0081e-01, -3.2023e-01,  1.0286e-01, -7.2223e-01],\n",
            "         [ 2.0384e-01, -1.8154e+00, -3.8775e-02,  9.2038e-01,  1.6064e+00,\n",
            "           1.4797e-01,  9.3175e-01, -3.5092e-01,  7.9991e-02, -7.5484e-01],\n",
            "         [ 2.3860e-03, -8.8764e-01,  7.9271e-02,  8.2297e-01,  1.6387e+00,\n",
            "           1.4424e-01,  9.4608e-01, -3.6274e-01,  7.1606e-02, -7.6735e-01]],\n",
            "\n",
            "        [[ 9.0236e-01,  6.6332e-01, -4.8438e-01,  5.7903e-01,  8.6326e-01,\n",
            "           2.3098e-01,  1.7238e-02,  6.7007e-01,  8.6070e-01,  3.3183e-01],\n",
            "         [ 1.7439e+00,  2.0231e-01, -3.2679e-01,  5.6735e-01,  8.8939e-01,\n",
            "           2.3054e-01,  2.2650e-02,  6.6844e-01,  8.6008e-01,  3.3010e-01],\n",
            "         [ 1.8120e+00, -7.5769e-01, -1.7355e-01,  5.3237e-01,  9.1726e-01,\n",
            "           2.2926e-01,  3.0496e-02,  6.6402e-01,  8.5734e-01,  3.2542e-01],\n",
            "         [ 1.0445e+00, -1.3410e+00, -2.9178e-02,  4.7743e-01,  9.4973e-01,\n",
            "           2.2678e-01,  4.4820e-02,  6.5223e-01,  8.4896e-01,  3.1291e-01],\n",
            "         [ 1.4832e-01, -1.0294e+00,  1.0100e-01,  4.1012e-01,  9.9404e-01,\n",
            "           2.2224e-01,  7.5765e-02,  6.2154e-01,  8.2609e-01,  2.8030e-01],\n",
            "         [-4.9536e-02, -1.5250e-01,  2.1000e-01,  3.4572e-01,  1.0660e+00,\n",
            "           2.1370e-01,  1.4549e-01,  5.4679e-01,  7.6942e-01,  2.0080e-01]],\n",
            "\n",
            "        [[ 9.0245e-01,  6.6201e-01, -4.8461e-01,  5.7988e-01,  8.6428e-01,\n",
            "           2.3086e-01,  1.8668e-02,  6.6844e-01,  8.5945e-01,  3.3010e-01],\n",
            "         [ 1.7442e+00,  1.9876e-01, -3.2742e-01,  5.6965e-01,  8.9216e-01,\n",
            "           2.3020e-01,  2.6515e-02,  6.6405e-01,  8.5671e-01,  3.2542e-01],\n",
            "         [ 1.8127e+00, -7.6718e-01, -1.7524e-01,  5.3853e-01,  9.2466e-01,\n",
            "           2.2836e-01,  4.0839e-02,  6.5227e-01,  8.4833e-01,  3.1291e-01],\n",
            "         [ 1.0462e+00, -1.3658e+00, -3.3581e-02,  4.9350e-01,  9.6902e-01,\n",
            "           2.2445e-01,  7.1784e-02,  6.2160e-01,  8.2546e-01,  2.8031e-01],\n",
            "         [ 1.5259e-01, -1.0898e+00,  9.0267e-02,  4.4930e-01,  1.0411e+00,\n",
            "           2.1654e-01,  1.4151e-01,  5.4686e-01,  7.6879e-01,  2.0080e-01],\n",
            "         [-4.0642e-02, -2.7843e-01,  1.8761e-01,  4.2747e-01,  1.1641e+00,\n",
            "           2.0180e-01,  2.8263e-01,  3.9098e-01,  6.4988e-01,  3.4952e-02]],\n",
            "\n",
            "        [[ 9.0512e-01,  6.2420e-01, -4.9134e-01,  6.0443e-01,  8.9373e-01,\n",
            "           2.2728e-01,  5.9841e-02,  6.2167e-01,  8.2357e-01,  2.8031e-01],\n",
            "         [ 1.7509e+00,  1.0414e-01, -3.4424e-01,  6.3108e-01,  9.6588e-01,\n",
            "           2.2126e-01,  1.2956e-01,  5.4698e-01,  7.6690e-01,  2.0081e-01],\n",
            "         [ 1.8276e+00, -9.7824e-01, -2.1277e-01,  6.7555e-01,  1.0891e+00,\n",
            "           2.0842e-01,  2.7069e-01,  3.9115e-01,  6.4799e-01,  3.4956e-02],\n",
            "         [ 1.0731e+00, -1.7464e+00, -1.0127e-01,  7.4060e-01,  1.2655e+00,\n",
            "           1.8848e-01,  4.8630e-01,  1.5069e-01,  4.6416e-01, -2.2096e-01],\n",
            "         [ 1.8893e-01, -1.6044e+00, -1.2423e-03,  7.8337e-01,  1.4419e+00,\n",
            "           1.6791e-01,  7.0190e-01, -8.9792e-02,  2.8033e-01, -4.7689e-01],\n",
            "         [-4.2971e-03, -7.9302e-01,  9.6098e-02,  7.6154e-01,  1.5650e+00,\n",
            "           1.5318e-01,  8.4303e-01, -2.4567e-01,  1.6142e-01, -6.4274e-01]],\n",
            "\n",
            "        [[ 9.4573e-01,  4.9255e-02, -5.9358e-01,  9.7768e-01,  1.3416e+00,\n",
            "           1.7296e-01,  6.8598e-01, -8.9665e-02,  2.7781e-01, -4.7688e-01],\n",
            "         [ 1.7961e+00, -5.3638e-01, -4.5815e-01,  1.0469e+00,  1.4649e+00,\n",
            "           1.6074e-01,  8.2710e-01, -2.4548e-01,  1.5890e-01, -6.4273e-01],\n",
            "         [ 1.8682e+00, -1.5532e+00, -3.1501e-01,  1.0488e+00,  1.5370e+00,\n",
            "           1.5409e-01,  8.9683e-01, -3.2019e-01,  1.0223e-01, -7.2223e-01],\n",
            "         [ 1.1018e+00, -2.1518e+00, -1.7336e-01,  1.0038e+00,  1.5814e+00,\n",
            "           1.5018e-01,  9.2777e-01, -3.5086e-01,  7.9360e-02, -7.5484e-01],\n",
            "         [ 2.0451e-01, -1.8249e+00, -4.0464e-02,  9.2655e-01,  1.6138e+00,\n",
            "           1.4707e-01,  9.4210e-01, -3.6267e-01,  7.0975e-02, -7.6735e-01],\n",
            "         [ 2.6367e-03, -8.9119e-01,  7.8640e-02,  8.2527e-01,  1.6415e+00,\n",
            "           1.4390e-01,  9.4994e-01, -3.6713e-01,  6.8237e-02, -7.7203e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "t tensor([[ 9],\n",
            "        [ 7],\n",
            "        [ 2],\n",
            "        [ 7],\n",
            "        [10],\n",
            "        [ 4],\n",
            "        [ 0],\n",
            "        [ 7],\n",
            "        [11],\n",
            "        [11],\n",
            "        [ 3],\n",
            "        [ 2],\n",
            "        [10],\n",
            "        [ 7],\n",
            "        [ 9]], dtype=torch.int32)\n",
            "b before tensor([[-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4]])\n",
            "b after tensor([[ -1,   0,   1,   2,   3,   4,   5],\n",
            "        [ -3,  -2,  -1,   0,   1,   2,   3],\n",
            "        [ -8,  -7,  -6,  -5,  -4,  -3,  -2],\n",
            "        [ -3,  -2,  -1,   0,   1,   2,   3],\n",
            "        [  0,   1,   2,   3,   4,   5,   6],\n",
            "        [ -6,  -5,  -4,  -3,  -2,  -1,   0],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [ -3,  -2,  -1,   0,   1,   2,   3],\n",
            "        [  1,   2,   3,   4,   5,   6,   7],\n",
            "        [  1,   2,   3,   4,   5,   6,   7],\n",
            "        [ -7,  -6,  -5,  -4,  -3,  -2,  -1],\n",
            "        [ -8,  -7,  -6,  -5,  -4,  -3,  -2],\n",
            "        [  0,   1,   2,   3,   4,   5,   6],\n",
            "        [ -3,  -2,  -1,   0,   1,   2,   3],\n",
            "        [ -1,   0,   1,   2,   3,   4,   5]])\n",
            "s torch.Size([15, 7])\n",
            "---------\n",
            "after positional encoding shapetensor([[[ 9.1811e-01,  4.3832e-01, -5.2466e-01,  7.2541e-01,  1.0390e+00,\n",
            "           2.0996e-01,  2.6268e-01,  3.9111e-01,  6.4684e-01,  3.4814e-02],\n",
            "         [ 1.7733e+00, -2.1566e-01, -4.0138e-01,  8.3907e-01,  1.2155e+00,\n",
            "           1.9122e-01,  4.7830e-01,  1.5066e-01,  4.6303e-01, -2.2112e-01],\n",
            "         [ 1.8549e+00, -1.3664e+00, -2.8206e-01,  9.2797e-01,  1.3920e+00,\n",
            "           1.7184e-01,  6.9392e-01, -8.9805e-02,  2.7921e-01, -4.7706e-01],\n",
            "         [ 1.0957e+00, -2.0661e+00, -1.5839e-01,  9.4865e-01,  1.5152e+00,\n",
            "           1.5833e-01,  8.3505e-01, -2.4566e-01,  1.6031e-01, -6.4292e-01],\n",
            "         [ 2.0201e-01, -1.7901e+00, -3.4538e-02,  9.0446e-01,  1.5873e+00,\n",
            "           1.5040e-01,  9.0477e-01, -3.2041e-01,  1.0364e-01, -7.2243e-01],\n",
            "         [ 1.6380e-03, -8.7759e-01,  8.0795e-02,  8.1695e-01,  1.6315e+00,\n",
            "           1.4521e-01,  9.3572e-01, -3.5112e-01,  8.0772e-02, -7.5504e-01]],\n",
            "\n",
            "        [[ 9.0493e-01,  6.2458e-01, -4.9155e-01,  6.0443e-01,  8.9378e-01,\n",
            "           2.2763e-01,  5.9790e-02,  6.2161e-01,  8.2367e-01,  2.8018e-01],\n",
            "         [ 1.7507e+00,  1.0453e-01, -3.4445e-01,  6.3110e-01,  9.6594e-01,\n",
            "           2.2159e-01,  1.2951e-01,  5.4692e-01,  7.6700e-01,  2.0067e-01],\n",
            "         [ 1.8274e+00, -9.7782e-01, -2.1297e-01,  6.7559e-01,  1.0892e+00,\n",
            "           2.0870e-01,  2.7065e-01,  3.9107e-01,  6.4810e-01,  3.4813e-02],\n",
            "         [ 1.0730e+00, -1.7460e+00, -1.0146e-01,  7.4068e-01,  1.2657e+00,\n",
            "           1.8870e-01,  4.8626e-01,  1.5059e-01,  4.6429e-01, -2.2112e-01],\n",
            "         [ 1.8882e-01, -1.6039e+00, -1.4192e-03,  7.8348e-01,  1.4421e+00,\n",
            "           1.6806e-01,  7.0188e-01, -8.9900e-02,  2.8047e-01, -4.7706e-01],\n",
            "         [-4.3874e-03, -7.9248e-01,  9.5929e-02,  7.6168e-01,  1.5652e+00,\n",
            "           1.5329e-01,  8.4301e-01, -2.4579e-01,  1.6157e-01, -6.4292e-01]],\n",
            "\n",
            "        [[ 9.0212e-01,  6.6418e-01, -4.8451e-01,  5.7872e-01,  8.6292e-01,\n",
            "           2.3138e-01,  1.6658e-02,  6.7062e-01,  8.6126e-01,  3.3234e-01],\n",
            "         [ 1.7436e+00,  2.0399e-01, -3.2676e-01,  5.6650e-01,  8.8841e-01,\n",
            "           2.3102e-01,  2.1166e-02,  6.7001e-01,  8.6143e-01,  3.3170e-01],\n",
            "         [ 1.8115e+00, -7.5377e-01, -1.7313e-01,  5.3007e-01,  9.1454e-01,\n",
            "           2.2995e-01,  2.6577e-02,  6.6836e-01,  8.6082e-01,  3.2997e-01],\n",
            "         [ 1.0436e+00, -1.3312e+00, -2.7701e-02,  4.7127e-01,  9.4237e-01,\n",
            "           2.2804e-01,  3.4424e-02,  6.6393e-01,  8.5808e-01,  3.2530e-01],\n",
            "         [ 1.4637e-01, -1.0043e+00,  1.0519e-01,  3.9405e-01,  9.7479e-01,\n",
            "           2.2493e-01,  4.8748e-02,  6.5212e-01,  8.4970e-01,  3.1279e-01],\n",
            "         [-5.3998e-02, -9.1757e-02,  2.2053e-01,  3.0654e-01,  1.0190e+00,\n",
            "           2.1975e-01,  7.9694e-02,  6.2142e-01,  8.2683e-01,  2.8017e-01]],\n",
            "\n",
            "        [[ 9.0493e-01,  6.2458e-01, -4.9155e-01,  6.0443e-01,  8.9378e-01,\n",
            "           2.2763e-01,  5.9790e-02,  6.2161e-01,  8.2367e-01,  2.8018e-01],\n",
            "         [ 1.7507e+00,  1.0453e-01, -3.4445e-01,  6.3110e-01,  9.6594e-01,\n",
            "           2.2159e-01,  1.2951e-01,  5.4692e-01,  7.6700e-01,  2.0067e-01],\n",
            "         [ 1.8274e+00, -9.7782e-01, -2.1297e-01,  6.7559e-01,  1.0892e+00,\n",
            "           2.0870e-01,  2.7065e-01,  3.9107e-01,  6.4810e-01,  3.4813e-02],\n",
            "         [ 1.0730e+00, -1.7460e+00, -1.0146e-01,  7.4068e-01,  1.2657e+00,\n",
            "           1.8870e-01,  4.8626e-01,  1.5059e-01,  4.6429e-01, -2.2112e-01],\n",
            "         [ 1.8882e-01, -1.6039e+00, -1.4192e-03,  7.8348e-01,  1.4421e+00,\n",
            "           1.6806e-01,  7.0188e-01, -8.9900e-02,  2.8047e-01, -4.7706e-01],\n",
            "         [-4.3874e-03, -7.9248e-01,  9.5929e-02,  7.6168e-01,  1.5652e+00,\n",
            "           1.5329e-01,  8.4301e-01, -2.4579e-01,  1.6157e-01, -6.4292e-01]],\n",
            "\n",
            "        [[ 9.3187e-01,  2.4404e-01, -5.5921e-01,  8.5160e-01,  1.1904e+00,\n",
            "           1.9153e-01,  4.7432e-01,  1.5067e-01,  4.6239e-01, -2.2112e-01],\n",
            "         [ 1.7871e+00, -4.0994e-01, -4.3593e-01,  9.6526e-01,  1.3669e+00,\n",
            "           1.7279e-01,  6.8994e-01, -8.9781e-02,  2.7858e-01, -4.7706e-01],\n",
            "         [ 1.8638e+00, -1.4923e+00, -3.0445e-01,  1.0098e+00,  1.4902e+00,\n",
            "           1.5990e-01,  8.3107e-01, -2.4562e-01,  1.5968e-01, -6.4292e-01],\n",
            "         [ 1.0999e+00, -2.1265e+00, -1.6912e-01,  9.8785e-01,  1.5623e+00,\n",
            "           1.5260e-01,  9.0079e-01, -3.2035e-01,  1.0301e-01, -7.2243e-01],\n",
            "         [ 2.0376e-01, -1.8149e+00, -3.8940e-02,  9.2054e-01,  1.6066e+00,\n",
            "           1.4805e-01,  9.3174e-01, -3.5104e-01,  8.0141e-02, -7.5504e-01],\n",
            "         [ 2.3103e-03, -8.8709e-01,  7.9107e-02,  8.2312e-01,  1.6389e+00,\n",
            "           1.4431e-01,  9.4606e-01, -3.6287e-01,  7.1757e-02, -7.6755e-01]],\n",
            "\n",
            "        [[ 9.0225e-01,  6.6238e-01, -4.8482e-01,  5.7988e-01,  8.6432e-01,\n",
            "           2.3121e-01,  1.8615e-02,  6.6839e-01,  8.5956e-01,  3.2997e-01],\n",
            "         [ 1.7440e+00,  1.9913e-01, -3.2763e-01,  5.6966e-01,  8.9220e-01,\n",
            "           2.3056e-01,  2.6462e-02,  6.6399e-01,  8.5682e-01,  3.2530e-01],\n",
            "         [ 1.8125e+00, -7.6681e-01, -1.7545e-01,  5.3854e-01,  9.2470e-01,\n",
            "           2.2871e-01,  4.0787e-02,  6.5222e-01,  8.4843e-01,  3.1279e-01],\n",
            "         [ 1.0460e+00, -1.3654e+00, -3.3791e-02,  4.9351e-01,  9.6907e-01,\n",
            "           2.2479e-01,  7.1733e-02,  6.2154e-01,  8.2556e-01,  2.8018e-01],\n",
            "         [ 1.5240e-01, -1.0894e+00,  9.0060e-02,  4.4932e-01,  1.0411e+00,\n",
            "           2.1686e-01,  1.4146e-01,  5.4680e-01,  7.6890e-01,  2.0067e-01],\n",
            "         [-4.0811e-02, -2.7801e-01,  1.8741e-01,  4.2752e-01,  1.1642e+00,\n",
            "           2.0208e-01,  2.8259e-01,  3.9091e-01,  6.5000e-01,  3.4809e-02]],\n",
            "\n",
            "        [[ 9.0211e-01,  6.6442e-01, -4.8446e-01,  5.7856e-01,  8.6273e-01,\n",
            "           2.3141e-01,  1.6392e-02,  6.7092e-01,  8.6149e-01,  3.3266e-01],\n",
            "         [ 1.7436e+00,  2.0466e-01, -3.2665e-01,  5.6607e-01,  8.8790e-01,\n",
            "           2.3108e-01,  2.0445e-02,  6.7083e-01,  8.6206e-01,  3.3258e-01],\n",
            "         [ 1.8114e+00, -7.5197e-01, -1.7281e-01,  5.2890e-01,  9.1314e-01,\n",
            "           2.3012e-01,  2.4620e-02,  6.7059e-01,  8.6252e-01,  3.3234e-01],\n",
            "         [ 1.0433e+00, -1.3263e+00, -2.6837e-02,  4.6811e-01,  9.3858e-01,\n",
            "           2.2850e-01,  2.9128e-02,  6.6995e-01,  8.6270e-01,  3.3170e-01],\n",
            "         [ 1.4545e-01, -9.9126e-01,  1.0751e-01,  3.8557e-01,  9.6463e-01,\n",
            "           2.2617e-01,  3.4539e-02,  6.6827e-01,  8.6208e-01,  3.2997e-01],\n",
            "         [-5.6422e-02, -5.7507e-02,  2.2662e-01,  2.8429e-01,  9.9235e-01,\n",
            "           2.2300e-01,  4.2385e-02,  6.6380e-01,  8.5934e-01,  3.2529e-01]],\n",
            "\n",
            "        [[ 9.0493e-01,  6.2458e-01, -4.9155e-01,  6.0443e-01,  8.9378e-01,\n",
            "           2.2763e-01,  5.9790e-02,  6.2161e-01,  8.2367e-01,  2.8018e-01],\n",
            "         [ 1.7507e+00,  1.0453e-01, -3.4445e-01,  6.3110e-01,  9.6594e-01,\n",
            "           2.2159e-01,  1.2951e-01,  5.4692e-01,  7.6700e-01,  2.0067e-01],\n",
            "         [ 1.8274e+00, -9.7782e-01, -2.1297e-01,  6.7559e-01,  1.0892e+00,\n",
            "           2.0870e-01,  2.7065e-01,  3.9107e-01,  6.4810e-01,  3.4813e-02],\n",
            "         [ 1.0730e+00, -1.7460e+00, -1.0146e-01,  7.4068e-01,  1.2657e+00,\n",
            "           1.8870e-01,  4.8626e-01,  1.5059e-01,  4.6429e-01, -2.2112e-01],\n",
            "         [ 1.8882e-01, -1.6039e+00, -1.4192e-03,  7.8348e-01,  1.4421e+00,\n",
            "           1.6806e-01,  7.0188e-01, -8.9900e-02,  2.8047e-01, -4.7706e-01],\n",
            "         [-4.3874e-03, -7.9248e-01,  9.5929e-02,  7.6168e-01,  1.5652e+00,\n",
            "           1.5329e-01,  8.4301e-01, -2.4579e-01,  1.6157e-01, -6.4292e-01]],\n",
            "\n",
            "        [[ 9.4562e-01,  4.9760e-02, -5.9376e-01,  9.7779e-01,  1.3418e+00,\n",
            "           1.7311e-01,  6.8596e-01, -8.9774e-02,  2.7795e-01, -4.7706e-01],\n",
            "         [ 1.7960e+00, -5.3584e-01, -4.5832e-01,  1.0470e+00,  1.4651e+00,\n",
            "           1.6085e-01,  8.2709e-01, -2.4560e-01,  1.5905e-01, -6.4292e-01],\n",
            "         [ 1.8681e+00, -1.5526e+00, -3.1518e-01,  1.0490e+00,  1.5372e+00,\n",
            "           1.5418e-01,  8.9681e-01, -3.2031e-01,  1.0238e-01, -7.2243e-01],\n",
            "         [ 1.1017e+00, -2.1512e+00, -1.7352e-01,  1.0039e+00,  1.5816e+00,\n",
            "           1.5025e-01,  9.2776e-01, -3.5099e-01,  7.9510e-02, -7.5504e-01],\n",
            "         [ 2.0443e-01, -1.8244e+00, -4.0629e-02,  9.2671e-01,  1.6140e+00,\n",
            "           1.4715e-01,  9.4208e-01, -3.6280e-01,  7.1126e-02, -7.6755e-01],\n",
            "         [ 2.5615e-03, -8.9063e-01,  7.8476e-02,  8.2543e-01,  1.6417e+00,\n",
            "           1.4398e-01,  9.4993e-01, -3.6726e-01,  6.8388e-02, -7.7222e-01]],\n",
            "\n",
            "        [[ 9.4562e-01,  4.9760e-02, -5.9376e-01,  9.7779e-01,  1.3418e+00,\n",
            "           1.7311e-01,  6.8596e-01, -8.9774e-02,  2.7795e-01, -4.7706e-01],\n",
            "         [ 1.7960e+00, -5.3584e-01, -4.5832e-01,  1.0470e+00,  1.4651e+00,\n",
            "           1.6085e-01,  8.2709e-01, -2.4560e-01,  1.5905e-01, -6.4292e-01],\n",
            "         [ 1.8681e+00, -1.5526e+00, -3.1518e-01,  1.0490e+00,  1.5372e+00,\n",
            "           1.5418e-01,  8.9681e-01, -3.2031e-01,  1.0238e-01, -7.2243e-01],\n",
            "         [ 1.1017e+00, -2.1512e+00, -1.7352e-01,  1.0039e+00,  1.5816e+00,\n",
            "           1.5025e-01,  9.2776e-01, -3.5099e-01,  7.9510e-02, -7.5504e-01],\n",
            "         [ 2.0443e-01, -1.8244e+00, -4.0629e-02,  9.2671e-01,  1.6140e+00,\n",
            "           1.4715e-01,  9.4208e-01, -3.6280e-01,  7.1126e-02, -7.6755e-01],\n",
            "         [ 2.5615e-03, -8.9063e-01,  7.8476e-02,  8.2543e-01,  1.6417e+00,\n",
            "           1.4398e-01,  9.4993e-01, -3.6726e-01,  6.8388e-02, -7.7222e-01]],\n",
            "\n",
            "        [[ 9.0216e-01,  6.6369e-01, -4.8459e-01,  5.7903e-01,  8.6330e-01,\n",
            "           2.3134e-01,  1.7185e-02,  6.7002e-01,  8.6080e-01,  3.3170e-01],\n",
            "         [ 1.7437e+00,  2.0268e-01, -3.2700e-01,  5.6735e-01,  8.8944e-01,\n",
            "           2.3090e-01,  2.2596e-02,  6.6839e-01,  8.6019e-01,  3.2997e-01],\n",
            "         [ 1.8118e+00, -7.5732e-01, -1.7376e-01,  5.3237e-01,  9.1730e-01,\n",
            "           2.2961e-01,  3.0443e-02,  6.6397e-01,  8.5745e-01,  3.2530e-01],\n",
            "         [ 1.0443e+00, -1.3407e+00, -2.9390e-02,  4.7743e-01,  9.4977e-01,\n",
            "           2.2714e-01,  4.4768e-02,  6.5218e-01,  8.4906e-01,  3.1279e-01],\n",
            "         [ 1.4812e-01, -1.0291e+00,  1.0079e-01,  4.1012e-01,  9.9409e-01,\n",
            "           2.2258e-01,  7.5713e-02,  6.2149e-01,  8.2620e-01,  2.8018e-01],\n",
            "         [-4.9725e-02, -1.5211e-01,  2.0980e-01,  3.4574e-01,  1.0661e+00,\n",
            "           2.1403e-01,  1.4544e-01,  5.4673e-01,  7.6953e-01,  2.0067e-01]],\n",
            "\n",
            "        [[ 9.0212e-01,  6.6418e-01, -4.8451e-01,  5.7872e-01,  8.6292e-01,\n",
            "           2.3138e-01,  1.6658e-02,  6.7062e-01,  8.6126e-01,  3.3234e-01],\n",
            "         [ 1.7436e+00,  2.0399e-01, -3.2676e-01,  5.6650e-01,  8.8841e-01,\n",
            "           2.3102e-01,  2.1166e-02,  6.7001e-01,  8.6143e-01,  3.3170e-01],\n",
            "         [ 1.8115e+00, -7.5377e-01, -1.7313e-01,  5.3007e-01,  9.1454e-01,\n",
            "           2.2995e-01,  2.6577e-02,  6.6836e-01,  8.6082e-01,  3.2997e-01],\n",
            "         [ 1.0436e+00, -1.3312e+00, -2.7701e-02,  4.7127e-01,  9.4237e-01,\n",
            "           2.2804e-01,  3.4424e-02,  6.6393e-01,  8.5808e-01,  3.2530e-01],\n",
            "         [ 1.4637e-01, -1.0043e+00,  1.0519e-01,  3.9405e-01,  9.7479e-01,\n",
            "           2.2493e-01,  4.8748e-02,  6.5212e-01,  8.4970e-01,  3.1279e-01],\n",
            "         [-5.3998e-02, -9.1757e-02,  2.2053e-01,  3.0654e-01,  1.0190e+00,\n",
            "           2.1975e-01,  7.9694e-02,  6.2142e-01,  8.2683e-01,  2.8017e-01]],\n",
            "\n",
            "        [[ 9.3187e-01,  2.4404e-01, -5.5921e-01,  8.5160e-01,  1.1904e+00,\n",
            "           1.9153e-01,  4.7432e-01,  1.5067e-01,  4.6239e-01, -2.2112e-01],\n",
            "         [ 1.7871e+00, -4.0994e-01, -4.3593e-01,  9.6526e-01,  1.3669e+00,\n",
            "           1.7279e-01,  6.8994e-01, -8.9781e-02,  2.7858e-01, -4.7706e-01],\n",
            "         [ 1.8638e+00, -1.4923e+00, -3.0445e-01,  1.0098e+00,  1.4902e+00,\n",
            "           1.5990e-01,  8.3107e-01, -2.4562e-01,  1.5968e-01, -6.4292e-01],\n",
            "         [ 1.0999e+00, -2.1265e+00, -1.6912e-01,  9.8785e-01,  1.5623e+00,\n",
            "           1.5260e-01,  9.0079e-01, -3.2035e-01,  1.0301e-01, -7.2243e-01],\n",
            "         [ 2.0376e-01, -1.8149e+00, -3.8940e-02,  9.2054e-01,  1.6066e+00,\n",
            "           1.4805e-01,  9.3174e-01, -3.5104e-01,  8.0141e-02, -7.5504e-01],\n",
            "         [ 2.3103e-03, -8.8709e-01,  7.9107e-02,  8.2312e-01,  1.6389e+00,\n",
            "           1.4431e-01,  9.4606e-01, -3.6287e-01,  7.1757e-02, -7.6755e-01]],\n",
            "\n",
            "        [[ 9.0493e-01,  6.2458e-01, -4.9155e-01,  6.0443e-01,  8.9378e-01,\n",
            "           2.2763e-01,  5.9790e-02,  6.2161e-01,  8.2367e-01,  2.8018e-01],\n",
            "         [ 1.7507e+00,  1.0453e-01, -3.4445e-01,  6.3110e-01,  9.6594e-01,\n",
            "           2.2159e-01,  1.2951e-01,  5.4692e-01,  7.6700e-01,  2.0067e-01],\n",
            "         [ 1.8274e+00, -9.7782e-01, -2.1297e-01,  6.7559e-01,  1.0892e+00,\n",
            "           2.0870e-01,  2.7065e-01,  3.9107e-01,  6.4810e-01,  3.4813e-02],\n",
            "         [ 1.0730e+00, -1.7460e+00, -1.0146e-01,  7.4068e-01,  1.2657e+00,\n",
            "           1.8870e-01,  4.8626e-01,  1.5059e-01,  4.6429e-01, -2.2112e-01],\n",
            "         [ 1.8882e-01, -1.6039e+00, -1.4192e-03,  7.8348e-01,  1.4421e+00,\n",
            "           1.6806e-01,  7.0188e-01, -8.9900e-02,  2.8047e-01, -4.7706e-01],\n",
            "         [-4.3874e-03, -7.9248e-01,  9.5929e-02,  7.6168e-01,  1.5652e+00,\n",
            "           1.5329e-01,  8.4301e-01, -2.4579e-01,  1.6157e-01, -6.4292e-01]],\n",
            "\n",
            "        [[ 9.1811e-01,  4.3832e-01, -5.2466e-01,  7.2541e-01,  1.0390e+00,\n",
            "           2.0996e-01,  2.6268e-01,  3.9111e-01,  6.4684e-01,  3.4814e-02],\n",
            "         [ 1.7733e+00, -2.1566e-01, -4.0138e-01,  8.3907e-01,  1.2155e+00,\n",
            "           1.9122e-01,  4.7830e-01,  1.5066e-01,  4.6303e-01, -2.2112e-01],\n",
            "         [ 1.8549e+00, -1.3664e+00, -2.8206e-01,  9.2797e-01,  1.3920e+00,\n",
            "           1.7184e-01,  6.9392e-01, -8.9805e-02,  2.7921e-01, -4.7706e-01],\n",
            "         [ 1.0957e+00, -2.0661e+00, -1.5839e-01,  9.4865e-01,  1.5152e+00,\n",
            "           1.5833e-01,  8.3505e-01, -2.4566e-01,  1.6031e-01, -6.4292e-01],\n",
            "         [ 2.0201e-01, -1.7901e+00, -3.4538e-02,  9.0446e-01,  1.5873e+00,\n",
            "           1.5040e-01,  9.0477e-01, -3.2041e-01,  1.0364e-01, -7.2243e-01],\n",
            "         [ 1.6380e-03, -8.7759e-01,  8.0795e-02,  8.1695e-01,  1.6315e+00,\n",
            "           1.4521e-01,  9.3572e-01, -3.5112e-01,  8.0772e-02, -7.5504e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "t tensor([[10],\n",
            "        [ 3],\n",
            "        [11],\n",
            "        [12],\n",
            "        [ 1],\n",
            "        [ 9],\n",
            "        [ 1],\n",
            "        [ 8],\n",
            "        [10],\n",
            "        [ 9],\n",
            "        [10],\n",
            "        [ 0],\n",
            "        [ 8],\n",
            "        [ 4],\n",
            "        [10]], dtype=torch.int32)\n",
            "b before tensor([[-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4]])\n",
            "b after tensor([[  0,   1,   2,   3,   4,   5,   6],\n",
            "        [ -7,  -6,  -5,  -4,  -3,  -2,  -1],\n",
            "        [  1,   2,   3,   4,   5,   6,   7],\n",
            "        [  2,   3,   4,   5,   6,   7,   8],\n",
            "        [ -9,  -8,  -7,  -6,  -5,  -4,  -3],\n",
            "        [ -1,   0,   1,   2,   3,   4,   5],\n",
            "        [ -9,  -8,  -7,  -6,  -5,  -4,  -3],\n",
            "        [ -2,  -1,   0,   1,   2,   3,   4],\n",
            "        [  0,   1,   2,   3,   4,   5,   6],\n",
            "        [ -1,   0,   1,   2,   3,   4,   5],\n",
            "        [  0,   1,   2,   3,   4,   5,   6],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [ -2,  -1,   0,   1,   2,   3,   4],\n",
            "        [ -6,  -5,  -4,  -3,  -2,  -1,   0],\n",
            "        [  0,   1,   2,   3,   4,   5,   6]])\n",
            "s torch.Size([15, 7])\n",
            "---------\n",
            "after positional encoding shapetensor([[[ 9.3173e-01,  2.4450e-01, -5.5939e-01,  8.5169e-01,  1.1905e+00,\n",
            "           1.9172e-01,  4.7430e-01,  1.5057e-01,  4.6254e-01, -2.2128e-01],\n",
            "         [ 1.7870e+00, -4.0943e-01, -4.3610e-01,  9.6538e-01,  1.3671e+00,\n",
            "           1.7291e-01,  6.8992e-01, -8.9897e-02,  2.7873e-01, -4.7724e-01],\n",
            "         [ 1.8637e+00, -1.4918e+00, -3.0461e-01,  1.0099e+00,  1.4903e+00,\n",
            "           1.5998e-01,  8.3106e-01, -2.4575e-01,  1.5984e-01, -6.4311e-01],\n",
            "         [ 1.0999e+00, -2.1259e+00, -1.6928e-01,  9.8801e-01,  1.5625e+00,\n",
            "           1.5266e-01,  9.0079e-01, -3.2049e-01,  1.0318e-01, -7.2262e-01],\n",
            "         [ 2.0369e-01, -1.8143e+00, -3.9098e-02,  9.2070e-01,  1.6068e+00,\n",
            "           1.4810e-01,  9.3173e-01, -3.5118e-01,  8.0308e-02, -7.5523e-01],\n",
            "         [ 2.2378e-03, -8.8653e-01,  7.8949e-02,  8.2329e-01,  1.6391e+00,\n",
            "           1.4436e-01,  9.4606e-01, -3.6300e-01,  7.1924e-02, -7.6774e-01]],\n",
            "\n",
            "        [[ 9.0196e-01,  6.6406e-01, -4.8479e-01,  5.7904e-01,  8.6335e-01,\n",
            "           2.3167e-01,  1.7138e-02,  6.6996e-01,  8.6092e-01,  3.3158e-01],\n",
            "         [ 1.7435e+00,  2.0305e-01, -3.2720e-01,  5.6736e-01,  8.8949e-01,\n",
            "           2.3123e-01,  2.2550e-02,  6.6833e-01,  8.6030e-01,  3.2985e-01],\n",
            "         [ 1.8116e+00, -7.5695e-01, -1.7396e-01,  5.3238e-01,  9.1735e-01,\n",
            "           2.2995e-01,  3.0396e-02,  6.6391e-01,  8.5756e-01,  3.2517e-01],\n",
            "         [ 1.0441e+00, -1.3403e+00, -2.9590e-02,  4.7745e-01,  9.4983e-01,\n",
            "           2.2747e-01,  4.4722e-02,  6.5212e-01,  8.4918e-01,  3.1266e-01],\n",
            "         [ 1.4793e-01, -1.0287e+00,  1.0059e-01,  4.1014e-01,  9.9414e-01,\n",
            "           2.2290e-01,  7.5669e-02,  6.2143e-01,  8.2631e-01,  2.8005e-01],\n",
            "         [-4.9906e-02, -1.5172e-01,  2.0960e-01,  3.4577e-01,  1.0662e+00,\n",
            "           2.1433e-01,  1.4540e-01,  5.4666e-01,  7.6965e-01,  2.0054e-01]],\n",
            "\n",
            "        [[ 9.4552e-01,  5.0265e-02, -5.9393e-01,  9.7792e-01,  1.3420e+00,\n",
            "           1.7323e-01,  6.8594e-01, -8.9889e-02,  2.7810e-01, -4.7724e-01],\n",
            "         [ 1.7959e+00, -5.3531e-01, -4.5848e-01,  1.0472e+00,  1.4652e+00,\n",
            "           1.6093e-01,  8.2708e-01, -2.4573e-01,  1.5921e-01, -6.4311e-01],\n",
            "         [ 1.8680e+00, -1.5521e+00, -3.1534e-01,  1.0491e+00,  1.5374e+00,\n",
            "           1.5424e-01,  8.9681e-01, -3.2045e-01,  1.0255e-01, -7.2262e-01],\n",
            "         [ 1.1016e+00, -2.1507e+00, -1.7368e-01,  1.0041e+00,  1.5818e+00,\n",
            "           1.5031e-01,  9.2775e-01, -3.5112e-01,  7.9677e-02, -7.5523e-01],\n",
            "         [ 2.0436e-01, -1.8238e+00, -4.0786e-02,  9.2687e-01,  1.6142e+00,\n",
            "           1.4720e-01,  9.4208e-01, -3.6293e-01,  7.1293e-02, -7.6774e-01],\n",
            "         [ 2.4896e-03, -8.9008e-01,  7.8319e-02,  8.2559e-01,  1.6419e+00,\n",
            "           1.4403e-01,  9.4993e-01, -3.6740e-01,  6.8556e-02, -7.7242e-01]],\n",
            "\n",
            "        [[ 9.5445e-01, -7.5611e-02, -6.1631e-01,  1.0597e+00,  1.4401e+00,\n",
            "           1.6124e-01,  8.2310e-01, -2.4572e-01,  1.5858e-01, -6.4311e-01],\n",
            "         [ 1.8002e+00, -5.9565e-01, -4.6921e-01,  1.0864e+00,  1.5123e+00,\n",
            "           1.5518e-01,  8.9283e-01, -3.2042e-01,  1.0191e-01, -7.2262e-01],\n",
            "         [ 1.8698e+00, -1.5768e+00, -3.1974e-01,  1.0652e+00,  1.5567e+00,\n",
            "           1.5188e-01,  9.2377e-01, -3.5108e-01,  7.9046e-02, -7.5523e-01],\n",
            "         [ 1.1023e+00, -2.1602e+00, -1.7537e-01,  1.0103e+00,  1.5892e+00,\n",
            "           1.4940e-01,  9.3810e-01, -3.6288e-01,  7.0663e-02, -7.6774e-01],\n",
            "         [ 2.0461e-01, -1.8274e+00, -4.1417e-02,  9.2918e-01,  1.6170e+00,\n",
            "           1.4686e-01,  9.4595e-01, -3.6732e-01,  6.7925e-02, -7.7242e-01],\n",
            "         [ 2.5827e-03, -8.9139e-01,  7.8085e-02,  8.2645e-01,  1.6429e+00,\n",
            "           1.4390e-01,  9.5136e-01, -3.6902e-01,  6.7309e-02, -7.7415e-01]],\n",
            "\n",
            "        [[ 9.0192e-01,  6.6472e-01, -4.8467e-01,  5.7861e-01,  8.6283e-01,\n",
            "           2.3173e-01,  1.6417e-02,  6.7078e-01,  8.6155e-01,  3.3245e-01],\n",
            "         [ 1.7434e+00,  2.0484e-01, -3.2688e-01,  5.6619e-01,  8.8809e-01,\n",
            "           2.3140e-01,  2.0592e-02,  6.7055e-01,  8.6201e-01,  3.3222e-01],\n",
            "         [ 1.8113e+00, -7.5209e-01, -1.7310e-01,  5.2922e-01,  9.1356e-01,\n",
            "           2.3041e-01,  2.5100e-02,  6.6993e-01,  8.6218e-01,  3.3158e-01],\n",
            "         [ 1.0432e+00, -1.3272e+00, -2.7271e-02,  4.6897e-01,  9.3966e-01,\n",
            "           2.2871e-01,  3.0512e-02,  6.6826e-01,  8.6156e-01,  3.2985e-01],\n",
            "         [ 1.4550e-01, -9.9445e-01,  1.0668e-01,  3.8789e-01,  9.6744e-01,\n",
            "           2.2616e-01,  3.8358e-02,  6.6382e-01,  8.5883e-01,  3.2517e-01],\n",
            "         [-5.5944e-02, -6.6636e-02,  2.2473e-01,  2.9047e-01,  9.9980e-01,\n",
            "           2.2243e-01,  5.2683e-02,  6.5199e-01,  8.5044e-01,  3.1266e-01]],\n",
            "\n",
            "        [[ 9.1795e-01,  4.3874e-01, -5.2485e-01,  7.2546e-01,  1.0390e+00,\n",
            "           2.1022e-01,  2.6265e-01,  3.9103e-01,  6.4697e-01,  3.4670e-02],\n",
            "         [ 1.7732e+00, -2.1520e-01, -4.0156e-01,  8.3916e-01,  1.2156e+00,\n",
            "           1.9141e-01,  4.7828e-01,  1.5056e-01,  4.6317e-01, -2.2128e-01],\n",
            "         [ 1.8548e+00, -1.3659e+00, -2.8223e-01,  9.2810e-01,  1.3922e+00,\n",
            "           1.7197e-01,  6.9390e-01, -8.9921e-02,  2.7936e-01, -4.7724e-01],\n",
            "         [ 1.0956e+00, -2.0656e+00, -1.5855e-01,  9.4880e-01,  1.5154e+00,\n",
            "           1.5841e-01,  8.3504e-01, -2.4579e-01,  1.6047e-01, -6.4311e-01],\n",
            "         [ 2.0193e-01, -1.7896e+00, -3.4698e-02,  9.0462e-01,  1.5875e+00,\n",
            "           1.5046e-01,  9.0477e-01, -3.2054e-01,  1.0381e-01, -7.2262e-01],\n",
            "         [ 1.5641e-03, -8.7704e-01,  8.0637e-02,  8.1712e-01,  1.6317e+00,\n",
            "           1.4527e-01,  9.3572e-01, -3.5125e-01,  8.0939e-02, -7.5523e-01]],\n",
            "\n",
            "        [[ 9.0192e-01,  6.6472e-01, -4.8467e-01,  5.7861e-01,  8.6283e-01,\n",
            "           2.3173e-01,  1.6417e-02,  6.7078e-01,  8.6155e-01,  3.3245e-01],\n",
            "         [ 1.7434e+00,  2.0484e-01, -3.2688e-01,  5.6619e-01,  8.8809e-01,\n",
            "           2.3140e-01,  2.0592e-02,  6.7055e-01,  8.6201e-01,  3.3222e-01],\n",
            "         [ 1.8113e+00, -7.5209e-01, -1.7310e-01,  5.2922e-01,  9.1356e-01,\n",
            "           2.3041e-01,  2.5100e-02,  6.6993e-01,  8.6218e-01,  3.3158e-01],\n",
            "         [ 1.0432e+00, -1.3272e+00, -2.7271e-02,  4.6897e-01,  9.3966e-01,\n",
            "           2.2871e-01,  3.0512e-02,  6.6826e-01,  8.6156e-01,  3.2985e-01],\n",
            "         [ 1.4550e-01, -9.9445e-01,  1.0668e-01,  3.8789e-01,  9.6744e-01,\n",
            "           2.2616e-01,  3.8358e-02,  6.6382e-01,  8.5883e-01,  3.2517e-01],\n",
            "         [-5.5944e-02, -6.6636e-02,  2.2473e-01,  2.9047e-01,  9.9980e-01,\n",
            "           2.2243e-01,  5.2683e-02,  6.5199e-01,  8.5044e-01,  3.1266e-01]],\n",
            "\n",
            "        [[ 9.0902e-01,  5.6461e-01, -5.0247e-01,  6.4366e-01,  9.4089e-01,\n",
            "           2.2220e-01,  1.2549e-01,  5.4686e-01,  7.6649e-01,  2.0054e-01],\n",
            "         [ 1.7594e+00, -2.0959e-02, -3.6703e-01,  7.1293e-01,  1.0642e+00,\n",
            "           2.0990e-01,  2.6663e-01,  3.9102e-01,  6.4760e-01,  3.4670e-02],\n",
            "         [ 1.8410e+00, -1.1716e+00, -2.4769e-01,  8.0187e-01,  1.2407e+00,\n",
            "           1.9046e-01,  4.8226e-01,  1.5054e-01,  4.6380e-01, -2.2128e-01],\n",
            "         [ 1.0866e+00, -1.9397e+00, -1.3617e-01,  8.6700e-01,  1.4173e+00,\n",
            "           1.7039e-01,  6.9788e-01, -8.9961e-02,  2.7999e-01, -4.7724e-01],\n",
            "         [ 1.9765e-01, -1.7293e+00, -2.3969e-02,  8.6541e-01,  1.5404e+00,\n",
            "           1.5620e-01,  8.3902e-01, -2.4585e-01,  1.6110e-01, -6.4311e-01],\n",
            "         [-1.9211e-04, -8.5229e-01,  8.5038e-02,  8.0104e-01,  1.6124e+00,\n",
            "           1.4762e-01,  9.0875e-01, -3.2061e-01,  1.0444e-01, -7.2262e-01]],\n",
            "\n",
            "        [[ 9.3173e-01,  2.4450e-01, -5.5939e-01,  8.5169e-01,  1.1905e+00,\n",
            "           1.9172e-01,  4.7430e-01,  1.5057e-01,  4.6254e-01, -2.2128e-01],\n",
            "         [ 1.7870e+00, -4.0943e-01, -4.3610e-01,  9.6538e-01,  1.3671e+00,\n",
            "           1.7291e-01,  6.8992e-01, -8.9897e-02,  2.7873e-01, -4.7724e-01],\n",
            "         [ 1.8637e+00, -1.4918e+00, -3.0461e-01,  1.0099e+00,  1.4903e+00,\n",
            "           1.5998e-01,  8.3106e-01, -2.4575e-01,  1.5984e-01, -6.4311e-01],\n",
            "         [ 1.0999e+00, -2.1259e+00, -1.6928e-01,  9.8801e-01,  1.5625e+00,\n",
            "           1.5266e-01,  9.0079e-01, -3.2049e-01,  1.0318e-01, -7.2262e-01],\n",
            "         [ 2.0369e-01, -1.8143e+00, -3.9098e-02,  9.2070e-01,  1.6068e+00,\n",
            "           1.4810e-01,  9.3173e-01, -3.5118e-01,  8.0308e-02, -7.5523e-01],\n",
            "         [ 2.2378e-03, -8.8653e-01,  7.8949e-02,  8.2329e-01,  1.6391e+00,\n",
            "           1.4436e-01,  9.4606e-01, -3.6300e-01,  7.1924e-02, -7.6774e-01]],\n",
            "\n",
            "        [[ 9.1795e-01,  4.3874e-01, -5.2485e-01,  7.2546e-01,  1.0390e+00,\n",
            "           2.1022e-01,  2.6265e-01,  3.9103e-01,  6.4697e-01,  3.4670e-02],\n",
            "         [ 1.7732e+00, -2.1520e-01, -4.0156e-01,  8.3916e-01,  1.2156e+00,\n",
            "           1.9141e-01,  4.7828e-01,  1.5056e-01,  4.6317e-01, -2.2128e-01],\n",
            "         [ 1.8548e+00, -1.3659e+00, -2.8223e-01,  9.2810e-01,  1.3922e+00,\n",
            "           1.7197e-01,  6.9390e-01, -8.9921e-02,  2.7936e-01, -4.7724e-01],\n",
            "         [ 1.0956e+00, -2.0656e+00, -1.5855e-01,  9.4880e-01,  1.5154e+00,\n",
            "           1.5841e-01,  8.3504e-01, -2.4579e-01,  1.6047e-01, -6.4311e-01],\n",
            "         [ 2.0193e-01, -1.7896e+00, -3.4698e-02,  9.0462e-01,  1.5875e+00,\n",
            "           1.5046e-01,  9.0477e-01, -3.2054e-01,  1.0381e-01, -7.2262e-01],\n",
            "         [ 1.5641e-03, -8.7704e-01,  8.0637e-02,  8.1712e-01,  1.6317e+00,\n",
            "           1.4527e-01,  9.3572e-01, -3.5125e-01,  8.0939e-02, -7.5523e-01]],\n",
            "\n",
            "        [[ 9.3173e-01,  2.4450e-01, -5.5939e-01,  8.5169e-01,  1.1905e+00,\n",
            "           1.9172e-01,  4.7430e-01,  1.5057e-01,  4.6254e-01, -2.2128e-01],\n",
            "         [ 1.7870e+00, -4.0943e-01, -4.3610e-01,  9.6538e-01,  1.3671e+00,\n",
            "           1.7291e-01,  6.8992e-01, -8.9897e-02,  2.7873e-01, -4.7724e-01],\n",
            "         [ 1.8637e+00, -1.4918e+00, -3.0461e-01,  1.0099e+00,  1.4903e+00,\n",
            "           1.5998e-01,  8.3106e-01, -2.4575e-01,  1.5984e-01, -6.4311e-01],\n",
            "         [ 1.0999e+00, -2.1259e+00, -1.6928e-01,  9.8801e-01,  1.5625e+00,\n",
            "           1.5266e-01,  9.0079e-01, -3.2049e-01,  1.0318e-01, -7.2262e-01],\n",
            "         [ 2.0369e-01, -1.8143e+00, -3.9098e-02,  9.2070e-01,  1.6068e+00,\n",
            "           1.4810e-01,  9.3173e-01, -3.5118e-01,  8.0308e-02, -7.5523e-01],\n",
            "         [ 2.2378e-03, -8.8653e-01,  7.8949e-02,  8.2329e-01,  1.6391e+00,\n",
            "           1.4436e-01,  9.4606e-01, -3.6300e-01,  7.1924e-02, -7.6774e-01]],\n",
            "\n",
            "        [[ 9.0191e-01,  6.6478e-01, -4.8466e-01,  5.7857e-01,  8.6278e-01,\n",
            "           2.3174e-01,  1.6345e-02,  6.7086e-01,  8.6161e-01,  3.3254e-01],\n",
            "         [ 1.7434e+00,  2.0502e-01, -3.2685e-01,  5.6608e-01,  8.8795e-01,\n",
            "           2.3142e-01,  2.0398e-02,  6.7077e-01,  8.6218e-01,  3.3245e-01],\n",
            "         [ 1.8112e+00, -7.5161e-01, -1.7301e-01,  5.2891e-01,  9.1319e-01,\n",
            "           2.3045e-01,  2.4573e-02,  6.7053e-01,  8.6264e-01,  3.3222e-01],\n",
            "         [ 1.0431e+00, -1.3259e+00, -2.7038e-02,  4.6812e-01,  9.3863e-01,\n",
            "           2.2883e-01,  2.9081e-02,  6.6989e-01,  8.6281e-01,  3.3158e-01],\n",
            "         [ 1.4525e-01, -9.9090e-01,  1.0731e-01,  3.8558e-01,  9.6468e-01,\n",
            "           2.2650e-01,  3.4492e-02,  6.6821e-01,  8.6219e-01,  3.2985e-01],\n",
            "         [-5.6617e-02, -5.7142e-02,  2.2642e-01,  2.8430e-01,  9.9240e-01,\n",
            "           2.2333e-01,  4.2338e-02,  6.6374e-01,  8.5946e-01,  3.2517e-01]],\n",
            "\n",
            "        [[ 9.0902e-01,  5.6461e-01, -5.0247e-01,  6.4366e-01,  9.4089e-01,\n",
            "           2.2220e-01,  1.2549e-01,  5.4686e-01,  7.6649e-01,  2.0054e-01],\n",
            "         [ 1.7594e+00, -2.0959e-02, -3.6703e-01,  7.1293e-01,  1.0642e+00,\n",
            "           2.0990e-01,  2.6663e-01,  3.9102e-01,  6.4760e-01,  3.4670e-02],\n",
            "         [ 1.8410e+00, -1.1716e+00, -2.4769e-01,  8.0187e-01,  1.2407e+00,\n",
            "           1.9046e-01,  4.8226e-01,  1.5054e-01,  4.6380e-01, -2.2128e-01],\n",
            "         [ 1.0866e+00, -1.9397e+00, -1.3617e-01,  8.6700e-01,  1.4173e+00,\n",
            "           1.7039e-01,  6.9788e-01, -8.9961e-02,  2.7999e-01, -4.7724e-01],\n",
            "         [ 1.9765e-01, -1.7293e+00, -2.3969e-02,  8.6541e-01,  1.5404e+00,\n",
            "           1.5620e-01,  8.3902e-01, -2.4585e-01,  1.6110e-01, -6.4311e-01],\n",
            "         [-1.9211e-04, -8.5229e-01,  8.5038e-02,  8.0104e-01,  1.6124e+00,\n",
            "           1.4762e-01,  9.0875e-01, -3.2061e-01,  1.0444e-01, -7.2262e-01]],\n",
            "\n",
            "        [[ 9.0206e-01,  6.6274e-01, -4.8503e-01,  5.7989e-01,  8.6437e-01,\n",
            "           2.3154e-01,  1.8569e-02,  6.6833e-01,  8.5967e-01,  3.2985e-01],\n",
            "         [ 1.7438e+00,  1.9950e-01, -3.2783e-01,  5.6966e-01,  8.9225e-01,\n",
            "           2.3089e-01,  2.6415e-02,  6.6393e-01,  8.5693e-01,  3.2517e-01],\n",
            "         [ 1.8123e+00, -7.6645e-01, -1.7565e-01,  5.3855e-01,  9.2476e-01,\n",
            "           2.2904e-01,  4.0741e-02,  6.5216e-01,  8.4855e-01,  3.1266e-01],\n",
            "         [ 1.0459e+00, -1.3650e+00, -3.3990e-02,  4.9353e-01,  9.6912e-01,\n",
            "           2.2511e-01,  7.1688e-02,  6.2148e-01,  8.2568e-01,  2.8005e-01],\n",
            "         [ 1.5222e-01, -1.0890e+00,  8.9864e-02,  4.4935e-01,  1.0412e+00,\n",
            "           2.1716e-01,  1.4142e-01,  5.4673e-01,  7.6902e-01,  2.0054e-01],\n",
            "         [-4.0973e-02, -2.7760e-01,  1.8722e-01,  4.2757e-01,  1.1643e+00,\n",
            "           2.0234e-01,  2.8255e-01,  3.9083e-01,  6.5013e-01,  3.4665e-02]],\n",
            "\n",
            "        [[ 9.3173e-01,  2.4450e-01, -5.5939e-01,  8.5169e-01,  1.1905e+00,\n",
            "           1.9172e-01,  4.7430e-01,  1.5057e-01,  4.6254e-01, -2.2128e-01],\n",
            "         [ 1.7870e+00, -4.0943e-01, -4.3610e-01,  9.6538e-01,  1.3671e+00,\n",
            "           1.7291e-01,  6.8992e-01, -8.9897e-02,  2.7873e-01, -4.7724e-01],\n",
            "         [ 1.8637e+00, -1.4918e+00, -3.0461e-01,  1.0099e+00,  1.4903e+00,\n",
            "           1.5998e-01,  8.3106e-01, -2.4575e-01,  1.5984e-01, -6.4311e-01],\n",
            "         [ 1.0999e+00, -2.1259e+00, -1.6928e-01,  9.8801e-01,  1.5625e+00,\n",
            "           1.5266e-01,  9.0079e-01, -3.2049e-01,  1.0318e-01, -7.2262e-01],\n",
            "         [ 2.0369e-01, -1.8143e+00, -3.9098e-02,  9.2070e-01,  1.6068e+00,\n",
            "           1.4810e-01,  9.3173e-01, -3.5118e-01,  8.0308e-02, -7.5523e-01],\n",
            "         [ 2.2378e-03, -8.8653e-01,  7.8949e-02,  8.2329e-01,  1.6391e+00,\n",
            "           1.4436e-01,  9.4606e-01, -3.6300e-01,  7.1924e-02, -7.6774e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "t tensor([[ 0],\n",
            "        [ 7],\n",
            "        [10],\n",
            "        [ 7],\n",
            "        [ 9],\n",
            "        [ 1],\n",
            "        [ 4],\n",
            "        [ 6],\n",
            "        [ 0],\n",
            "        [ 5],\n",
            "        [ 8],\n",
            "        [ 5],\n",
            "        [ 9],\n",
            "        [ 0],\n",
            "        [ 9]], dtype=torch.int32)\n",
            "b before tensor([[-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4]])\n",
            "b after tensor([[-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [ -3,  -2,  -1,   0,   1,   2,   3],\n",
            "        [  0,   1,   2,   3,   4,   5,   6],\n",
            "        [ -3,  -2,  -1,   0,   1,   2,   3],\n",
            "        [ -1,   0,   1,   2,   3,   4,   5],\n",
            "        [ -9,  -8,  -7,  -6,  -5,  -4,  -3],\n",
            "        [ -6,  -5,  -4,  -3,  -2,  -1,   0],\n",
            "        [ -4,  -3,  -2,  -1,   0,   1,   2],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [ -5,  -4,  -3,  -2,  -1,   0,   1],\n",
            "        [ -2,  -1,   0,   1,   2,   3,   4],\n",
            "        [ -5,  -4,  -3,  -2,  -1,   0,   1],\n",
            "        [ -1,   0,   1,   2,   3,   4,   5],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [ -1,   0,   1,   2,   3,   4,   5]])\n",
            "s torch.Size([15, 7])\n",
            "---------\n",
            "after positional encoding shapetensor([[[ 9.0170e-01,  6.6513e-01, -4.8488e-01,  5.7855e-01,  8.6281e-01,\n",
            "           2.3211e-01,  1.6289e-02,  6.7083e-01,  8.6169e-01,  3.3242e-01],\n",
            "         [ 1.7432e+00,  2.0537e-01, -3.2707e-01,  5.6606e-01,  8.8797e-01,\n",
            "           2.3179e-01,  2.0342e-02,  6.7074e-01,  8.6226e-01,  3.3233e-01],\n",
            "         [ 1.8110e+00, -7.5126e-01, -1.7323e-01,  5.2889e-01,  9.1321e-01,\n",
            "           2.3083e-01,  2.4517e-02,  6.7049e-01,  8.6272e-01,  3.3210e-01],\n",
            "         [ 1.0429e+00, -1.3256e+00, -2.7256e-02,  4.6811e-01,  9.3866e-01,\n",
            "           2.2921e-01,  2.9025e-02,  6.6985e-01,  8.6290e-01,  3.3146e-01],\n",
            "         [ 1.4505e-01, -9.9055e-01,  1.0709e-01,  3.8557e-01,  9.6470e-01,\n",
            "           2.2688e-01,  3.4436e-02,  6.6817e-01,  8.6228e-01,  3.2973e-01],\n",
            "         [-5.6823e-02, -5.6792e-02,  2.2620e-01,  2.8429e-01,  9.9243e-01,\n",
            "           2.2370e-01,  4.2283e-02,  6.6371e-01,  8.5954e-01,  3.2505e-01]],\n",
            "\n",
            "        [[ 9.0454e-01,  6.2531e-01, -4.9196e-01,  6.0444e-01,  8.9387e-01,\n",
            "           2.2831e-01,  5.9691e-02,  6.2151e-01,  8.2388e-01,  2.7993e-01],\n",
            "         [ 1.7503e+00,  1.0529e-01, -3.4486e-01,  6.3113e-01,  9.6605e-01,\n",
            "           2.2223e-01,  1.2942e-01,  5.4680e-01,  7.6722e-01,  2.0042e-01],\n",
            "         [ 1.8271e+00, -9.7701e-01, -2.1336e-01,  6.7567e-01,  1.0893e+00,\n",
            "           2.0926e-01,  2.7057e-01,  3.9094e-01,  6.4833e-01,  3.4534e-02],\n",
            "         [ 1.0727e+00, -1.7451e+00, -1.0183e-01,  7.4083e-01,  1.2659e+00,\n",
            "           1.8913e-01,  4.8620e-01,  1.5043e-01,  4.6453e-01, -2.2144e-01],\n",
            "         [ 1.8860e-01, -1.6029e+00, -1.7707e-03,  7.8370e-01,  1.4424e+00,\n",
            "           1.6836e-01,  7.0183e-01, -9.0105e-02,  2.8074e-01, -4.7741e-01],\n",
            "         [-4.5690e-03, -7.9144e-01,  9.5591e-02,  7.6194e-01,  1.5656e+00,\n",
            "           1.5350e-01,  8.4298e-01, -2.4602e-01,  1.6185e-01, -6.4329e-01]],\n",
            "\n",
            "        [[ 9.3159e-01,  2.4494e-01, -5.5958e-01,  8.5175e-01,  1.1906e+00,\n",
            "           1.9196e-01,  4.7426e-01,  1.5050e-01,  4.6264e-01, -2.2143e-01],\n",
            "         [ 1.7869e+00, -4.0896e-01, -4.3628e-01,  9.6548e-01,  1.3672e+00,\n",
            "           1.7309e-01,  6.8989e-01, -8.9986e-02,  2.7885e-01, -4.7740e-01],\n",
            "         [ 1.8637e+00, -1.4913e+00, -3.0479e-01,  1.0100e+00,  1.4905e+00,\n",
            "           1.6012e-01,  8.3104e-01, -2.4585e-01,  1.5996e-01, -6.4329e-01],\n",
            "         [ 1.0998e+00, -2.1254e+00, -1.6945e-01,  9.8814e-01,  1.5626e+00,\n",
            "           1.5278e-01,  9.0077e-01, -3.2059e-01,  1.0330e-01, -7.2280e-01],\n",
            "         [ 2.0360e-01, -1.8138e+00, -3.9268e-02,  9.2084e-01,  1.6070e+00,\n",
            "           1.4821e-01,  9.3171e-01, -3.5129e-01,  8.0431e-02, -7.5542e-01],\n",
            "         [ 2.1569e-03, -8.8601e-01,  7.8780e-02,  8.2342e-01,  1.6393e+00,\n",
            "           1.4447e-01,  9.4604e-01, -3.6311e-01,  7.2048e-02, -7.6793e-01]],\n",
            "\n",
            "        [[ 9.0454e-01,  6.2531e-01, -4.9196e-01,  6.0444e-01,  8.9387e-01,\n",
            "           2.2831e-01,  5.9691e-02,  6.2151e-01,  8.2388e-01,  2.7993e-01],\n",
            "         [ 1.7503e+00,  1.0529e-01, -3.4486e-01,  6.3113e-01,  9.6605e-01,\n",
            "           2.2223e-01,  1.2942e-01,  5.4680e-01,  7.6722e-01,  2.0042e-01],\n",
            "         [ 1.8271e+00, -9.7701e-01, -2.1336e-01,  6.7567e-01,  1.0893e+00,\n",
            "           2.0926e-01,  2.7057e-01,  3.9094e-01,  6.4833e-01,  3.4534e-02],\n",
            "         [ 1.0727e+00, -1.7451e+00, -1.0183e-01,  7.4083e-01,  1.2659e+00,\n",
            "           1.8913e-01,  4.8620e-01,  1.5043e-01,  4.6453e-01, -2.2144e-01],\n",
            "         [ 1.8860e-01, -1.6029e+00, -1.7707e-03,  7.8370e-01,  1.4424e+00,\n",
            "           1.6836e-01,  7.0183e-01, -9.0105e-02,  2.8074e-01, -4.7741e-01],\n",
            "         [-4.5690e-03, -7.9144e-01,  9.5591e-02,  7.6194e-01,  1.5656e+00,\n",
            "           1.5350e-01,  8.4298e-01, -2.4602e-01,  1.6185e-01, -6.4329e-01]],\n",
            "\n",
            "        [[ 9.1778e-01,  4.3914e-01, -5.2506e-01,  7.2549e-01,  1.0391e+00,\n",
            "           2.1052e-01,  2.6260e-01,  3.9097e-01,  6.4707e-01,  3.4535e-02],\n",
            "         [ 1.7731e+00, -2.1476e-01, -4.0176e-01,  8.3922e-01,  1.2157e+00,\n",
            "           1.9165e-01,  4.7824e-01,  1.5049e-01,  4.6327e-01, -2.2143e-01],\n",
            "         [ 1.8547e+00, -1.3654e+00, -2.8241e-01,  9.2819e-01,  1.3923e+00,\n",
            "           1.7215e-01,  6.9387e-01, -9.0009e-02,  2.7948e-01, -4.7740e-01],\n",
            "         [ 1.0955e+00, -2.0651e+00, -1.5873e-01,  9.4891e-01,  1.5156e+00,\n",
            "           1.5854e-01,  8.3502e-01, -2.4589e-01,  1.6059e-01, -6.4329e-01],\n",
            "         [ 2.0184e-01, -1.7891e+00, -3.4869e-02,  9.0475e-01,  1.5877e+00,\n",
            "           1.5057e-01,  9.0475e-01, -3.2065e-01,  1.0393e-01, -7.2280e-01],\n",
            "         [ 1.4818e-03, -8.7651e-01,  8.0467e-02,  8.1725e-01,  1.6319e+00,\n",
            "           1.4538e-01,  9.3569e-01, -3.5136e-01,  8.1062e-02, -7.5542e-01]],\n",
            "\n",
            "        [[ 9.0171e-01,  6.6507e-01, -4.8489e-01,  5.7860e-01,  8.6286e-01,\n",
            "           2.3211e-01,  1.6361e-02,  6.7074e-01,  8.6163e-01,  3.3233e-01],\n",
            "         [ 1.7432e+00,  2.0519e-01, -3.2710e-01,  5.6618e-01,  8.8811e-01,\n",
            "           2.3177e-01,  2.0536e-02,  6.7052e-01,  8.6209e-01,  3.3210e-01],\n",
            "         [ 1.8111e+00, -7.5174e-01, -1.7331e-01,  5.2921e-01,  9.1359e-01,\n",
            "           2.3078e-01,  2.5044e-02,  6.6989e-01,  8.6226e-01,  3.3146e-01],\n",
            "         [ 1.0430e+00, -1.3269e+00, -2.7489e-02,  4.6896e-01,  9.3968e-01,\n",
            "           2.2908e-01,  3.0456e-02,  6.6823e-01,  8.6165e-01,  3.2973e-01],\n",
            "         [ 1.4530e-01, -9.9410e-01,  1.0646e-01,  3.8788e-01,  9.6747e-01,\n",
            "           2.2654e-01,  3.8302e-02,  6.6378e-01,  8.5891e-01,  3.2505e-01],\n",
            "         [-5.6148e-02, -6.6284e-02,  2.2451e-01,  2.9046e-01,  9.9983e-01,\n",
            "           2.2280e-01,  5.2627e-02,  6.5196e-01,  8.5053e-01,  3.1254e-01]],\n",
            "\n",
            "        [[ 9.0185e-01,  6.6309e-01, -4.8524e-01,  5.7988e-01,  8.6440e-01,\n",
            "           2.3192e-01,  1.8513e-02,  6.6830e-01,  8.5976e-01,  3.2973e-01],\n",
            "         [ 1.7436e+00,  1.9985e-01, -3.2805e-01,  5.6965e-01,  8.9228e-01,\n",
            "           2.3126e-01,  2.6360e-02,  6.6390e-01,  8.5702e-01,  3.2506e-01],\n",
            "         [ 1.8121e+00, -7.6609e-01, -1.7586e-01,  5.3854e-01,  9.2479e-01,\n",
            "           2.2941e-01,  4.0685e-02,  6.5212e-01,  8.4864e-01,  3.1255e-01],\n",
            "         [ 1.0457e+00, -1.3647e+00, -3.4206e-02,  4.9352e-01,  9.6916e-01,\n",
            "           2.2547e-01,  7.1634e-02,  6.2144e-01,  8.2577e-01,  2.7993e-01],\n",
            "         [ 1.5202e-01, -1.0887e+00,  8.9652e-02,  4.4936e-01,  1.0412e+00,\n",
            "           2.1750e-01,  1.4136e-01,  5.4669e-01,  7.6911e-01,  2.0041e-01],\n",
            "         [-4.1146e-02, -2.7720e-01,  1.8701e-01,  4.2760e-01,  1.1644e+00,\n",
            "           2.0264e-01,  2.8251e-01,  3.9077e-01,  6.5022e-01,  3.4530e-02]],\n",
            "\n",
            "        [[ 9.0278e-01,  6.5005e-01, -4.8756e-01,  5.8836e-01,  8.7457e-01,\n",
            "           2.3067e-01,  3.2723e-02,  6.5215e-01,  8.4737e-01,  3.1255e-01],\n",
            "         [ 1.7460e+00,  1.6561e-01, -3.3413e-01,  5.9191e-01,  9.1899e-01,\n",
            "           2.2799e-01,  6.3672e-02,  6.2151e-01,  8.2451e-01,  2.7993e-01],\n",
            "         [ 1.8181e+00, -8.5116e-01, -1.9099e-01,  5.9385e-01,  9.9115e-01,\n",
            "           2.2128e-01,  1.3340e-01,  5.4678e-01,  7.6785e-01,  2.0042e-01],\n",
            "         [ 1.0589e+00, -1.5509e+00, -6.7305e-02,  6.1457e-01,  1.1144e+00,\n",
            "           2.0768e-01,  2.7455e-01,  3.9090e-01,  6.4896e-01,  3.4533e-02],\n",
            "         [ 1.7479e-01, -1.4087e+00,  3.2754e-02,  6.5744e-01,  1.2909e+00,\n",
            "           1.8692e-01,  4.9018e-01,  1.5037e-01,  4.6516e-01, -2.2144e-01],\n",
            "         [-1.3520e-02, -6.6560e-01,  1.1796e-01,  6.8012e-01,  1.4674e+00,\n",
            "           1.6553e-01,  7.0581e-01, -9.0176e-02,  2.8137e-01, -4.7741e-01]],\n",
            "\n",
            "        [[ 9.0170e-01,  6.6513e-01, -4.8488e-01,  5.7855e-01,  8.6281e-01,\n",
            "           2.3211e-01,  1.6289e-02,  6.7083e-01,  8.6169e-01,  3.3242e-01],\n",
            "         [ 1.7432e+00,  2.0537e-01, -3.2707e-01,  5.6606e-01,  8.8797e-01,\n",
            "           2.3179e-01,  2.0342e-02,  6.7074e-01,  8.6226e-01,  3.3233e-01],\n",
            "         [ 1.8110e+00, -7.5126e-01, -1.7323e-01,  5.2889e-01,  9.1321e-01,\n",
            "           2.3083e-01,  2.4517e-02,  6.7049e-01,  8.6272e-01,  3.3210e-01],\n",
            "         [ 1.0429e+00, -1.3256e+00, -2.7256e-02,  4.6811e-01,  9.3866e-01,\n",
            "           2.2921e-01,  2.9025e-02,  6.6985e-01,  8.6290e-01,  3.3146e-01],\n",
            "         [ 1.4505e-01, -9.9055e-01,  1.0709e-01,  3.8557e-01,  9.6470e-01,\n",
            "           2.2688e-01,  3.4436e-02,  6.6817e-01,  8.6228e-01,  3.2973e-01],\n",
            "         [-5.6823e-02, -5.6792e-02,  2.2620e-01,  2.8429e-01,  9.9243e-01,\n",
            "           2.2370e-01,  4.2283e-02,  6.6371e-01,  8.5954e-01,  3.2505e-01]],\n",
            "\n",
            "        [[ 9.0210e-01,  6.5955e-01, -4.8587e-01,  5.8219e-01,  8.6716e-01,\n",
            "           2.3158e-01,  2.2378e-02,  6.6391e-01,  8.5639e-01,  3.2506e-01],\n",
            "         [ 1.7442e+00,  1.9036e-01, -3.2974e-01,  5.7582e-01,  8.9969e-01,\n",
            "           2.3036e-01,  3.6704e-02,  6.5215e-01,  8.4800e-01,  3.1255e-01],\n",
            "         [ 1.8138e+00, -7.9084e-01, -1.8026e-01,  5.5463e-01,  9.4409e-01,\n",
            "           2.2705e-01,  6.7653e-02,  6.2148e-01,  8.2514e-01,  2.7993e-01],\n",
            "         [ 1.0499e+00, -1.4250e+00, -4.4931e-02,  5.3275e-01,  1.0162e+00,\n",
            "           2.1971e-01,  1.3738e-01,  5.4674e-01,  7.6848e-01,  2.0042e-01],\n",
            "         [ 1.6098e-01, -1.2145e+00,  6.7279e-02,  5.3118e-01,  1.1394e+00,\n",
            "           2.0548e-01,  2.7853e-01,  3.9084e-01,  6.4959e-01,  3.4532e-02],\n",
            "         [-2.7333e-02, -4.7140e-01,  1.5249e-01,  5.5386e-01,  1.3159e+00,\n",
            "           1.8409e-01,  4.9416e-01,  1.5030e-01,  4.6580e-01, -2.2144e-01]],\n",
            "\n",
            "        [[ 9.0883e-01,  5.6499e-01, -5.0269e-01,  6.4367e-01,  9.4094e-01,\n",
            "           2.2254e-01,  1.2544e-01,  5.4681e-01,  7.6658e-01,  2.0042e-01],\n",
            "         [ 1.7592e+00, -2.0562e-02, -3.6723e-01,  7.1296e-01,  1.0642e+00,\n",
            "           2.1020e-01,  2.6658e-01,  3.9096e-01,  6.4770e-01,  3.4535e-02],\n",
            "         [ 1.8409e+00, -1.1712e+00, -2.4789e-01,  8.0193e-01,  1.2408e+00,\n",
            "           1.9070e-01,  4.8222e-01,  1.5047e-01,  4.6390e-01, -2.2143e-01],\n",
            "         [ 1.0865e+00, -1.9392e+00, -1.3635e-01,  8.6709e-01,  1.4174e+00,\n",
            "           1.7057e-01,  6.9785e-01, -9.0049e-02,  2.8011e-01, -4.7740e-01],\n",
            "         [ 1.9755e-01, -1.7288e+00, -2.4145e-02,  8.6553e-01,  1.5406e+00,\n",
            "           1.5634e-01,  8.3900e-01, -2.4595e-01,  1.6122e-01, -6.4329e-01],\n",
            "         [-2.7812e-04, -8.5177e-01,  8.4866e-02,  8.0116e-01,  1.6126e+00,\n",
            "           1.4774e-01,  9.0873e-01, -3.2072e-01,  1.0456e-01, -7.2280e-01]],\n",
            "\n",
            "        [[ 9.0210e-01,  6.5955e-01, -4.8587e-01,  5.8219e-01,  8.6716e-01,\n",
            "           2.3158e-01,  2.2378e-02,  6.6391e-01,  8.5639e-01,  3.2506e-01],\n",
            "         [ 1.7442e+00,  1.9036e-01, -3.2974e-01,  5.7582e-01,  8.9969e-01,\n",
            "           2.3036e-01,  3.6704e-02,  6.5215e-01,  8.4800e-01,  3.1255e-01],\n",
            "         [ 1.8138e+00, -7.9084e-01, -1.8026e-01,  5.5463e-01,  9.4409e-01,\n",
            "           2.2705e-01,  6.7653e-02,  6.2148e-01,  8.2514e-01,  2.7993e-01],\n",
            "         [ 1.0499e+00, -1.4250e+00, -4.4931e-02,  5.3275e-01,  1.0162e+00,\n",
            "           2.1971e-01,  1.3738e-01,  5.4674e-01,  7.6848e-01,  2.0042e-01],\n",
            "         [ 1.6098e-01, -1.2145e+00,  6.7279e-02,  5.3118e-01,  1.1394e+00,\n",
            "           2.0548e-01,  2.7853e-01,  3.9084e-01,  6.4959e-01,  3.4532e-02],\n",
            "         [-2.7333e-02, -4.7140e-01,  1.5249e-01,  5.5386e-01,  1.3159e+00,\n",
            "           1.8409e-01,  4.9416e-01,  1.5030e-01,  4.6580e-01, -2.2144e-01]],\n",
            "\n",
            "        [[ 9.1778e-01,  4.3914e-01, -5.2506e-01,  7.2549e-01,  1.0391e+00,\n",
            "           2.1052e-01,  2.6260e-01,  3.9097e-01,  6.4707e-01,  3.4535e-02],\n",
            "         [ 1.7731e+00, -2.1476e-01, -4.0176e-01,  8.3922e-01,  1.2157e+00,\n",
            "           1.9165e-01,  4.7824e-01,  1.5049e-01,  4.6327e-01, -2.2143e-01],\n",
            "         [ 1.8547e+00, -1.3654e+00, -2.8241e-01,  9.2819e-01,  1.3923e+00,\n",
            "           1.7215e-01,  6.9387e-01, -9.0009e-02,  2.7948e-01, -4.7740e-01],\n",
            "         [ 1.0955e+00, -2.0651e+00, -1.5873e-01,  9.4891e-01,  1.5156e+00,\n",
            "           1.5854e-01,  8.3502e-01, -2.4589e-01,  1.6059e-01, -6.4329e-01],\n",
            "         [ 2.0184e-01, -1.7891e+00, -3.4869e-02,  9.0475e-01,  1.5877e+00,\n",
            "           1.5057e-01,  9.0475e-01, -3.2065e-01,  1.0393e-01, -7.2280e-01],\n",
            "         [ 1.4818e-03, -8.7651e-01,  8.0467e-02,  8.1725e-01,  1.6319e+00,\n",
            "           1.4538e-01,  9.3569e-01, -3.5136e-01,  8.1062e-02, -7.5542e-01]],\n",
            "\n",
            "        [[ 9.0170e-01,  6.6513e-01, -4.8488e-01,  5.7855e-01,  8.6281e-01,\n",
            "           2.3211e-01,  1.6289e-02,  6.7083e-01,  8.6169e-01,  3.3242e-01],\n",
            "         [ 1.7432e+00,  2.0537e-01, -3.2707e-01,  5.6606e-01,  8.8797e-01,\n",
            "           2.3179e-01,  2.0342e-02,  6.7074e-01,  8.6226e-01,  3.3233e-01],\n",
            "         [ 1.8110e+00, -7.5126e-01, -1.7323e-01,  5.2889e-01,  9.1321e-01,\n",
            "           2.3083e-01,  2.4517e-02,  6.7049e-01,  8.6272e-01,  3.3210e-01],\n",
            "         [ 1.0429e+00, -1.3256e+00, -2.7256e-02,  4.6811e-01,  9.3866e-01,\n",
            "           2.2921e-01,  2.9025e-02,  6.6985e-01,  8.6290e-01,  3.3146e-01],\n",
            "         [ 1.4505e-01, -9.9055e-01,  1.0709e-01,  3.8557e-01,  9.6470e-01,\n",
            "           2.2688e-01,  3.4436e-02,  6.6817e-01,  8.6228e-01,  3.2973e-01],\n",
            "         [-5.6823e-02, -5.6792e-02,  2.2620e-01,  2.8429e-01,  9.9243e-01,\n",
            "           2.2370e-01,  4.2283e-02,  6.6371e-01,  8.5954e-01,  3.2505e-01]],\n",
            "\n",
            "        [[ 9.1778e-01,  4.3914e-01, -5.2506e-01,  7.2549e-01,  1.0391e+00,\n",
            "           2.1052e-01,  2.6260e-01,  3.9097e-01,  6.4707e-01,  3.4535e-02],\n",
            "         [ 1.7731e+00, -2.1476e-01, -4.0176e-01,  8.3922e-01,  1.2157e+00,\n",
            "           1.9165e-01,  4.7824e-01,  1.5049e-01,  4.6327e-01, -2.2143e-01],\n",
            "         [ 1.8547e+00, -1.3654e+00, -2.8241e-01,  9.2819e-01,  1.3923e+00,\n",
            "           1.7215e-01,  6.9387e-01, -9.0009e-02,  2.7948e-01, -4.7740e-01],\n",
            "         [ 1.0955e+00, -2.0651e+00, -1.5873e-01,  9.4891e-01,  1.5156e+00,\n",
            "           1.5854e-01,  8.3502e-01, -2.4589e-01,  1.6059e-01, -6.4329e-01],\n",
            "         [ 2.0184e-01, -1.7891e+00, -3.4869e-02,  9.0475e-01,  1.5877e+00,\n",
            "           1.5057e-01,  9.0475e-01, -3.2065e-01,  1.0393e-01, -7.2280e-01],\n",
            "         [ 1.4818e-03, -8.7651e-01,  8.0467e-02,  8.1725e-01,  1.6319e+00,\n",
            "           1.4538e-01,  9.3569e-01, -3.5136e-01,  8.1062e-02, -7.5542e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "t tensor([[ 1],\n",
            "        [ 2],\n",
            "        [ 4],\n",
            "        [ 2],\n",
            "        [ 6],\n",
            "        [ 8],\n",
            "        [ 4],\n",
            "        [12],\n",
            "        [ 4],\n",
            "        [12],\n",
            "        [ 3],\n",
            "        [11],\n",
            "        [12],\n",
            "        [ 7],\n",
            "        [11]], dtype=torch.int32)\n",
            "b before tensor([[-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4]])\n",
            "b after tensor([[-9, -8, -7, -6, -5, -4, -3],\n",
            "        [-8, -7, -6, -5, -4, -3, -2],\n",
            "        [-6, -5, -4, -3, -2, -1,  0],\n",
            "        [-8, -7, -6, -5, -4, -3, -2],\n",
            "        [-4, -3, -2, -1,  0,  1,  2],\n",
            "        [-2, -1,  0,  1,  2,  3,  4],\n",
            "        [-6, -5, -4, -3, -2, -1,  0],\n",
            "        [ 2,  3,  4,  5,  6,  7,  8],\n",
            "        [-6, -5, -4, -3, -2, -1,  0],\n",
            "        [ 2,  3,  4,  5,  6,  7,  8],\n",
            "        [-7, -6, -5, -4, -3, -2, -1],\n",
            "        [ 1,  2,  3,  4,  5,  6,  7],\n",
            "        [ 2,  3,  4,  5,  6,  7,  8],\n",
            "        [-3, -2, -1,  0,  1,  2,  3],\n",
            "        [ 1,  2,  3,  4,  5,  6,  7]])\n",
            "s torch.Size([15, 7])\n",
            "---------\n",
            "after positional encoding shapetensor([[[ 9.0145e-01,  6.6539e-01, -4.8518e-01,  5.7853e-01,  8.6281e-01,\n",
            "           2.3259e-01,  1.6308e-02,  6.7078e-01,  8.6170e-01,  3.3221e-01],\n",
            "         [ 1.7429e+00,  2.0552e-01, -3.2738e-01,  5.6611e-01,  8.8806e-01,\n",
            "           2.3226e-01,  2.0484e-02,  6.7055e-01,  8.6216e-01,  3.3197e-01],\n",
            "         [ 1.8108e+00, -7.5142e-01, -1.7360e-01,  5.2914e-01,  9.1354e-01,\n",
            "           2.3127e-01,  2.4992e-02,  6.6993e-01,  8.6234e-01,  3.3134e-01],\n",
            "         [ 1.0427e+00, -1.3266e+00, -2.7773e-02,  4.6889e-01,  9.3963e-01,\n",
            "           2.2957e-01,  3.0403e-02,  6.6827e-01,  8.6172e-01,  3.2960e-01],\n",
            "         [ 1.4504e-01, -9.9377e-01,  1.0618e-01,  3.8781e-01,  9.6742e-01,\n",
            "           2.2702e-01,  3.8250e-02,  6.6382e-01,  8.5898e-01,  3.2493e-01],\n",
            "         [-5.6406e-02, -6.5954e-02,  2.2423e-01,  2.9040e-01,  9.9979e-01,\n",
            "           2.2328e-01,  5.2576e-02,  6.5199e-01,  8.5060e-01,  3.1241e-01]],\n",
            "\n",
            "        [[ 9.0146e-01,  6.6522e-01, -4.8521e-01,  5.7864e-01,  8.6295e-01,\n",
            "           2.3258e-01,  1.6503e-02,  6.7056e-01,  8.6153e-01,  3.3197e-01],\n",
            "         [ 1.7430e+00,  2.0503e-01, -3.2747e-01,  5.6643e-01,  8.8844e-01,\n",
            "           2.3221e-01,  2.1011e-02,  6.6996e-01,  8.6170e-01,  3.3134e-01],\n",
            "         [ 1.8109e+00, -7.5273e-01, -1.7383e-01,  5.2999e-01,  9.1456e-01,\n",
            "           2.3114e-01,  2.6422e-02,  6.6831e-01,  8.6109e-01,  3.2961e-01],\n",
            "         [ 1.0430e+00, -1.3301e+00, -2.8403e-02,  4.7120e-01,  9.4240e-01,\n",
            "           2.2923e-01,  3.4269e-02,  6.6387e-01,  8.5835e-01,  3.2493e-01],\n",
            "         [ 1.4572e-01, -1.0033e+00,  1.0449e-01,  3.9398e-01,  9.7483e-01,\n",
            "           2.2611e-01,  4.8595e-02,  6.5206e-01,  8.4997e-01,  3.1242e-01],\n",
            "         [-5.4642e-02, -9.0692e-02,  2.1983e-01,  3.0649e-01,  1.0191e+00,\n",
            "           2.2091e-01,  7.9544e-02,  6.2135e-01,  8.2710e-01,  2.7980e-01]],\n",
            "\n",
            "        [[ 9.0159e-01,  6.6342e-01, -4.8553e-01,  5.7981e-01,  8.6435e-01,\n",
            "           2.3240e-01,  1.8460e-02,  6.6834e-01,  8.5983e-01,  3.2961e-01],\n",
            "         [ 1.7433e+00,  2.0018e-01, -3.2833e-01,  5.6959e-01,  8.9223e-01,\n",
            "           2.3175e-01,  2.6307e-02,  6.6394e-01,  8.5709e-01,  3.2493e-01],\n",
            "         [ 1.8118e+00, -7.6576e-01, -1.7615e-01,  5.3847e-01,  9.2474e-01,\n",
            "           2.2989e-01,  4.0634e-02,  6.5216e-01,  8.4871e-01,  3.1242e-01],\n",
            "         [ 1.0454e+00, -1.3643e+00, -3.4488e-02,  4.9346e-01,  9.6912e-01,\n",
            "           2.2594e-01,  7.1583e-02,  6.2148e-01,  8.2584e-01,  2.7980e-01],\n",
            "         [ 1.5178e-01, -1.0883e+00,  8.9374e-02,  4.4931e-01,  1.0412e+00,\n",
            "           2.1796e-01,  1.4132e-01,  5.4672e-01,  7.6918e-01,  2.0028e-01],\n",
            "         [-4.1373e-02, -2.7683e-01,  1.8674e-01,  4.2757e-01,  1.1644e+00,\n",
            "           2.0306e-01,  2.8246e-01,  3.9079e-01,  6.5030e-01,  3.4387e-02]],\n",
            "\n",
            "        [[ 9.0146e-01,  6.6522e-01, -4.8521e-01,  5.7864e-01,  8.6295e-01,\n",
            "           2.3258e-01,  1.6503e-02,  6.7056e-01,  8.6153e-01,  3.3197e-01],\n",
            "         [ 1.7430e+00,  2.0503e-01, -3.2747e-01,  5.6643e-01,  8.8844e-01,\n",
            "           2.3221e-01,  2.1011e-02,  6.6996e-01,  8.6170e-01,  3.3134e-01],\n",
            "         [ 1.8109e+00, -7.5273e-01, -1.7383e-01,  5.2999e-01,  9.1456e-01,\n",
            "           2.3114e-01,  2.6422e-02,  6.6831e-01,  8.6109e-01,  3.2961e-01],\n",
            "         [ 1.0430e+00, -1.3301e+00, -2.8403e-02,  4.7120e-01,  9.4240e-01,\n",
            "           2.2923e-01,  3.4269e-02,  6.6387e-01,  8.5835e-01,  3.2493e-01],\n",
            "         [ 1.4572e-01, -1.0033e+00,  1.0449e-01,  3.9398e-01,  9.7483e-01,\n",
            "           2.2611e-01,  4.8595e-02,  6.5206e-01,  8.4997e-01,  3.1242e-01],\n",
            "         [-5.4642e-02, -9.0692e-02,  2.1983e-01,  3.0649e-01,  1.0191e+00,\n",
            "           2.2091e-01,  7.9544e-02,  6.2135e-01,  8.2710e-01,  2.7980e-01]],\n",
            "\n",
            "        [[ 9.0252e-01,  6.5038e-01, -4.8784e-01,  5.8829e-01,  8.7452e-01,\n",
            "           2.3115e-01,  3.2672e-02,  6.5219e-01,  8.4745e-01,  3.1242e-01],\n",
            "         [ 1.7458e+00,  1.6595e-01, -3.3442e-01,  5.9185e-01,  9.1895e-01,\n",
            "           2.2847e-01,  6.3621e-02,  6.2154e-01,  8.2458e-01,  2.7980e-01],\n",
            "         [ 1.8179e+00, -8.5081e-01, -1.9127e-01,  5.9380e-01,  9.9112e-01,\n",
            "           2.2174e-01,  1.3335e-01,  5.4681e-01,  7.6792e-01,  2.0028e-01],\n",
            "         [ 1.0587e+00, -1.5505e+00, -6.7576e-02,  6.1454e-01,  1.1144e+00,\n",
            "           2.0810e-01,  2.7450e-01,  3.9092e-01,  6.4904e-01,  3.4390e-02],\n",
            "         [ 1.7459e-01, -1.4083e+00,  3.2493e-02,  6.5745e-01,  1.2910e+00,\n",
            "           1.8727e-01,  4.9015e-01,  1.5037e-01,  4.6526e-01, -2.2160e-01],\n",
            "         [-1.3691e-02, -6.6514e-01,  1.1771e-01,  6.8016e-01,  1.4674e+00,\n",
            "           1.6582e-01,  7.0579e-01, -9.0192e-02,  2.8147e-01, -4.7758e-01]],\n",
            "\n",
            "        [[ 9.0858e-01,  5.6533e-01, -5.0296e-01,  6.4362e-01,  9.4090e-01,\n",
            "           2.2300e-01,  1.2539e-01,  5.4684e-01,  7.6666e-01,  2.0028e-01],\n",
            "         [ 1.7590e+00, -2.0187e-02, -3.6750e-01,  7.1293e-01,  1.0642e+00,\n",
            "           2.1062e-01,  2.6654e-01,  3.9098e-01,  6.4778e-01,  3.4391e-02],\n",
            "         [ 1.8407e+00, -1.1708e+00, -2.4815e-01,  8.0194e-01,  1.2409e+00,\n",
            "           1.9105e-01,  4.8219e-01,  1.5047e-01,  4.6399e-01, -2.2159e-01],\n",
            "         [ 1.0864e+00, -1.9388e+00, -1.3660e-01,  8.6713e-01,  1.4175e+00,\n",
            "           1.7086e-01,  6.9783e-01, -9.0066e-02,  2.8021e-01, -4.7758e-01],\n",
            "         [ 1.9740e-01, -1.7283e+00, -2.4389e-02,  8.6559e-01,  1.5407e+00,\n",
            "           1.5659e-01,  8.3898e-01, -2.4597e-01,  1.6133e-01, -6.4347e-01],\n",
            "         [-4.2206e-04, -8.5127e-01,  8.4625e-02,  8.0123e-01,  1.6127e+00,\n",
            "           1.4797e-01,  9.0871e-01, -3.2075e-01,  1.0467e-01, -7.2300e-01]],\n",
            "\n",
            "        [[ 9.0159e-01,  6.6342e-01, -4.8553e-01,  5.7981e-01,  8.6435e-01,\n",
            "           2.3240e-01,  1.8460e-02,  6.6834e-01,  8.5983e-01,  3.2961e-01],\n",
            "         [ 1.7433e+00,  2.0018e-01, -3.2833e-01,  5.6959e-01,  8.9223e-01,\n",
            "           2.3175e-01,  2.6307e-02,  6.6394e-01,  8.5709e-01,  3.2493e-01],\n",
            "         [ 1.8118e+00, -7.6576e-01, -1.7615e-01,  5.3847e-01,  9.2474e-01,\n",
            "           2.2989e-01,  4.0634e-02,  6.5216e-01,  8.4871e-01,  3.1242e-01],\n",
            "         [ 1.0454e+00, -1.3643e+00, -3.4488e-02,  4.9346e-01,  9.6912e-01,\n",
            "           2.2594e-01,  7.1583e-02,  6.2148e-01,  8.2584e-01,  2.7980e-01],\n",
            "         [ 1.5178e-01, -1.0883e+00,  8.9374e-02,  4.4931e-01,  1.0412e+00,\n",
            "           2.1796e-01,  1.4132e-01,  5.4672e-01,  7.6918e-01,  2.0028e-01],\n",
            "         [-4.1373e-02, -2.7683e-01,  1.8674e-01,  4.2757e-01,  1.1644e+00,\n",
            "           2.0306e-01,  2.8246e-01,  3.9079e-01,  6.5030e-01,  3.4387e-02]],\n",
            "\n",
            "        [[ 9.5420e-01, -7.4620e-02, -6.1673e-01,  1.0599e+00,  1.4404e+00,\n",
            "           1.6163e-01,  8.2305e-01, -2.4585e-01,  1.5881e-01, -6.4347e-01],\n",
            "         [ 1.8000e+00, -5.9463e-01, -4.6962e-01,  1.0866e+00,  1.5126e+00,\n",
            "           1.5553e-01,  8.9279e-01, -3.2056e-01,  1.0215e-01, -7.2299e-01],\n",
            "         [ 1.8696e+00, -1.5758e+00, -3.2015e-01,  1.0654e+00,  1.5570e+00,\n",
            "           1.5221e-01,  9.2374e-01, -3.5123e-01,  7.9282e-02, -7.5561e-01],\n",
            "         [ 1.1021e+00, -2.1592e+00, -1.7578e-01,  1.0105e+00,  1.5895e+00,\n",
            "           1.4973e-01,  9.3806e-01, -3.6302e-01,  7.0900e-02, -7.6812e-01],\n",
            "         [ 2.0439e-01, -1.8263e+00, -4.1825e-02,  9.2939e-01,  1.6173e+00,\n",
            "           1.4718e-01,  9.4591e-01, -3.6747e-01,  6.8162e-02, -7.7280e-01],\n",
            "         [ 2.3643e-03, -8.9036e-01,  7.7677e-02,  8.2666e-01,  1.6432e+00,\n",
            "           1.4422e-01,  9.5132e-01, -3.6917e-01,  6.7547e-02, -7.7453e-01]],\n",
            "\n",
            "        [[ 9.0159e-01,  6.6342e-01, -4.8553e-01,  5.7981e-01,  8.6435e-01,\n",
            "           2.3240e-01,  1.8460e-02,  6.6834e-01,  8.5983e-01,  3.2961e-01],\n",
            "         [ 1.7433e+00,  2.0018e-01, -3.2833e-01,  5.6959e-01,  8.9223e-01,\n",
            "           2.3175e-01,  2.6307e-02,  6.6394e-01,  8.5709e-01,  3.2493e-01],\n",
            "         [ 1.8118e+00, -7.6576e-01, -1.7615e-01,  5.3847e-01,  9.2474e-01,\n",
            "           2.2989e-01,  4.0634e-02,  6.5216e-01,  8.4871e-01,  3.1242e-01],\n",
            "         [ 1.0454e+00, -1.3643e+00, -3.4488e-02,  4.9346e-01,  9.6912e-01,\n",
            "           2.2594e-01,  7.1583e-02,  6.2148e-01,  8.2584e-01,  2.7980e-01],\n",
            "         [ 1.5178e-01, -1.0883e+00,  8.9374e-02,  4.4931e-01,  1.0412e+00,\n",
            "           2.1796e-01,  1.4132e-01,  5.4672e-01,  7.6918e-01,  2.0028e-01],\n",
            "         [-4.1373e-02, -2.7683e-01,  1.8674e-01,  4.2757e-01,  1.1644e+00,\n",
            "           2.0306e-01,  2.8246e-01,  3.9079e-01,  6.5030e-01,  3.4387e-02]],\n",
            "\n",
            "        [[ 9.5420e-01, -7.4620e-02, -6.1673e-01,  1.0599e+00,  1.4404e+00,\n",
            "           1.6163e-01,  8.2305e-01, -2.4585e-01,  1.5881e-01, -6.4347e-01],\n",
            "         [ 1.8000e+00, -5.9463e-01, -4.6962e-01,  1.0866e+00,  1.5126e+00,\n",
            "           1.5553e-01,  8.9279e-01, -3.2056e-01,  1.0215e-01, -7.2299e-01],\n",
            "         [ 1.8696e+00, -1.5758e+00, -3.2015e-01,  1.0654e+00,  1.5570e+00,\n",
            "           1.5221e-01,  9.2374e-01, -3.5123e-01,  7.9282e-02, -7.5561e-01],\n",
            "         [ 1.1021e+00, -2.1592e+00, -1.7578e-01,  1.0105e+00,  1.5895e+00,\n",
            "           1.4973e-01,  9.3806e-01, -3.6302e-01,  7.0900e-02, -7.6812e-01],\n",
            "         [ 2.0439e-01, -1.8263e+00, -4.1825e-02,  9.2939e-01,  1.6173e+00,\n",
            "           1.4718e-01,  9.4591e-01, -3.6747e-01,  6.8162e-02, -7.7280e-01],\n",
            "         [ 2.3643e-03, -8.9036e-01,  7.7677e-02,  8.2666e-01,  1.6432e+00,\n",
            "           1.4422e-01,  9.5132e-01, -3.6917e-01,  6.7547e-02, -7.7453e-01]],\n",
            "\n",
            "        [[ 9.0150e-01,  6.6473e-01, -4.8529e-01,  5.7896e-01,  8.6332e-01,\n",
            "           2.3253e-01,  1.7030e-02,  6.6996e-01,  8.6107e-01,  3.3134e-01],\n",
            "         [ 1.7431e+00,  2.0372e-01, -3.2770e-01,  5.6728e-01,  8.8946e-01,\n",
            "           2.3209e-01,  2.2441e-02,  6.6833e-01,  8.6046e-01,  3.2961e-01],\n",
            "         [ 1.8111e+00, -7.5627e-01, -1.7446e-01,  5.3230e-01,  9.1733e-01,\n",
            "           2.3080e-01,  3.0288e-02,  6.6391e-01,  8.5772e-01,  3.2493e-01],\n",
            "         [ 1.0436e+00, -1.3396e+00, -3.0090e-02,  4.7737e-01,  9.4981e-01,\n",
            "           2.2832e-01,  4.4615e-02,  6.5212e-01,  8.4934e-01,  3.1242e-01],\n",
            "         [ 1.4748e-01, -1.0280e+00,  1.0010e-01,  4.1007e-01,  9.9414e-01,\n",
            "           2.2374e-01,  7.5564e-02,  6.2142e-01,  8.2647e-01,  2.7980e-01],\n",
            "         [-5.0343e-02, -1.5100e-01,  2.0911e-01,  3.4572e-01,  1.0662e+00,\n",
            "           2.1512e-01,  1.4530e-01,  5.4664e-01,  7.6982e-01,  2.0028e-01]],\n",
            "\n",
            "        [[ 9.4523e-01,  5.1202e-02, -5.9436e-01,  9.7805e-01,  1.3422e+00,\n",
            "           1.7370e-01,  6.8589e-01, -8.9994e-02,  2.7832e-01, -4.7758e-01],\n",
            "         [ 1.7957e+00, -5.3432e-01, -4.5890e-01,  1.0474e+00,  1.4655e+00,\n",
            "           1.6132e-01,  8.2704e-01, -2.4585e-01,  1.5944e-01, -6.4347e-01],\n",
            "         [ 1.8678e+00, -1.5511e+00, -3.1575e-01,  1.0493e+00,  1.5377e+00,\n",
            "           1.5459e-01,  8.9677e-01, -3.2059e-01,  1.0278e-01, -7.2299e-01],\n",
            "         [ 1.1014e+00, -2.1497e+00, -1.7409e-01,  1.0043e+00,  1.5821e+00,\n",
            "           1.5064e-01,  9.2772e-01, -3.5127e-01,  7.9913e-02, -7.5561e-01],\n",
            "         [ 2.0414e-01, -1.8228e+00, -4.1195e-02,  9.2708e-01,  1.6145e+00,\n",
            "           1.4752e-01,  9.4204e-01, -3.6308e-01,  7.1531e-02, -7.6812e-01],\n",
            "         [ 2.2707e-03, -8.8904e-01,  7.7910e-02,  8.2581e-01,  1.6422e+00,\n",
            "           1.4435e-01,  9.4989e-01, -3.6754e-01,  6.8793e-02, -7.7280e-01]],\n",
            "\n",
            "        [[ 9.5420e-01, -7.4620e-02, -6.1673e-01,  1.0599e+00,  1.4404e+00,\n",
            "           1.6163e-01,  8.2305e-01, -2.4585e-01,  1.5881e-01, -6.4347e-01],\n",
            "         [ 1.8000e+00, -5.9463e-01, -4.6962e-01,  1.0866e+00,  1.5126e+00,\n",
            "           1.5553e-01,  8.9279e-01, -3.2056e-01,  1.0215e-01, -7.2299e-01],\n",
            "         [ 1.8696e+00, -1.5758e+00, -3.2015e-01,  1.0654e+00,  1.5570e+00,\n",
            "           1.5221e-01,  9.2374e-01, -3.5123e-01,  7.9282e-02, -7.5561e-01],\n",
            "         [ 1.1021e+00, -2.1592e+00, -1.7578e-01,  1.0105e+00,  1.5895e+00,\n",
            "           1.4973e-01,  9.3806e-01, -3.6302e-01,  7.0900e-02, -7.6812e-01],\n",
            "         [ 2.0439e-01, -1.8263e+00, -4.1825e-02,  9.2939e-01,  1.6173e+00,\n",
            "           1.4718e-01,  9.4591e-01, -3.6747e-01,  6.8162e-02, -7.7280e-01],\n",
            "         [ 2.3643e-03, -8.9036e-01,  7.7677e-02,  8.2666e-01,  1.6432e+00,\n",
            "           1.4422e-01,  9.5132e-01, -3.6917e-01,  6.7547e-02, -7.7453e-01]],\n",
            "\n",
            "        [[ 9.0428e-01,  6.2565e-01, -4.9224e-01,  6.0438e-01,  8.9383e-01,\n",
            "           2.2878e-01,  5.9640e-02,  6.2155e-01,  8.2395e-01,  2.7980e-01],\n",
            "         [ 1.7501e+00,  1.0564e-01, -3.4514e-01,  6.3108e-01,  9.6602e-01,\n",
            "           2.2268e-01,  1.2937e-01,  5.4683e-01,  7.6729e-01,  2.0028e-01],\n",
            "         [ 1.8268e+00, -9.7664e-01, -2.1363e-01,  6.7564e-01,  1.0893e+00,\n",
            "           2.0967e-01,  2.7052e-01,  3.9096e-01,  6.4841e-01,  3.4391e-02],\n",
            "         [ 1.0725e+00, -1.7446e+00, -1.0209e-01,  7.4083e-01,  1.2659e+00,\n",
            "           1.8948e-01,  4.8617e-01,  1.5043e-01,  4.6463e-01, -2.2159e-01],\n",
            "         [ 1.8843e-01, -1.6024e+00, -2.0216e-03,  7.8374e-01,  1.4425e+00,\n",
            "           1.6865e-01,  7.0181e-01, -9.0121e-02,  2.8084e-01, -4.7758e-01],\n",
            "         [-4.7216e-03, -7.9096e-01,  9.5347e-02,  7.6200e-01,  1.5657e+00,\n",
            "           1.5376e-01,  8.4296e-01, -2.4604e-01,  1.6196e-01, -6.4347e-01]],\n",
            "\n",
            "        [[ 9.4523e-01,  5.1202e-02, -5.9436e-01,  9.7805e-01,  1.3422e+00,\n",
            "           1.7370e-01,  6.8589e-01, -8.9994e-02,  2.7832e-01, -4.7758e-01],\n",
            "         [ 1.7957e+00, -5.3432e-01, -4.5890e-01,  1.0474e+00,  1.4655e+00,\n",
            "           1.6132e-01,  8.2704e-01, -2.4585e-01,  1.5944e-01, -6.4347e-01],\n",
            "         [ 1.8678e+00, -1.5511e+00, -3.1575e-01,  1.0493e+00,  1.5377e+00,\n",
            "           1.5459e-01,  8.9677e-01, -3.2059e-01,  1.0278e-01, -7.2299e-01],\n",
            "         [ 1.1014e+00, -2.1497e+00, -1.7409e-01,  1.0043e+00,  1.5821e+00,\n",
            "           1.5064e-01,  9.2772e-01, -3.5127e-01,  7.9913e-02, -7.5561e-01],\n",
            "         [ 2.0414e-01, -1.8228e+00, -4.1195e-02,  9.2708e-01,  1.6145e+00,\n",
            "           1.4752e-01,  9.4204e-01, -3.6308e-01,  7.1531e-02, -7.6812e-01],\n",
            "         [ 2.2707e-03, -8.8904e-01,  7.7910e-02,  8.2581e-01,  1.6422e+00,\n",
            "           1.4435e-01,  9.4989e-01, -3.6754e-01,  6.8793e-02, -7.7280e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "t tensor([[ 1],\n",
            "        [ 3],\n",
            "        [ 6],\n",
            "        [ 0],\n",
            "        [ 8],\n",
            "        [ 5],\n",
            "        [ 4],\n",
            "        [ 9],\n",
            "        [12],\n",
            "        [ 5],\n",
            "        [ 4],\n",
            "        [ 8],\n",
            "        [11],\n",
            "        [ 1],\n",
            "        [ 4]], dtype=torch.int32)\n",
            "b before tensor([[-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4]])\n",
            "b after tensor([[ -9,  -8,  -7,  -6,  -5,  -4,  -3],\n",
            "        [ -7,  -6,  -5,  -4,  -3,  -2,  -1],\n",
            "        [ -4,  -3,  -2,  -1,   0,   1,   2],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [ -2,  -1,   0,   1,   2,   3,   4],\n",
            "        [ -5,  -4,  -3,  -2,  -1,   0,   1],\n",
            "        [ -6,  -5,  -4,  -3,  -2,  -1,   0],\n",
            "        [ -1,   0,   1,   2,   3,   4,   5],\n",
            "        [  2,   3,   4,   5,   6,   7,   8],\n",
            "        [ -5,  -4,  -3,  -2,  -1,   0,   1],\n",
            "        [ -6,  -5,  -4,  -3,  -2,  -1,   0],\n",
            "        [ -2,  -1,   0,   1,   2,   3,   4],\n",
            "        [  1,   2,   3,   4,   5,   6,   7],\n",
            "        [ -9,  -8,  -7,  -6,  -5,  -4,  -3],\n",
            "        [ -6,  -5,  -4,  -3,  -2,  -1,   0]])\n",
            "s torch.Size([15, 7])\n",
            "---------\n",
            "after positional encoding shapetensor([[[ 9.0125e-01,  6.6579e-01, -4.8538e-01,  5.7854e-01,  8.6288e-01,\n",
            "           2.3295e-01,  1.6231e-02,  6.7071e-01,  8.6179e-01,  3.3210e-01],\n",
            "         [ 1.7427e+00,  2.0592e-01, -3.2758e-01,  5.6613e-01,  8.8814e-01,\n",
            "           2.3262e-01,  2.0406e-02,  6.7048e-01,  8.6225e-01,  3.3186e-01],\n",
            "         [ 1.8106e+00, -7.5102e-01, -1.7380e-01,  5.2916e-01,  9.1361e-01,\n",
            "           2.3163e-01,  2.4915e-02,  6.6985e-01,  8.6242e-01,  3.3123e-01],\n",
            "         [ 1.0425e+00, -1.3262e+00, -2.7975e-02,  4.6891e-01,  9.3971e-01,\n",
            "           2.2993e-01,  3.0326e-02,  6.6819e-01,  8.6180e-01,  3.2950e-01],\n",
            "         [ 1.4484e-01, -9.9337e-01,  1.0598e-01,  3.8782e-01,  9.6750e-01,\n",
            "           2.2738e-01,  3.8173e-02,  6.6374e-01,  8.5907e-01,  3.2482e-01],\n",
            "         [-5.6600e-02, -6.5553e-02,  2.2403e-01,  2.9041e-01,  9.9986e-01,\n",
            "           2.2363e-01,  5.2499e-02,  6.5191e-01,  8.5069e-01,  3.1230e-01]],\n",
            "\n",
            "        [[ 9.0130e-01,  6.6513e-01, -4.8550e-01,  5.7897e-01,  8.6340e-01,\n",
            "           2.3289e-01,  1.6952e-02,  6.6989e-01,  8.6116e-01,  3.3123e-01],\n",
            "         [ 1.7429e+00,  2.0412e-01, -3.2790e-01,  5.6729e-01,  8.8954e-01,\n",
            "           2.3245e-01,  2.2364e-02,  6.6825e-01,  8.6054e-01,  3.2950e-01],\n",
            "         [ 1.8109e+00, -7.5587e-01, -1.7466e-01,  5.3232e-01,  9.1741e-01,\n",
            "           2.3116e-01,  3.0211e-02,  6.6384e-01,  8.5781e-01,  3.2482e-01],\n",
            "         [ 1.0434e+00, -1.3392e+00, -3.0291e-02,  4.7739e-01,  9.4989e-01,\n",
            "           2.2867e-01,  4.4538e-02,  6.5204e-01,  8.4942e-01,  3.1231e-01],\n",
            "         [ 1.4729e-01, -1.0276e+00,  9.9896e-02,  4.1010e-01,  9.9422e-01,\n",
            "           2.2408e-01,  7.5488e-02,  6.2134e-01,  8.2656e-01,  2.7969e-01],\n",
            "         [-5.0523e-02, -1.5058e-01,  2.0891e-01,  3.4575e-01,  1.0663e+00,\n",
            "           2.1545e-01,  1.4522e-01,  5.4656e-01,  7.6990e-01,  2.0016e-01]],\n",
            "\n",
            "        [[ 9.0232e-01,  6.5079e-01, -4.8805e-01,  5.8831e-01,  8.7460e-01,\n",
            "           2.3151e-01,  3.2595e-02,  6.5211e-01,  8.4753e-01,  3.1231e-01],\n",
            "         [ 1.7456e+00,  1.6636e-01, -3.3461e-01,  5.9187e-01,  9.1903e-01,\n",
            "           2.2881e-01,  6.3545e-02,  6.2146e-01,  8.2467e-01,  2.7969e-01],\n",
            "         [ 1.8177e+00, -8.5039e-01, -1.9146e-01,  5.9383e-01,  9.9122e-01,\n",
            "           2.2206e-01,  1.3328e-01,  5.4672e-01,  7.6801e-01,  2.0016e-01],\n",
            "         [ 1.0585e+00, -1.5500e+00, -6.7763e-02,  6.1460e-01,  1.1145e+00,\n",
            "           2.0837e-01,  2.7444e-01,  3.9082e-01,  6.4914e-01,  3.4258e-02],\n",
            "         [ 1.7446e-01, -1.4078e+00,  3.2319e-02,  6.5754e-01,  1.2911e+00,\n",
            "           1.8748e-01,  4.9009e-01,  1.5025e-01,  4.6536e-01, -2.2175e-01],\n",
            "         [-1.3785e-02, -6.6460e-01,  1.1755e-01,  6.8028e-01,  1.4677e+00,\n",
            "           1.6596e-01,  7.0574e-01, -9.0332e-02,  2.8159e-01, -4.7775e-01]],\n",
            "\n",
            "        [[ 9.0125e-01,  6.6586e-01, -4.8537e-01,  5.7850e-01,  8.6283e-01,\n",
            "           2.3296e-01,  1.6159e-02,  6.7079e-01,  8.6185e-01,  3.3219e-01],\n",
            "         [ 1.7427e+00,  2.0609e-01, -3.2755e-01,  5.6601e-01,  8.8800e-01,\n",
            "           2.3264e-01,  2.0212e-02,  6.7070e-01,  8.6242e-01,  3.3210e-01],\n",
            "         [ 1.8106e+00, -7.5053e-01, -1.7371e-01,  5.2884e-01,  9.1324e-01,\n",
            "           2.3167e-01,  2.4387e-02,  6.7045e-01,  8.6288e-01,  3.3186e-01],\n",
            "         [ 1.0424e+00, -1.3249e+00, -2.7741e-02,  4.6805e-01,  9.3868e-01,\n",
            "           2.3005e-01,  2.8895e-02,  6.6981e-01,  8.6305e-01,  3.3123e-01],\n",
            "         [ 1.4459e-01, -9.8983e-01,  1.0661e-01,  3.8552e-01,  9.6473e-01,\n",
            "           2.2772e-01,  3.4307e-02,  6.6813e-01,  8.6244e-01,  3.2949e-01],\n",
            "         [-5.7278e-02, -5.6065e-02,  2.2571e-01,  2.8424e-01,  9.9246e-01,\n",
            "           2.2455e-01,  4.2153e-02,  6.6367e-01,  8.5970e-01,  3.2482e-01]],\n",
            "\n",
            "        [[ 9.0840e-01,  5.6575e-01, -5.0316e-01,  6.4365e-01,  9.4100e-01,\n",
            "           2.2332e-01,  1.2532e-01,  5.4675e-01,  7.6675e-01,  2.0016e-01],\n",
            "         [ 1.7589e+00, -1.9737e-02, -3.6769e-01,  7.1298e-01,  1.0644e+00,\n",
            "           2.1090e-01,  2.6647e-01,  3.9088e-01,  6.4788e-01,  3.4260e-02],\n",
            "         [ 1.8406e+00, -1.1703e+00, -2.4832e-01,  8.0203e-01,  1.2410e+00,\n",
            "           1.9126e-01,  4.8213e-01,  1.5035e-01,  4.6410e-01, -2.2174e-01],\n",
            "         [ 1.0863e+00, -1.9383e+00, -1.3677e-01,  8.6725e-01,  1.4177e+00,\n",
            "           1.7100e-01,  6.9778e-01, -9.0205e-02,  2.8032e-01, -4.7775e-01],\n",
            "         [ 1.9733e-01, -1.7277e+00, -2.4541e-02,  8.6573e-01,  1.5409e+00,\n",
            "           1.5668e-01,  8.3893e-01, -2.4613e-01,  1.6145e-01, -6.4366e-01],\n",
            "         [-4.8465e-04, -8.5069e-01,  8.4476e-02,  8.0139e-01,  1.6130e+00,\n",
            "           1.4805e-01,  9.0867e-01, -3.2091e-01,  1.0479e-01, -7.2318e-01]],\n",
            "\n",
            "        [[ 9.0165e-01,  6.6027e-01, -4.8636e-01,  5.8214e-01,  8.6719e-01,\n",
            "           2.3242e-01,  2.2249e-02,  6.6387e-01,  8.5654e-01,  3.2482e-01],\n",
            "         [ 1.7438e+00,  1.9109e-01, -3.3022e-01,  5.7578e-01,  8.9972e-01,\n",
            "           2.3119e-01,  3.6576e-02,  6.5210e-01,  8.4816e-01,  3.1231e-01],\n",
            "         [ 1.8134e+00, -7.9009e-01, -1.8074e-01,  5.5459e-01,  9.4413e-01,\n",
            "           2.2787e-01,  6.7526e-02,  6.2144e-01,  8.2530e-01,  2.7969e-01],\n",
            "         [ 1.0495e+00, -1.4242e+00, -4.5404e-02,  5.3273e-01,  1.0163e+00,\n",
            "           2.2048e-01,  1.3726e-01,  5.4668e-01,  7.6864e-01,  2.0016e-01],\n",
            "         [ 1.6059e-01, -1.2137e+00,  6.6820e-02,  5.3121e-01,  1.1395e+00,\n",
            "           2.0617e-01,  2.7842e-01,  3.9076e-01,  6.4977e-01,  3.4257e-02],\n",
            "         [-2.7659e-02, -4.7049e-01,  1.5205e-01,  5.5395e-01,  1.3161e+00,\n",
            "           1.8465e-01,  4.9407e-01,  1.5018e-01,  4.6599e-01, -2.2175e-01]],\n",
            "\n",
            "        [[ 9.0139e-01,  6.6382e-01, -4.8573e-01,  5.7983e-01,  8.6442e-01,\n",
            "           2.3276e-01,  1.8383e-02,  6.6826e-01,  8.5991e-01,  3.2950e-01],\n",
            "         [ 1.7431e+00,  2.0057e-01, -3.2853e-01,  5.6960e-01,  8.9231e-01,\n",
            "           2.3211e-01,  2.6230e-02,  6.6386e-01,  8.5717e-01,  3.2482e-01],\n",
            "         [ 1.8116e+00, -7.6536e-01, -1.7635e-01,  5.3849e-01,  9.2482e-01,\n",
            "           2.3025e-01,  4.0557e-02,  6.5208e-01,  8.4879e-01,  3.1231e-01],\n",
            "         [ 1.0452e+00, -1.3639e+00, -3.4687e-02,  4.9348e-01,  9.6920e-01,\n",
            "           2.2629e-01,  7.1507e-02,  6.2140e-01,  8.2593e-01,  2.7969e-01],\n",
            "         [ 1.5160e-01, -1.0879e+00,  8.9179e-02,  4.4934e-01,  1.0413e+00,\n",
            "           2.1828e-01,  1.4124e-01,  5.4663e-01,  7.6927e-01,  2.0016e-01],\n",
            "         [-4.1532e-02, -2.7638e-01,  1.8656e-01,  4.2762e-01,  1.1645e+00,\n",
            "           2.0334e-01,  2.8240e-01,  3.9069e-01,  6.5040e-01,  3.4255e-02]],\n",
            "\n",
            "        [[ 9.1739e-01,  4.3996e-01, -5.2552e-01,  7.2552e-01,  1.0392e+00,\n",
            "           2.1121e-01,  2.6249e-01,  3.9089e-01,  6.4724e-01,  3.4260e-02],\n",
            "         [ 1.7727e+00, -2.1385e-01, -4.0219e-01,  8.3931e-01,  1.2159e+00,\n",
            "           1.9221e-01,  4.7815e-01,  1.5037e-01,  4.6347e-01, -2.2174e-01],\n",
            "         [ 1.8544e+00, -1.3644e+00, -2.8282e-01,  9.2836e-01,  1.3926e+00,\n",
            "           1.7258e-01,  6.9380e-01, -9.0166e-02,  2.7969e-01, -4.7775e-01],\n",
            "         [ 1.0952e+00, -2.0640e+00, -1.5912e-01,  9.4912e-01,  1.5159e+00,\n",
            "           1.5889e-01,  8.3495e-01, -2.4607e-01,  1.6082e-01, -6.4365e-01],\n",
            "         [ 2.0164e-01, -1.7880e+00, -3.5259e-02,  9.0498e-01,  1.5880e+00,\n",
            "           1.5088e-01,  9.0469e-01, -3.2084e-01,  1.0416e-01, -7.2318e-01],\n",
            "         [ 1.2830e-03, -8.7542e-01,  8.0080e-02,  8.1749e-01,  1.6323e+00,\n",
            "           1.4566e-01,  9.3564e-01, -3.5155e-01,  8.1299e-02, -7.5580e-01]],\n",
            "\n",
            "        [[ 9.5413e-01, -7.4052e-02, -6.1688e-01,  1.0600e+00,  1.4406e+00,\n",
            "           1.6173e-01,  8.2301e-01, -2.4600e-01,  1.5892e-01, -6.4365e-01],\n",
            "         [ 1.7999e+00, -5.9405e-01, -4.6977e-01,  1.0868e+00,  1.5128e+00,\n",
            "           1.5561e-01,  8.9274e-01, -3.2072e-01,  1.0227e-01, -7.2318e-01],\n",
            "         [ 1.8695e+00, -1.5752e+00, -3.2030e-01,  1.0656e+00,  1.5573e+00,\n",
            "           1.5228e-01,  9.2370e-01, -3.5139e-01,  7.9406e-02, -7.5580e-01],\n",
            "         [ 1.1020e+00, -2.1586e+00, -1.7592e-01,  1.0106e+00,  1.5897e+00,\n",
            "           1.4979e-01,  9.3802e-01, -3.6318e-01,  7.1024e-02, -7.6831e-01],\n",
            "         [ 2.0434e-01, -1.8258e+00, -4.1972e-02,  9.2955e-01,  1.6175e+00,\n",
            "           1.4724e-01,  9.4587e-01, -3.6763e-01,  6.8286e-02, -7.7299e-01],\n",
            "         [ 2.3082e-03, -8.8977e-01,  7.7531e-02,  8.2682e-01,  1.6435e+00,\n",
            "           1.4428e-01,  9.5128e-01, -3.6933e-01,  6.7671e-02, -7.7472e-01]],\n",
            "\n",
            "        [[ 9.0165e-01,  6.6027e-01, -4.8636e-01,  5.8214e-01,  8.6719e-01,\n",
            "           2.3242e-01,  2.2249e-02,  6.6387e-01,  8.5654e-01,  3.2482e-01],\n",
            "         [ 1.7438e+00,  1.9109e-01, -3.3022e-01,  5.7578e-01,  8.9972e-01,\n",
            "           2.3119e-01,  3.6576e-02,  6.5210e-01,  8.4816e-01,  3.1231e-01],\n",
            "         [ 1.8134e+00, -7.9009e-01, -1.8074e-01,  5.5459e-01,  9.4413e-01,\n",
            "           2.2787e-01,  6.7526e-02,  6.2144e-01,  8.2530e-01,  2.7969e-01],\n",
            "         [ 1.0495e+00, -1.4242e+00, -4.5404e-02,  5.3273e-01,  1.0163e+00,\n",
            "           2.2048e-01,  1.3726e-01,  5.4668e-01,  7.6864e-01,  2.0016e-01],\n",
            "         [ 1.6059e-01, -1.2137e+00,  6.6820e-02,  5.3121e-01,  1.1395e+00,\n",
            "           2.0617e-01,  2.7842e-01,  3.9076e-01,  6.4977e-01,  3.4257e-02],\n",
            "         [-2.7659e-02, -4.7049e-01,  1.5205e-01,  5.5395e-01,  1.3161e+00,\n",
            "           1.8465e-01,  4.9407e-01,  1.5018e-01,  4.6599e-01, -2.2175e-01]],\n",
            "\n",
            "        [[ 9.0139e-01,  6.6382e-01, -4.8573e-01,  5.7983e-01,  8.6442e-01,\n",
            "           2.3276e-01,  1.8383e-02,  6.6826e-01,  8.5991e-01,  3.2950e-01],\n",
            "         [ 1.7431e+00,  2.0057e-01, -3.2853e-01,  5.6960e-01,  8.9231e-01,\n",
            "           2.3211e-01,  2.6230e-02,  6.6386e-01,  8.5717e-01,  3.2482e-01],\n",
            "         [ 1.8116e+00, -7.6536e-01, -1.7635e-01,  5.3849e-01,  9.2482e-01,\n",
            "           2.3025e-01,  4.0557e-02,  6.5208e-01,  8.4879e-01,  3.1231e-01],\n",
            "         [ 1.0452e+00, -1.3639e+00, -3.4687e-02,  4.9348e-01,  9.6920e-01,\n",
            "           2.2629e-01,  7.1507e-02,  6.2140e-01,  8.2593e-01,  2.7969e-01],\n",
            "         [ 1.5160e-01, -1.0879e+00,  8.9179e-02,  4.4934e-01,  1.0413e+00,\n",
            "           2.1828e-01,  1.4124e-01,  5.4663e-01,  7.6927e-01,  2.0016e-01],\n",
            "         [-4.1532e-02, -2.7638e-01,  1.8656e-01,  4.2762e-01,  1.1645e+00,\n",
            "           2.0334e-01,  2.8240e-01,  3.9069e-01,  6.5040e-01,  3.4255e-02]],\n",
            "\n",
            "        [[ 9.0840e-01,  5.6575e-01, -5.0316e-01,  6.4365e-01,  9.4100e-01,\n",
            "           2.2332e-01,  1.2532e-01,  5.4675e-01,  7.6675e-01,  2.0016e-01],\n",
            "         [ 1.7589e+00, -1.9737e-02, -3.6769e-01,  7.1298e-01,  1.0644e+00,\n",
            "           2.1090e-01,  2.6647e-01,  3.9088e-01,  6.4788e-01,  3.4260e-02],\n",
            "         [ 1.8406e+00, -1.1703e+00, -2.4832e-01,  8.0203e-01,  1.2410e+00,\n",
            "           1.9126e-01,  4.8213e-01,  1.5035e-01,  4.6410e-01, -2.2174e-01],\n",
            "         [ 1.0863e+00, -1.9383e+00, -1.3677e-01,  8.6725e-01,  1.4177e+00,\n",
            "           1.7100e-01,  6.9778e-01, -9.0205e-02,  2.8032e-01, -4.7775e-01],\n",
            "         [ 1.9733e-01, -1.7277e+00, -2.4541e-02,  8.6573e-01,  1.5409e+00,\n",
            "           1.5668e-01,  8.3893e-01, -2.4613e-01,  1.6145e-01, -6.4366e-01],\n",
            "         [-4.8465e-04, -8.5069e-01,  8.4476e-02,  8.0139e-01,  1.6130e+00,\n",
            "           1.4805e-01,  9.0867e-01, -3.2091e-01,  1.0479e-01, -7.2318e-01]],\n",
            "\n",
            "        [[ 9.4514e-01,  5.1742e-02, -5.9452e-01,  9.7817e-01,  1.3424e+00,\n",
            "           1.7384e-01,  6.8584e-01, -9.0134e-02,  2.7843e-01, -4.7775e-01],\n",
            "         [ 1.7956e+00, -5.3375e-01, -4.5905e-01,  1.0475e+00,  1.4658e+00,\n",
            "           1.6141e-01,  8.2699e-01, -2.4601e-01,  1.5956e-01, -6.4365e-01],\n",
            "         [ 1.8677e+00, -1.5505e+00, -3.1590e-01,  1.0495e+00,  1.5379e+00,\n",
            "           1.5466e-01,  8.9673e-01, -3.2074e-01,  1.0290e-01, -7.2318e-01],\n",
            "         [ 1.1013e+00, -2.1491e+00, -1.7424e-01,  1.0045e+00,  1.5823e+00,\n",
            "           1.5070e-01,  9.2768e-01, -3.5143e-01,  8.0037e-02, -7.5580e-01],\n",
            "         [ 2.0408e-01, -1.8222e+00, -4.1341e-02,  9.2725e-01,  1.6148e+00,\n",
            "           1.4758e-01,  9.4200e-01, -3.6324e-01,  7.1655e-02, -7.6831e-01],\n",
            "         [ 2.2145e-03, -8.8845e-01,  7.7764e-02,  8.2597e-01,  1.6425e+00,\n",
            "           1.4441e-01,  9.4985e-01, -3.6770e-01,  6.8917e-02, -7.7299e-01]],\n",
            "\n",
            "        [[ 9.0125e-01,  6.6579e-01, -4.8538e-01,  5.7854e-01,  8.6288e-01,\n",
            "           2.3295e-01,  1.6231e-02,  6.7071e-01,  8.6179e-01,  3.3210e-01],\n",
            "         [ 1.7427e+00,  2.0592e-01, -3.2758e-01,  5.6613e-01,  8.8814e-01,\n",
            "           2.3262e-01,  2.0406e-02,  6.7048e-01,  8.6225e-01,  3.3186e-01],\n",
            "         [ 1.8106e+00, -7.5102e-01, -1.7380e-01,  5.2916e-01,  9.1361e-01,\n",
            "           2.3163e-01,  2.4915e-02,  6.6985e-01,  8.6242e-01,  3.3123e-01],\n",
            "         [ 1.0425e+00, -1.3262e+00, -2.7975e-02,  4.6891e-01,  9.3971e-01,\n",
            "           2.2993e-01,  3.0326e-02,  6.6819e-01,  8.6180e-01,  3.2950e-01],\n",
            "         [ 1.4484e-01, -9.9337e-01,  1.0598e-01,  3.8782e-01,  9.6750e-01,\n",
            "           2.2738e-01,  3.8173e-02,  6.6374e-01,  8.5907e-01,  3.2482e-01],\n",
            "         [-5.6600e-02, -6.5553e-02,  2.2403e-01,  2.9041e-01,  9.9986e-01,\n",
            "           2.2363e-01,  5.2499e-02,  6.5191e-01,  8.5069e-01,  3.1230e-01]],\n",
            "\n",
            "        [[ 9.0139e-01,  6.6382e-01, -4.8573e-01,  5.7983e-01,  8.6442e-01,\n",
            "           2.3276e-01,  1.8383e-02,  6.6826e-01,  8.5991e-01,  3.2950e-01],\n",
            "         [ 1.7431e+00,  2.0057e-01, -3.2853e-01,  5.6960e-01,  8.9231e-01,\n",
            "           2.3211e-01,  2.6230e-02,  6.6386e-01,  8.5717e-01,  3.2482e-01],\n",
            "         [ 1.8116e+00, -7.6536e-01, -1.7635e-01,  5.3849e-01,  9.2482e-01,\n",
            "           2.3025e-01,  4.0557e-02,  6.5208e-01,  8.4879e-01,  3.1231e-01],\n",
            "         [ 1.0452e+00, -1.3639e+00, -3.4687e-02,  4.9348e-01,  9.6920e-01,\n",
            "           2.2629e-01,  7.1507e-02,  6.2140e-01,  8.2593e-01,  2.7969e-01],\n",
            "         [ 1.5160e-01, -1.0879e+00,  8.9179e-02,  4.4934e-01,  1.0413e+00,\n",
            "           2.1828e-01,  1.4124e-01,  5.4663e-01,  7.6927e-01,  2.0016e-01],\n",
            "         [-4.1532e-02, -2.7638e-01,  1.8656e-01,  4.2762e-01,  1.1645e+00,\n",
            "           2.0334e-01,  2.8240e-01,  3.9069e-01,  6.5040e-01,  3.4255e-02]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "t tensor([[ 4],\n",
            "        [ 1],\n",
            "        [ 0],\n",
            "        [11],\n",
            "        [ 5],\n",
            "        [ 7],\n",
            "        [11],\n",
            "        [11],\n",
            "        [ 8],\n",
            "        [ 4],\n",
            "        [11],\n",
            "        [ 3],\n",
            "        [ 5],\n",
            "        [12],\n",
            "        [ 9]], dtype=torch.int32)\n",
            "b before tensor([[-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4]])\n",
            "b after tensor([[ -6,  -5,  -4,  -3,  -2,  -1,   0],\n",
            "        [ -9,  -8,  -7,  -6,  -5,  -4,  -3],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [  1,   2,   3,   4,   5,   6,   7],\n",
            "        [ -5,  -4,  -3,  -2,  -1,   0,   1],\n",
            "        [ -3,  -2,  -1,   0,   1,   2,   3],\n",
            "        [  1,   2,   3,   4,   5,   6,   7],\n",
            "        [  1,   2,   3,   4,   5,   6,   7],\n",
            "        [ -2,  -1,   0,   1,   2,   3,   4],\n",
            "        [ -6,  -5,  -4,  -3,  -2,  -1,   0],\n",
            "        [  1,   2,   3,   4,   5,   6,   7],\n",
            "        [ -7,  -6,  -5,  -4,  -3,  -2,  -1],\n",
            "        [ -5,  -4,  -3,  -2,  -1,   0,   1],\n",
            "        [  2,   3,   4,   5,   6,   7,   8],\n",
            "        [ -1,   0,   1,   2,   3,   4,   5]])\n",
            "s torch.Size([15, 7])\n",
            "---------\n",
            "after positional encoding shapetensor([[[ 9.0123e-01,  6.6428e-01, -4.8589e-01,  5.7989e-01,  8.6458e-01,\n",
            "           2.3307e-01,  1.8273e-02,  6.6810e-01,  8.5999e-01,  3.2940e-01],\n",
            "         [ 1.7430e+00,  2.0104e-01, -3.2869e-01,  5.6967e-01,  8.9247e-01,\n",
            "           2.3241e-01,  2.6120e-02,  6.6370e-01,  8.5725e-01,  3.2473e-01],\n",
            "         [ 1.8115e+00, -7.6489e-01, -1.7651e-01,  5.3856e-01,  9.2498e-01,\n",
            "           2.3055e-01,  4.0447e-02,  6.5192e-01,  8.4887e-01,  3.1221e-01],\n",
            "         [ 1.0451e+00, -1.3635e+00, -3.4843e-02,  4.9356e-01,  9.6937e-01,\n",
            "           2.2658e-01,  7.1399e-02,  6.2124e-01,  8.2601e-01,  2.7959e-01],\n",
            "         [ 1.5145e-01, -1.0874e+00,  8.9027e-02,  4.4942e-01,  1.0415e+00,\n",
            "           2.1855e-01,  1.4114e-01,  5.4646e-01,  7.6935e-01,  2.0005e-01],\n",
            "         [-4.1655e-02, -2.7586e-01,  1.8641e-01,  4.2773e-01,  1.1647e+00,\n",
            "           2.0355e-01,  2.8230e-01,  3.9051e-01,  6.5049e-01,  3.4134e-02]],\n",
            "\n",
            "        [[ 9.0109e-01,  6.6626e-01, -4.8554e-01,  5.7861e-01,  8.6304e-01,\n",
            "           2.3326e-01,  1.6121e-02,  6.7055e-01,  8.6186e-01,  3.3200e-01],\n",
            "         [ 1.7426e+00,  2.0638e-01, -3.2774e-01,  5.6619e-01,  8.8830e-01,\n",
            "           2.3293e-01,  2.0296e-02,  6.7032e-01,  8.6233e-01,  3.3177e-01],\n",
            "         [ 1.8104e+00, -7.5055e-01, -1.7396e-01,  5.2922e-01,  9.1377e-01,\n",
            "           2.3194e-01,  2.4804e-02,  6.6970e-01,  8.6250e-01,  3.3113e-01],\n",
            "         [ 1.0423e+00, -1.3257e+00, -2.8134e-02,  4.6897e-01,  9.3987e-01,\n",
            "           2.3023e-01,  3.0216e-02,  6.6803e-01,  8.6188e-01,  3.2940e-01],\n",
            "         [ 1.4468e-01, -9.9290e-01,  1.0582e-01,  3.8789e-01,  9.6766e-01,\n",
            "           2.2769e-01,  3.8063e-02,  6.6358e-01,  8.5914e-01,  3.2472e-01],\n",
            "         [-5.6763e-02, -6.5084e-02,  2.2387e-01,  2.9048e-01,  1.0000e+00,\n",
            "           2.2394e-01,  5.2389e-02,  6.5176e-01,  8.5076e-01,  3.1221e-01]],\n",
            "\n",
            "        [[ 9.0108e-01,  6.6632e-01, -4.8553e-01,  5.7857e-01,  8.6299e-01,\n",
            "           2.3327e-01,  1.6049e-02,  6.7063e-01,  8.6193e-01,  3.3209e-01],\n",
            "         [ 1.7426e+00,  2.0656e-01, -3.2771e-01,  5.6608e-01,  8.8816e-01,\n",
            "           2.3295e-01,  2.0102e-02,  6.7054e-01,  8.6249e-01,  3.3200e-01],\n",
            "         [ 1.8104e+00, -7.5007e-01, -1.7387e-01,  5.2891e-01,  9.1340e-01,\n",
            "           2.3198e-01,  2.4277e-02,  6.7030e-01,  8.6296e-01,  3.3177e-01],\n",
            "         [ 1.0423e+00, -1.3244e+00, -2.7901e-02,  4.6812e-01,  9.3884e-01,\n",
            "           2.3036e-01,  2.8785e-02,  6.6966e-01,  8.6313e-01,  3.3113e-01],\n",
            "         [ 1.4442e-01, -9.8936e-01,  1.0645e-01,  3.8558e-01,  9.6489e-01,\n",
            "           2.2803e-01,  3.4196e-02,  6.6798e-01,  8.6251e-01,  3.2940e-01],\n",
            "         [-5.7443e-02, -5.5599e-02,  2.2555e-01,  2.8431e-01,  9.9262e-01,\n",
            "           2.2485e-01,  4.2043e-02,  6.6351e-01,  8.5978e-01,  3.2472e-01]],\n",
            "\n",
            "        [[ 9.4509e-01,  5.2356e-02, -5.9463e-01,  9.7835e-01,  1.3427e+00,\n",
            "           1.7390e-01,  6.8575e-01, -9.0360e-02,  2.7853e-01, -4.7791e-01],\n",
            "         [ 1.7956e+00, -5.3310e-01, -4.5915e-01,  1.0477e+00,  1.4661e+00,\n",
            "           1.6143e-01,  8.2691e-01, -2.4625e-01,  1.5966e-01, -6.4383e-01],\n",
            "         [ 1.8677e+00, -1.5498e+00, -3.1599e-01,  1.0497e+00,  1.5383e+00,\n",
            "           1.5465e-01,  8.9665e-01, -3.2099e-01,  1.0301e-01, -7.2337e-01],\n",
            "         [ 1.1013e+00, -2.1484e+00, -1.7433e-01,  1.0047e+00,  1.5827e+00,\n",
            "           1.5068e-01,  9.2760e-01, -3.5168e-01,  8.0150e-02, -7.5599e-01],\n",
            "         [ 2.0408e-01, -1.8215e+00, -4.1433e-02,  9.2746e-01,  1.6152e+00,\n",
            "           1.4756e-01,  9.4193e-01, -3.6349e-01,  7.1768e-02, -7.6850e-01],\n",
            "         [ 2.2100e-03, -8.8779e-01,  7.7672e-02,  8.2618e-01,  1.6429e+00,\n",
            "           1.4438e-01,  9.4977e-01, -3.6795e-01,  6.9031e-02, -7.7318e-01]],\n",
            "\n",
            "        [[ 9.0148e-01,  6.6074e-01, -4.8652e-01,  5.8220e-01,  8.6735e-01,\n",
            "           2.3273e-01,  2.2139e-02,  6.6371e-01,  8.5662e-01,  3.2473e-01],\n",
            "         [ 1.7436e+00,  1.9156e-01, -3.3038e-01,  5.7585e-01,  8.9988e-01,\n",
            "           2.3150e-01,  3.6466e-02,  6.5195e-01,  8.4824e-01,  3.1221e-01],\n",
            "         [ 1.8132e+00, -7.8962e-01, -1.8090e-01,  5.5466e-01,  9.4430e-01,\n",
            "           2.2816e-01,  6.7418e-02,  6.2128e-01,  8.2538e-01,  2.7959e-01],\n",
            "         [ 1.0494e+00, -1.4237e+00, -4.5556e-02,  5.3281e-01,  1.0165e+00,\n",
            "           2.2075e-01,  1.3716e-01,  5.4652e-01,  7.6872e-01,  2.0006e-01],\n",
            "         [ 1.6047e-01, -1.2132e+00,  6.6678e-02,  5.3131e-01,  1.1398e+00,\n",
            "           2.0639e-01,  2.7832e-01,  3.9058e-01,  6.4985e-01,  3.4136e-02],\n",
            "         [-2.7744e-02, -4.6992e-01,  1.5193e-01,  5.5409e-01,  1.3164e+00,\n",
            "           1.8479e-01,  4.9397e-01,  1.4998e-01,  4.6609e-01, -2.2189e-01]],\n",
            "\n",
            "        [[ 9.0393e-01,  6.2653e-01, -4.9260e-01,  6.0448e-01,  8.9408e-01,\n",
            "           2.2942e-01,  5.9456e-02,  6.2131e-01,  8.2411e-01,  2.7959e-01],\n",
            "         [ 1.7497e+00,  1.0655e-01, -3.4548e-01,  6.3120e-01,  9.6631e-01,\n",
            "           2.2328e-01,  1.2919e-01,  5.4658e-01,  7.6746e-01,  2.0006e-01],\n",
            "         [ 1.8266e+00, -9.7567e-01, -2.1396e-01,  6.7580e-01,  1.0897e+00,\n",
            "           2.1017e-01,  2.7035e-01,  3.9068e-01,  6.4859e-01,  3.4138e-02],\n",
            "         [ 1.0723e+00, -1.7436e+00, -1.0239e-01,  7.4106e-01,  1.2664e+00,\n",
            "           1.8983e-01,  4.8601e-01,  1.5010e-01,  4.6483e-01, -2.2189e-01],\n",
            "         [ 1.8829e-01, -1.6013e+00, -2.2926e-03,  7.8404e-01,  1.4430e+00,\n",
            "           1.6886e-01,  7.0167e-01, -9.0487e-02,  2.8106e-01, -4.7792e-01],\n",
            "         [-4.8177e-03, -7.8974e-01,  9.5094e-02,  7.6234e-01,  1.5663e+00,\n",
            "           1.5386e-01,  8.4283e-01, -2.4644e-01,  1.6219e-01, -6.4384e-01]],\n",
            "\n",
            "        [[ 9.4509e-01,  5.2356e-02, -5.9463e-01,  9.7835e-01,  1.3427e+00,\n",
            "           1.7390e-01,  6.8575e-01, -9.0360e-02,  2.7853e-01, -4.7791e-01],\n",
            "         [ 1.7956e+00, -5.3310e-01, -4.5915e-01,  1.0477e+00,  1.4661e+00,\n",
            "           1.6143e-01,  8.2691e-01, -2.4625e-01,  1.5966e-01, -6.4383e-01],\n",
            "         [ 1.8677e+00, -1.5498e+00, -3.1599e-01,  1.0497e+00,  1.5383e+00,\n",
            "           1.5465e-01,  8.9665e-01, -3.2099e-01,  1.0301e-01, -7.2337e-01],\n",
            "         [ 1.1013e+00, -2.1484e+00, -1.7433e-01,  1.0047e+00,  1.5827e+00,\n",
            "           1.5068e-01,  9.2760e-01, -3.5168e-01,  8.0150e-02, -7.5599e-01],\n",
            "         [ 2.0408e-01, -1.8215e+00, -4.1433e-02,  9.2746e-01,  1.6152e+00,\n",
            "           1.4756e-01,  9.4193e-01, -3.6349e-01,  7.1768e-02, -7.6850e-01],\n",
            "         [ 2.2100e-03, -8.8779e-01,  7.7672e-02,  8.2618e-01,  1.6429e+00,\n",
            "           1.4438e-01,  9.4977e-01, -3.6795e-01,  6.9031e-02, -7.7318e-01]],\n",
            "\n",
            "        [[ 9.4509e-01,  5.2356e-02, -5.9463e-01,  9.7835e-01,  1.3427e+00,\n",
            "           1.7390e-01,  6.8575e-01, -9.0360e-02,  2.7853e-01, -4.7791e-01],\n",
            "         [ 1.7956e+00, -5.3310e-01, -4.5915e-01,  1.0477e+00,  1.4661e+00,\n",
            "           1.6143e-01,  8.2691e-01, -2.4625e-01,  1.5966e-01, -6.4383e-01],\n",
            "         [ 1.8677e+00, -1.5498e+00, -3.1599e-01,  1.0497e+00,  1.5383e+00,\n",
            "           1.5465e-01,  8.9665e-01, -3.2099e-01,  1.0301e-01, -7.2337e-01],\n",
            "         [ 1.1013e+00, -2.1484e+00, -1.7433e-01,  1.0047e+00,  1.5827e+00,\n",
            "           1.5068e-01,  9.2760e-01, -3.5168e-01,  8.0150e-02, -7.5599e-01],\n",
            "         [ 2.0408e-01, -1.8215e+00, -4.1433e-02,  9.2746e-01,  1.6152e+00,\n",
            "           1.4756e-01,  9.4193e-01, -3.6349e-01,  7.1768e-02, -7.6850e-01],\n",
            "         [ 2.2100e-03, -8.8779e-01,  7.7672e-02,  8.2618e-01,  1.6429e+00,\n",
            "           1.4438e-01,  9.4977e-01, -3.6795e-01,  6.9031e-02, -7.7318e-01]],\n",
            "\n",
            "        [[ 9.0825e-01,  5.6624e-01, -5.0331e-01,  6.4373e-01,  9.4119e-01,\n",
            "           2.2359e-01,  1.2521e-01,  5.4659e-01,  7.6683e-01,  2.0006e-01],\n",
            "         [ 1.7587e+00, -1.9217e-02, -3.6783e-01,  7.1309e-01,  1.0646e+00,\n",
            "           2.1112e-01,  2.6637e-01,  3.9070e-01,  6.4796e-01,  3.4139e-02],\n",
            "         [ 1.8405e+00, -1.1697e+00, -2.4845e-01,  8.0217e-01,  1.2413e+00,\n",
            "           1.9141e-01,  4.8203e-01,  1.5014e-01,  4.6419e-01, -2.2189e-01],\n",
            "         [ 1.0862e+00, -1.9376e+00, -1.3688e-01,  8.6742e-01,  1.4180e+00,\n",
            "           1.7106e-01,  6.9769e-01, -9.0431e-02,  2.8043e-01, -4.7792e-01],\n",
            "         [ 1.9730e-01, -1.7271e+00, -2.4641e-02,  8.6593e-01,  1.5413e+00,\n",
            "           1.5670e-01,  8.3885e-01, -2.4637e-01,  1.6156e-01, -6.4384e-01],\n",
            "         [-4.9639e-04, -8.5003e-01,  8.4382e-02,  8.0159e-01,  1.6134e+00,\n",
            "           1.4804e-01,  9.0859e-01, -3.2116e-01,  1.0491e-01, -7.2337e-01]],\n",
            "\n",
            "        [[ 9.0123e-01,  6.6428e-01, -4.8589e-01,  5.7989e-01,  8.6458e-01,\n",
            "           2.3307e-01,  1.8273e-02,  6.6810e-01,  8.5999e-01,  3.2940e-01],\n",
            "         [ 1.7430e+00,  2.0104e-01, -3.2869e-01,  5.6967e-01,  8.9247e-01,\n",
            "           2.3241e-01,  2.6120e-02,  6.6370e-01,  8.5725e-01,  3.2473e-01],\n",
            "         [ 1.8115e+00, -7.6489e-01, -1.7651e-01,  5.3856e-01,  9.2498e-01,\n",
            "           2.3055e-01,  4.0447e-02,  6.5192e-01,  8.4887e-01,  3.1221e-01],\n",
            "         [ 1.0451e+00, -1.3635e+00, -3.4843e-02,  4.9356e-01,  9.6937e-01,\n",
            "           2.2658e-01,  7.1399e-02,  6.2124e-01,  8.2601e-01,  2.7959e-01],\n",
            "         [ 1.5145e-01, -1.0874e+00,  8.9027e-02,  4.4942e-01,  1.0415e+00,\n",
            "           2.1855e-01,  1.4114e-01,  5.4646e-01,  7.6935e-01,  2.0005e-01],\n",
            "         [-4.1655e-02, -2.7586e-01,  1.8641e-01,  4.2773e-01,  1.1647e+00,\n",
            "           2.0355e-01,  2.8230e-01,  3.9051e-01,  6.5049e-01,  3.4134e-02]],\n",
            "\n",
            "        [[ 9.4509e-01,  5.2356e-02, -5.9463e-01,  9.7835e-01,  1.3427e+00,\n",
            "           1.7390e-01,  6.8575e-01, -9.0360e-02,  2.7853e-01, -4.7791e-01],\n",
            "         [ 1.7956e+00, -5.3310e-01, -4.5915e-01,  1.0477e+00,  1.4661e+00,\n",
            "           1.6143e-01,  8.2691e-01, -2.4625e-01,  1.5966e-01, -6.4383e-01],\n",
            "         [ 1.8677e+00, -1.5498e+00, -3.1599e-01,  1.0497e+00,  1.5383e+00,\n",
            "           1.5465e-01,  8.9665e-01, -3.2099e-01,  1.0301e-01, -7.2337e-01],\n",
            "         [ 1.1013e+00, -2.1484e+00, -1.7433e-01,  1.0047e+00,  1.5827e+00,\n",
            "           1.5068e-01,  9.2760e-01, -3.5168e-01,  8.0150e-02, -7.5599e-01],\n",
            "         [ 2.0408e-01, -1.8215e+00, -4.1433e-02,  9.2746e-01,  1.6152e+00,\n",
            "           1.4756e-01,  9.4193e-01, -3.6349e-01,  7.1768e-02, -7.6850e-01],\n",
            "         [ 2.2100e-03, -8.8779e-01,  7.7672e-02,  8.2618e-01,  1.6429e+00,\n",
            "           1.4438e-01,  9.4977e-01, -3.6795e-01,  6.9031e-02, -7.7318e-01]],\n",
            "\n",
            "        [[ 9.0113e-01,  6.6560e-01, -4.8566e-01,  5.7904e-01,  8.6356e-01,\n",
            "           2.3320e-01,  1.6842e-02,  6.6973e-01,  8.6123e-01,  3.3113e-01],\n",
            "         [ 1.7427e+00,  2.0459e-01, -3.2806e-01,  5.6736e-01,  8.8970e-01,\n",
            "           2.3276e-01,  2.2254e-02,  6.6810e-01,  8.6062e-01,  3.2940e-01],\n",
            "         [ 1.8108e+00, -7.5541e-01, -1.7482e-01,  5.3238e-01,  9.1757e-01,\n",
            "           2.3147e-01,  3.0101e-02,  6.6368e-01,  8.5788e-01,  3.2472e-01],\n",
            "         [ 1.0433e+00, -1.3387e+00, -3.0450e-02,  4.7746e-01,  9.5005e-01,\n",
            "           2.2897e-01,  4.4428e-02,  6.5188e-01,  8.4950e-01,  3.1221e-01],\n",
            "         [ 1.4713e-01, -1.0271e+00,  9.9740e-02,  4.1017e-01,  9.9439e-01,\n",
            "           2.2438e-01,  7.5379e-02,  6.2118e-01,  8.2664e-01,  2.7959e-01],\n",
            "         [-5.0670e-02, -1.5009e-01,  2.0876e-01,  3.4584e-01,  1.0665e+00,\n",
            "           2.1572e-01,  1.4512e-01,  5.4639e-01,  7.6999e-01,  2.0005e-01]],\n",
            "\n",
            "        [[ 9.0148e-01,  6.6074e-01, -4.8652e-01,  5.8220e-01,  8.6735e-01,\n",
            "           2.3273e-01,  2.2139e-02,  6.6371e-01,  8.5662e-01,  3.2473e-01],\n",
            "         [ 1.7436e+00,  1.9156e-01, -3.3038e-01,  5.7585e-01,  8.9988e-01,\n",
            "           2.3150e-01,  3.6466e-02,  6.5195e-01,  8.4824e-01,  3.1221e-01],\n",
            "         [ 1.8132e+00, -7.8962e-01, -1.8090e-01,  5.5466e-01,  9.4430e-01,\n",
            "           2.2816e-01,  6.7418e-02,  6.2128e-01,  8.2538e-01,  2.7959e-01],\n",
            "         [ 1.0494e+00, -1.4237e+00, -4.5556e-02,  5.3281e-01,  1.0165e+00,\n",
            "           2.2075e-01,  1.3716e-01,  5.4652e-01,  7.6872e-01,  2.0006e-01],\n",
            "         [ 1.6047e-01, -1.2132e+00,  6.6678e-02,  5.3131e-01,  1.1398e+00,\n",
            "           2.0639e-01,  2.7832e-01,  3.9058e-01,  6.4985e-01,  3.4136e-02],\n",
            "         [-2.7744e-02, -4.6992e-01,  1.5193e-01,  5.5409e-01,  1.3164e+00,\n",
            "           1.8479e-01,  4.9397e-01,  1.4998e-01,  4.6609e-01, -2.2189e-01]],\n",
            "\n",
            "        [[ 9.5411e-01, -7.3407e-02, -6.1698e-01,  1.0602e+00,  1.4410e+00,\n",
            "           1.6174e-01,  8.2293e-01, -2.4624e-01,  1.5903e-01, -6.4383e-01],\n",
            "         [ 1.7999e+00, -5.9339e-01, -4.6986e-01,  1.0870e+00,  1.5132e+00,\n",
            "           1.5560e-01,  8.9267e-01, -3.2097e-01,  1.0238e-01, -7.2337e-01],\n",
            "         [ 1.8695e+00, -1.5746e+00, -3.2039e-01,  1.0658e+00,  1.5577e+00,\n",
            "           1.5226e-01,  9.2362e-01, -3.5164e-01,  7.9519e-02, -7.5599e-01],\n",
            "         [ 1.1020e+00, -2.1579e+00, -1.7602e-01,  1.0108e+00,  1.5901e+00,\n",
            "           1.4977e-01,  9.3795e-01, -3.6343e-01,  7.1137e-02, -7.6850e-01],\n",
            "         [ 2.0433e-01, -1.8251e+00, -4.2063e-02,  9.2976e-01,  1.6179e+00,\n",
            "           1.4722e-01,  9.4579e-01, -3.6788e-01,  6.8400e-02, -7.7318e-01],\n",
            "         [ 2.3041e-03, -8.8910e-01,  7.7439e-02,  8.2703e-01,  1.6439e+00,\n",
            "           1.4426e-01,  9.5120e-01, -3.6958e-01,  6.7785e-02, -7.7491e-01]],\n",
            "\n",
            "        [[ 9.1727e-01,  4.4048e-01, -5.2566e-01,  7.2562e-01,  1.0395e+00,\n",
            "           2.1143e-01,  2.6239e-01,  3.9071e-01,  6.4733e-01,  3.4139e-02],\n",
            "         [ 1.7727e+00, -2.1328e-01, -4.0232e-01,  8.3945e-01,  1.2162e+00,\n",
            "           1.9235e-01,  4.7805e-01,  1.5017e-01,  4.6356e-01, -2.2189e-01],\n",
            "         [ 1.8544e+00, -1.3638e+00, -2.8293e-01,  9.2853e-01,  1.3930e+00,\n",
            "           1.7264e-01,  6.9371e-01, -9.0392e-02,  2.7980e-01, -4.7792e-01],\n",
            "         [ 1.0952e+00, -2.0634e+00, -1.5922e-01,  9.4931e-01,  1.5163e+00,\n",
            "           1.5890e-01,  8.3487e-01, -2.4631e-01,  1.6093e-01, -6.4384e-01],\n",
            "         [ 2.0163e-01, -1.7873e+00, -3.5354e-02,  9.0518e-01,  1.5884e+00,\n",
            "           1.5087e-01,  9.0461e-01, -3.2109e-01,  1.0428e-01, -7.2337e-01],\n",
            "         [ 1.2760e-03, -8.7476e-01,  7.9988e-02,  8.1769e-01,  1.6327e+00,\n",
            "           1.4564e-01,  9.3556e-01, -3.5180e-01,  8.1412e-02, -7.5599e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "t tensor([[ 0],\n",
            "        [ 5],\n",
            "        [ 3],\n",
            "        [ 9],\n",
            "        [ 1],\n",
            "        [ 8],\n",
            "        [ 8],\n",
            "        [11],\n",
            "        [10],\n",
            "        [ 4],\n",
            "        [ 3],\n",
            "        [ 8],\n",
            "        [ 0],\n",
            "        [ 4],\n",
            "        [ 1]], dtype=torch.int32)\n",
            "b before tensor([[-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4]])\n",
            "b after tensor([[-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [ -5,  -4,  -3,  -2,  -1,   0,   1],\n",
            "        [ -7,  -6,  -5,  -4,  -3,  -2,  -1],\n",
            "        [ -1,   0,   1,   2,   3,   4,   5],\n",
            "        [ -9,  -8,  -7,  -6,  -5,  -4,  -3],\n",
            "        [ -2,  -1,   0,   1,   2,   3,   4],\n",
            "        [ -2,  -1,   0,   1,   2,   3,   4],\n",
            "        [  1,   2,   3,   4,   5,   6,   7],\n",
            "        [  0,   1,   2,   3,   4,   5,   6],\n",
            "        [ -6,  -5,  -4,  -3,  -2,  -1,   0],\n",
            "        [ -7,  -6,  -5,  -4,  -3,  -2,  -1],\n",
            "        [ -2,  -1,   0,   1,   2,   3,   4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [ -6,  -5,  -4,  -3,  -2,  -1,   0],\n",
            "        [ -9,  -8,  -7,  -6,  -5,  -4,  -3]])\n",
            "s torch.Size([15, 7])\n",
            "---------\n",
            "after positional encoding shapetensor([[[ 9.0094e-01,  6.6682e-01, -4.8565e-01,  5.7867e-01,  8.6321e-01,\n",
            "           2.3353e-01,  1.5917e-02,  6.7042e-01,  8.6199e-01,  3.3201e-01],\n",
            "         [ 1.7424e+00,  2.0706e-01, -3.2783e-01,  5.6618e-01,  8.8838e-01,\n",
            "           2.3321e-01,  1.9969e-02,  6.7033e-01,  8.6256e-01,  3.3193e-01],\n",
            "         [ 1.8103e+00, -7.4957e-01, -1.7399e-01,  5.2901e-01,  9.1362e-01,\n",
            "           2.3225e-01,  2.4144e-02,  6.7009e-01,  8.6302e-01,  3.3169e-01],\n",
            "         [ 1.0421e+00, -1.3239e+00, -2.8023e-02,  4.6822e-01,  9.3906e-01,\n",
            "           2.3062e-01,  2.8653e-02,  6.6945e-01,  8.6319e-01,  3.3105e-01],\n",
            "         [ 1.4429e-01, -9.8886e-01,  1.0633e-01,  3.8569e-01,  9.6511e-01,\n",
            "           2.2829e-01,  3.4064e-02,  6.6777e-01,  8.6258e-01,  3.2932e-01],\n",
            "         [-5.7579e-02, -5.5099e-02,  2.2543e-01,  2.8441e-01,  9.9284e-01,\n",
            "           2.2511e-01,  4.1911e-02,  6.6330e-01,  8.5984e-01,  3.2464e-01]],\n",
            "\n",
            "        [[ 9.0135e-01,  6.6124e-01, -4.8664e-01,  5.8231e-01,  8.6757e-01,\n",
            "           2.3299e-01,  2.2007e-02,  6.6350e-01,  8.5669e-01,  3.2465e-01],\n",
            "         [ 1.7435e+00,  1.9206e-01, -3.3050e-01,  5.7595e-01,  9.0010e-01,\n",
            "           2.3175e-01,  3.6334e-02,  6.5174e-01,  8.4831e-01,  3.1213e-01],\n",
            "         [ 1.8131e+00, -7.8911e-01, -1.8102e-01,  5.5477e-01,  9.4453e-01,\n",
            "           2.2841e-01,  6.7286e-02,  6.2106e-01,  8.2544e-01,  2.7951e-01],\n",
            "         [ 1.0493e+00, -1.4232e+00, -4.5669e-02,  5.3293e-01,  1.0167e+00,\n",
            "           2.2098e-01,  1.3703e-01,  5.4630e-01,  7.6879e-01,  1.9996e-01],\n",
            "         [ 1.6038e-01, -1.2126e+00,  6.6577e-02,  5.3145e-01,  1.1401e+00,\n",
            "           2.0656e-01,  2.7819e-01,  3.9035e-01,  6.4993e-01,  3.4027e-02],\n",
            "         [-2.7794e-02, -4.6932e-01,  1.5184e-01,  5.5426e-01,  1.3167e+00,\n",
            "           1.8488e-01,  4.9386e-01,  1.4972e-01,  4.6617e-01, -2.2203e-01]],\n",
            "\n",
            "        [[ 9.0100e-01,  6.6609e-01, -4.8578e-01,  5.7914e-01,  8.6378e-01,\n",
            "           2.3346e-01,  1.6710e-02,  6.6952e-01,  8.6130e-01,  3.3105e-01],\n",
            "         [ 1.7426e+00,  2.0509e-01, -3.2818e-01,  5.6746e-01,  8.8992e-01,\n",
            "           2.3302e-01,  2.2121e-02,  6.6789e-01,  8.6069e-01,  3.2932e-01],\n",
            "         [ 1.8106e+00, -7.5491e-01, -1.7494e-01,  5.3249e-01,  9.1779e-01,\n",
            "           2.3173e-01,  2.9969e-02,  6.6347e-01,  8.5795e-01,  3.2464e-01],\n",
            "         [ 1.0431e+00, -1.3382e+00, -3.0570e-02,  4.7756e-01,  9.5027e-01,\n",
            "           2.2923e-01,  4.4296e-02,  6.5167e-01,  8.4957e-01,  3.1213e-01],\n",
            "         [ 1.4700e-01, -1.0266e+00,  9.9621e-02,  4.1028e-01,  9.9462e-01,\n",
            "           2.2462e-01,  7.5248e-02,  6.2097e-01,  8.2670e-01,  2.7950e-01],\n",
            "         [-5.0786e-02, -1.4957e-01,  2.0865e-01,  3.4596e-01,  1.0667e+00,\n",
            "           2.1594e-01,  1.4499e-01,  5.4617e-01,  7.7006e-01,  1.9996e-01]],\n",
            "\n",
            "        [[ 9.1718e-01,  4.4103e-01, -5.2576e-01,  7.2576e-01,  1.0398e+00,\n",
            "           2.1160e-01,  2.6227e-01,  3.9047e-01,  6.4740e-01,  3.4031e-02],\n",
            "         [ 1.7726e+00, -2.1268e-01, -4.0240e-01,  8.3962e-01,  1.2166e+00,\n",
            "           1.9244e-01,  4.7793e-01,  1.4991e-01,  4.6364e-01, -2.2202e-01],\n",
            "         [ 1.8544e+00, -1.3631e+00, -2.8300e-01,  9.2873e-01,  1.3934e+00,\n",
            "           1.7265e-01,  6.9360e-01, -9.0674e-02,  2.7988e-01, -4.7807e-01],\n",
            "         [ 1.0952e+00, -2.0627e+00, -1.5928e-01,  9.4954e-01,  1.5168e+00,\n",
            "           1.5886e-01,  8.3477e-01, -2.4661e-01,  1.6102e-01, -6.4401e-01],\n",
            "         [ 2.0165e-01, -1.7866e+00, -3.5403e-02,  9.0541e-01,  1.5889e+00,\n",
            "           1.5080e-01,  9.0450e-01, -3.2139e-01,  1.0437e-01, -7.2355e-01],\n",
            "         [ 1.3095e-03, -8.7406e-01,  7.9941e-02,  8.1793e-01,  1.6332e+00,\n",
            "           1.4557e-01,  9.3546e-01, -3.5211e-01,  8.1506e-02, -7.5618e-01]],\n",
            "\n",
            "        [[ 9.0095e-01,  6.6676e-01, -4.8566e-01,  5.7871e-01,  8.6326e-01,\n",
            "           2.3353e-01,  1.5988e-02,  6.7034e-01,  8.6193e-01,  3.3193e-01],\n",
            "         [ 1.7424e+00,  2.0688e-01, -3.2787e-01,  5.6629e-01,  8.8851e-01,\n",
            "           2.3319e-01,  2.0163e-02,  6.7011e-01,  8.6239e-01,  3.3169e-01],\n",
            "         [ 1.8103e+00, -7.5005e-01, -1.7408e-01,  5.2932e-01,  9.1399e-01,\n",
            "           2.3220e-01,  2.4672e-02,  6.6949e-01,  8.6256e-01,  3.3105e-01],\n",
            "         [ 1.0422e+00, -1.3252e+00, -2.8256e-02,  4.6908e-01,  9.4009e-01,\n",
            "           2.3050e-01,  3.0083e-02,  6.6782e-01,  8.6195e-01,  3.2932e-01],\n",
            "         [ 1.4454e-01, -9.9240e-01,  1.0570e-01,  3.8800e-01,  9.6788e-01,\n",
            "           2.2795e-01,  3.7930e-02,  6.6337e-01,  8.5921e-01,  3.2464e-01],\n",
            "         [-5.6897e-02, -6.4581e-02,  2.2375e-01,  2.9059e-01,  1.0003e+00,\n",
            "           2.2419e-01,  5.2257e-02,  6.5155e-01,  8.5083e-01,  3.1213e-01]],\n",
            "\n",
            "        [[ 9.0814e-01,  5.6677e-01, -5.0342e-01,  6.4385e-01,  9.4144e-01,\n",
            "           2.2381e-01,  1.2508e-01,  5.4637e-01,  7.6690e-01,  1.9997e-01],\n",
            "         [ 1.7587e+00, -1.8663e-02, -3.6793e-01,  7.1323e-01,  1.0649e+00,\n",
            "           2.1129e-01,  2.6625e-01,  3.9046e-01,  6.4804e-01,  3.4030e-02],\n",
            "         [ 1.8404e+00, -1.1691e+00, -2.4853e-01,  8.0233e-01,  1.2417e+00,\n",
            "           1.9149e-01,  4.8191e-01,  1.4988e-01,  4.6427e-01, -2.2202e-01],\n",
            "         [ 1.0862e+00, -1.9370e+00, -1.3694e-01,  8.6763e-01,  1.4184e+00,\n",
            "           1.7107e-01,  6.9758e-01, -9.0714e-02,  2.8051e-01, -4.7807e-01],\n",
            "         [ 1.9732e-01, -1.7264e+00, -2.4696e-02,  8.6615e-01,  1.5418e+00,\n",
            "           1.5666e-01,  8.3875e-01, -2.4666e-01,  1.6165e-01, -6.4401e-01],\n",
            "         [-4.6808e-04, -8.4934e-01,  8.4332e-02,  8.0183e-01,  1.6139e+00,\n",
            "           1.4797e-01,  9.0849e-01, -3.2146e-01,  1.0500e-01, -7.2355e-01]],\n",
            "\n",
            "        [[ 9.0814e-01,  5.6677e-01, -5.0342e-01,  6.4385e-01,  9.4144e-01,\n",
            "           2.2381e-01,  1.2508e-01,  5.4637e-01,  7.6690e-01,  1.9997e-01],\n",
            "         [ 1.7587e+00, -1.8663e-02, -3.6793e-01,  7.1323e-01,  1.0649e+00,\n",
            "           2.1129e-01,  2.6625e-01,  3.9046e-01,  6.4804e-01,  3.4030e-02],\n",
            "         [ 1.8404e+00, -1.1691e+00, -2.4853e-01,  8.0233e-01,  1.2417e+00,\n",
            "           1.9149e-01,  4.8191e-01,  1.4988e-01,  4.6427e-01, -2.2202e-01],\n",
            "         [ 1.0862e+00, -1.9370e+00, -1.3694e-01,  8.6763e-01,  1.4184e+00,\n",
            "           1.7107e-01,  6.9758e-01, -9.0714e-02,  2.8051e-01, -4.7807e-01],\n",
            "         [ 1.9732e-01, -1.7264e+00, -2.4696e-02,  8.6615e-01,  1.5418e+00,\n",
            "           1.5666e-01,  8.3875e-01, -2.4666e-01,  1.6165e-01, -6.4401e-01],\n",
            "         [-4.6808e-04, -8.4934e-01,  8.4332e-02,  8.0183e-01,  1.6139e+00,\n",
            "           1.4797e-01,  9.0849e-01, -3.2146e-01,  1.0500e-01, -7.2355e-01]],\n",
            "\n",
            "        [[ 9.4508e-01,  5.3005e-02, -5.9470e-01,  9.7855e-01,  1.3432e+00,\n",
            "           1.7391e-01,  6.8564e-01, -9.0642e-02,  2.7862e-01, -4.7807e-01],\n",
            "         [ 1.7956e+00, -5.3243e-01, -4.5921e-01,  1.0479e+00,  1.4666e+00,\n",
            "           1.6138e-01,  8.2680e-01, -2.4654e-01,  1.5976e-01, -6.4401e-01],\n",
            "         [ 1.8678e+00, -1.5491e+00, -3.1604e-01,  1.0499e+00,  1.5388e+00,\n",
            "           1.5458e-01,  8.9654e-01, -3.2130e-01,  1.0311e-01, -7.2355e-01],\n",
            "         [ 1.1014e+00, -2.1477e+00, -1.7438e-01,  1.0049e+00,  1.5832e+00,\n",
            "           1.5061e-01,  9.2750e-01, -3.5199e-01,  8.0244e-02, -7.5617e-01],\n",
            "         [ 2.0411e-01, -1.8208e+00, -4.1480e-02,  9.2769e-01,  1.6156e+00,\n",
            "           1.4748e-01,  9.4182e-01, -3.6380e-01,  7.1862e-02, -7.6869e-01],\n",
            "         [ 2.2461e-03, -8.8708e-01,  7.7626e-02,  8.2642e-01,  1.6434e+00,\n",
            "           1.4430e-01,  9.4967e-01, -3.6826e-01,  6.9126e-02, -7.7337e-01]],\n",
            "\n",
            "        [[ 9.3113e-01,  2.4702e-01, -5.6023e-01,  8.5215e-01,  1.1915e+00,\n",
            "           1.9276e-01,  4.7395e-01,  1.4991e-01,  4.6301e-01, -2.2202e-01],\n",
            "         [ 1.7866e+00, -4.0669e-01, -4.3687e-01,  9.6601e-01,  1.3683e+00,\n",
            "           1.7360e-01,  6.8962e-01, -9.0650e-02,  2.7925e-01, -4.7807e-01],\n",
            "         [ 1.8634e+00, -1.4889e+00, -3.0534e-01,  1.0106e+00,  1.4917e+00,\n",
            "           1.6044e-01,  8.3078e-01, -2.4657e-01,  1.6039e-01, -6.4401e-01],\n",
            "         [ 1.0996e+00, -2.1230e+00, -1.6999e-01,  9.8880e-01,  1.5639e+00,\n",
            "           1.5301e-01,  9.0052e-01, -3.2134e-01,  1.0374e-01, -7.2355e-01],\n",
            "         [ 2.0343e-01, -1.8114e+00, -3.9795e-02,  9.2151e-01,  1.6082e+00,\n",
            "           1.4840e-01,  9.3148e-01, -3.5204e-01,  8.0875e-02, -7.5617e-01],\n",
            "         [ 1.9913e-03, -8.8354e-01,  7.8256e-02,  8.2411e-01,  1.6406e+00,\n",
            "           1.4465e-01,  9.4580e-01, -3.6387e-01,  7.2493e-02, -7.6869e-01]],\n",
            "\n",
            "        [[ 9.0109e-01,  6.6478e-01, -4.8601e-01,  5.8000e-01,  8.6480e-01,\n",
            "           2.3333e-01,  1.8140e-02,  6.6790e-01,  8.6005e-01,  3.2932e-01],\n",
            "         [ 1.7428e+00,  2.0154e-01, -3.2881e-01,  5.6977e-01,  8.9269e-01,\n",
            "           2.3267e-01,  2.5988e-02,  6.6349e-01,  8.5732e-01,  3.2464e-01],\n",
            "         [ 1.8113e+00, -7.6439e-01, -1.7663e-01,  5.3866e-01,  9.2520e-01,\n",
            "           2.3081e-01,  4.0315e-02,  6.5171e-01,  8.4894e-01,  3.1213e-01],\n",
            "         [ 1.0449e+00, -1.3630e+00, -3.4962e-02,  4.9367e-01,  9.6960e-01,\n",
            "           2.2683e-01,  7.1267e-02,  6.2102e-01,  8.2607e-01,  2.7950e-01],\n",
            "         [ 1.5134e-01, -1.0869e+00,  8.8914e-02,  4.4954e-01,  1.0417e+00,\n",
            "           2.1877e-01,  1.4101e-01,  5.4624e-01,  7.6942e-01,  1.9996e-01],\n",
            "         [-4.1745e-02, -2.7530e-01,  1.8631e-01,  4.2787e-01,  1.1650e+00,\n",
            "           2.0372e-01,  2.8217e-01,  3.9027e-01,  6.5056e-01,  3.4026e-02]],\n",
            "\n",
            "        [[ 9.0100e-01,  6.6609e-01, -4.8578e-01,  5.7914e-01,  8.6378e-01,\n",
            "           2.3346e-01,  1.6710e-02,  6.6952e-01,  8.6130e-01,  3.3105e-01],\n",
            "         [ 1.7426e+00,  2.0509e-01, -3.2818e-01,  5.6746e-01,  8.8992e-01,\n",
            "           2.3302e-01,  2.2121e-02,  6.6789e-01,  8.6069e-01,  3.2932e-01],\n",
            "         [ 1.8106e+00, -7.5491e-01, -1.7494e-01,  5.3249e-01,  9.1779e-01,\n",
            "           2.3173e-01,  2.9969e-02,  6.6347e-01,  8.5795e-01,  3.2464e-01],\n",
            "         [ 1.0431e+00, -1.3382e+00, -3.0570e-02,  4.7756e-01,  9.5027e-01,\n",
            "           2.2923e-01,  4.4296e-02,  6.5167e-01,  8.4957e-01,  3.1213e-01],\n",
            "         [ 1.4700e-01, -1.0266e+00,  9.9621e-02,  4.1028e-01,  9.9462e-01,\n",
            "           2.2462e-01,  7.5248e-02,  6.2097e-01,  8.2670e-01,  2.7950e-01],\n",
            "         [-5.0786e-02, -1.4957e-01,  2.0865e-01,  3.4596e-01,  1.0667e+00,\n",
            "           2.1594e-01,  1.4499e-01,  5.4617e-01,  7.7006e-01,  1.9996e-01]],\n",
            "\n",
            "        [[ 9.0814e-01,  5.6677e-01, -5.0342e-01,  6.4385e-01,  9.4144e-01,\n",
            "           2.2381e-01,  1.2508e-01,  5.4637e-01,  7.6690e-01,  1.9997e-01],\n",
            "         [ 1.7587e+00, -1.8663e-02, -3.6793e-01,  7.1323e-01,  1.0649e+00,\n",
            "           2.1129e-01,  2.6625e-01,  3.9046e-01,  6.4804e-01,  3.4030e-02],\n",
            "         [ 1.8404e+00, -1.1691e+00, -2.4853e-01,  8.0233e-01,  1.2417e+00,\n",
            "           1.9149e-01,  4.8191e-01,  1.4988e-01,  4.6427e-01, -2.2202e-01],\n",
            "         [ 1.0862e+00, -1.9370e+00, -1.3694e-01,  8.6763e-01,  1.4184e+00,\n",
            "           1.7107e-01,  6.9758e-01, -9.0714e-02,  2.8051e-01, -4.7807e-01],\n",
            "         [ 1.9732e-01, -1.7264e+00, -2.4696e-02,  8.6615e-01,  1.5418e+00,\n",
            "           1.5666e-01,  8.3875e-01, -2.4666e-01,  1.6165e-01, -6.4401e-01],\n",
            "         [-4.6808e-04, -8.4934e-01,  8.4332e-02,  8.0183e-01,  1.6139e+00,\n",
            "           1.4797e-01,  9.0849e-01, -3.2146e-01,  1.0500e-01, -7.2355e-01]],\n",
            "\n",
            "        [[ 9.0094e-01,  6.6682e-01, -4.8565e-01,  5.7867e-01,  8.6321e-01,\n",
            "           2.3353e-01,  1.5917e-02,  6.7042e-01,  8.6199e-01,  3.3201e-01],\n",
            "         [ 1.7424e+00,  2.0706e-01, -3.2783e-01,  5.6618e-01,  8.8838e-01,\n",
            "           2.3321e-01,  1.9969e-02,  6.7033e-01,  8.6256e-01,  3.3193e-01],\n",
            "         [ 1.8103e+00, -7.4957e-01, -1.7399e-01,  5.2901e-01,  9.1362e-01,\n",
            "           2.3225e-01,  2.4144e-02,  6.7009e-01,  8.6302e-01,  3.3169e-01],\n",
            "         [ 1.0421e+00, -1.3239e+00, -2.8023e-02,  4.6822e-01,  9.3906e-01,\n",
            "           2.3062e-01,  2.8653e-02,  6.6945e-01,  8.6319e-01,  3.3105e-01],\n",
            "         [ 1.4429e-01, -9.8886e-01,  1.0633e-01,  3.8569e-01,  9.6511e-01,\n",
            "           2.2829e-01,  3.4064e-02,  6.6777e-01,  8.6258e-01,  3.2932e-01],\n",
            "         [-5.7579e-02, -5.5099e-02,  2.2543e-01,  2.8441e-01,  9.9284e-01,\n",
            "           2.2511e-01,  4.1911e-02,  6.6330e-01,  8.5984e-01,  3.2464e-01]],\n",
            "\n",
            "        [[ 9.0109e-01,  6.6478e-01, -4.8601e-01,  5.8000e-01,  8.6480e-01,\n",
            "           2.3333e-01,  1.8140e-02,  6.6790e-01,  8.6005e-01,  3.2932e-01],\n",
            "         [ 1.7428e+00,  2.0154e-01, -3.2881e-01,  5.6977e-01,  8.9269e-01,\n",
            "           2.3267e-01,  2.5988e-02,  6.6349e-01,  8.5732e-01,  3.2464e-01],\n",
            "         [ 1.8113e+00, -7.6439e-01, -1.7663e-01,  5.3866e-01,  9.2520e-01,\n",
            "           2.3081e-01,  4.0315e-02,  6.5171e-01,  8.4894e-01,  3.1213e-01],\n",
            "         [ 1.0449e+00, -1.3630e+00, -3.4962e-02,  4.9367e-01,  9.6960e-01,\n",
            "           2.2683e-01,  7.1267e-02,  6.2102e-01,  8.2607e-01,  2.7950e-01],\n",
            "         [ 1.5134e-01, -1.0869e+00,  8.8914e-02,  4.4954e-01,  1.0417e+00,\n",
            "           2.1877e-01,  1.4101e-01,  5.4624e-01,  7.6942e-01,  1.9996e-01],\n",
            "         [-4.1745e-02, -2.7530e-01,  1.8631e-01,  4.2787e-01,  1.1650e+00,\n",
            "           2.0372e-01,  2.8217e-01,  3.9027e-01,  6.5056e-01,  3.4026e-02]],\n",
            "\n",
            "        [[ 9.0095e-01,  6.6676e-01, -4.8566e-01,  5.7871e-01,  8.6326e-01,\n",
            "           2.3353e-01,  1.5988e-02,  6.7034e-01,  8.6193e-01,  3.3193e-01],\n",
            "         [ 1.7424e+00,  2.0688e-01, -3.2787e-01,  5.6629e-01,  8.8851e-01,\n",
            "           2.3319e-01,  2.0163e-02,  6.7011e-01,  8.6239e-01,  3.3169e-01],\n",
            "         [ 1.8103e+00, -7.5005e-01, -1.7408e-01,  5.2932e-01,  9.1399e-01,\n",
            "           2.3220e-01,  2.4672e-02,  6.6949e-01,  8.6256e-01,  3.3105e-01],\n",
            "         [ 1.0422e+00, -1.3252e+00, -2.8256e-02,  4.6908e-01,  9.4009e-01,\n",
            "           2.3050e-01,  3.0083e-02,  6.6782e-01,  8.6195e-01,  3.2932e-01],\n",
            "         [ 1.4454e-01, -9.9240e-01,  1.0570e-01,  3.8800e-01,  9.6788e-01,\n",
            "           2.2795e-01,  3.7930e-02,  6.6337e-01,  8.5921e-01,  3.2464e-01],\n",
            "         [-5.6897e-02, -6.4581e-02,  2.2375e-01,  2.9059e-01,  1.0003e+00,\n",
            "           2.2419e-01,  5.2257e-02,  6.5155e-01,  8.5083e-01,  3.1213e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "t tensor([[ 2],\n",
            "        [ 3],\n",
            "        [ 2],\n",
            "        [ 6],\n",
            "        [12],\n",
            "        [ 8],\n",
            "        [ 7],\n",
            "        [ 3],\n",
            "        [ 4],\n",
            "        [ 9],\n",
            "        [ 8],\n",
            "        [ 9],\n",
            "        [ 7],\n",
            "        [10],\n",
            "        [ 5]], dtype=torch.int32)\n",
            "b before tensor([[-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4]])\n",
            "b after tensor([[-8, -7, -6, -5, -4, -3, -2],\n",
            "        [-7, -6, -5, -4, -3, -2, -1],\n",
            "        [-8, -7, -6, -5, -4, -3, -2],\n",
            "        [-4, -3, -2, -1,  0,  1,  2],\n",
            "        [ 2,  3,  4,  5,  6,  7,  8],\n",
            "        [-2, -1,  0,  1,  2,  3,  4],\n",
            "        [-3, -2, -1,  0,  1,  2,  3],\n",
            "        [-7, -6, -5, -4, -3, -2, -1],\n",
            "        [-6, -5, -4, -3, -2, -1,  0],\n",
            "        [-1,  0,  1,  2,  3,  4,  5],\n",
            "        [-2, -1,  0,  1,  2,  3,  4],\n",
            "        [-1,  0,  1,  2,  3,  4,  5],\n",
            "        [-3, -2, -1,  0,  1,  2,  3],\n",
            "        [ 0,  1,  2,  3,  4,  5,  6],\n",
            "        [-5, -4, -3, -2, -1,  0,  1]])\n",
            "s torch.Size([15, 7])\n",
            "---------\n",
            "after positional encoding shapetensor([[[ 9.0082e-01,  6.6710e-01, -4.8581e-01,  5.7894e-01,  8.6364e-01,\n",
            "           2.3378e-01,  1.6032e-02,  6.6990e-01,  8.6181e-01,  3.3162e-01],\n",
            "         [ 1.7423e+00,  2.0692e-01, -3.2807e-01,  5.6672e-01,  8.8913e-01,\n",
            "           2.3342e-01,  2.0540e-02,  6.6929e-01,  8.6198e-01,  3.3098e-01],\n",
            "         [ 1.8103e+00, -7.5084e-01, -1.7443e-01,  5.3029e-01,  9.1526e-01,\n",
            "           2.3235e-01,  2.5952e-02,  6.6764e-01,  8.6137e-01,  3.2925e-01],\n",
            "         [ 1.0423e+00, -1.3282e+00, -2.9007e-02,  4.7149e-01,  9.4310e-01,\n",
            "           2.3042e-01,  3.3799e-02,  6.6321e-01,  8.5863e-01,  3.2457e-01],\n",
            "         [ 1.4509e-01, -1.0014e+00,  1.0389e-01,  3.9428e-01,  9.7554e-01,\n",
            "           2.2729e-01,  4.8127e-02,  6.5139e-01,  8.5025e-01,  3.1205e-01],\n",
            "         [-5.5247e-02, -8.8767e-02,  2.1924e-01,  3.0681e-01,  1.0198e+00,\n",
            "           2.2205e-01,  7.9079e-02,  6.2067e-01,  8.2739e-01,  2.7942e-01]],\n",
            "\n",
            "        [[ 9.0086e-01,  6.6662e-01, -4.8590e-01,  5.7925e-01,  8.6402e-01,\n",
            "           2.3373e-01,  1.6559e-02,  6.6930e-01,  8.6135e-01,  3.3098e-01],\n",
            "         [ 1.7424e+00,  2.0561e-01, -3.2831e-01,  5.6757e-01,  8.9016e-01,\n",
            "           2.3329e-01,  2.1971e-02,  6.6766e-01,  8.6074e-01,  3.2925e-01],\n",
            "         [ 1.8105e+00, -7.5438e-01, -1.7506e-01,  5.3260e-01,  9.1803e-01,\n",
            "           2.3200e-01,  2.9819e-02,  6.6325e-01,  8.5800e-01,  3.2457e-01],\n",
            "         [ 1.0430e+00, -1.3377e+00, -3.0690e-02,  4.7767e-01,  9.5052e-01,\n",
            "           2.2950e-01,  4.4146e-02,  6.5145e-01,  8.4962e-01,  3.1205e-01],\n",
            "         [ 1.4687e-01, -1.0261e+00,  9.9504e-02,  4.1039e-01,  9.9488e-01,\n",
            "           2.2488e-01,  7.5099e-02,  6.2074e-01,  8.2676e-01,  2.7942e-01],\n",
            "         [-5.0901e-02, -1.4902e-01,  2.0854e-01,  3.4608e-01,  1.0670e+00,\n",
            "           2.1617e-01,  1.4484e-01,  5.4593e-01,  7.7011e-01,  1.9987e-01]],\n",
            "\n",
            "        [[ 9.0082e-01,  6.6710e-01, -4.8581e-01,  5.7894e-01,  8.6364e-01,\n",
            "           2.3378e-01,  1.6032e-02,  6.6990e-01,  8.6181e-01,  3.3162e-01],\n",
            "         [ 1.7423e+00,  2.0692e-01, -3.2807e-01,  5.6672e-01,  8.8913e-01,\n",
            "           2.3342e-01,  2.0540e-02,  6.6929e-01,  8.6198e-01,  3.3098e-01],\n",
            "         [ 1.8103e+00, -7.5084e-01, -1.7443e-01,  5.3029e-01,  9.1526e-01,\n",
            "           2.3235e-01,  2.5952e-02,  6.6764e-01,  8.6137e-01,  3.2925e-01],\n",
            "         [ 1.0423e+00, -1.3282e+00, -2.9007e-02,  4.7149e-01,  9.4310e-01,\n",
            "           2.3042e-01,  3.3799e-02,  6.6321e-01,  8.5863e-01,  3.2457e-01],\n",
            "         [ 1.4509e-01, -1.0014e+00,  1.0389e-01,  3.9428e-01,  9.7554e-01,\n",
            "           2.2729e-01,  4.8127e-02,  6.5139e-01,  8.5025e-01,  3.1205e-01],\n",
            "         [-5.5247e-02, -8.8767e-02,  2.1924e-01,  3.0681e-01,  1.0198e+00,\n",
            "           2.2205e-01,  7.9079e-02,  6.2067e-01,  8.2739e-01,  2.7942e-01]],\n",
            "\n",
            "        [[ 9.0189e-01,  6.5228e-01, -4.8844e-01,  5.8859e-01,  8.7523e-01,\n",
            "           2.3234e-01,  3.2203e-02,  6.5152e-01,  8.4773e-01,  3.1205e-01],\n",
            "         [ 1.7451e+00,  1.6787e-01, -3.3501e-01,  5.9217e-01,  9.1969e-01,\n",
            "           2.2961e-01,  6.3157e-02,  6.2086e-01,  8.2487e-01,  2.7943e-01],\n",
            "         [ 1.8173e+00, -8.4883e-01, -1.9184e-01,  5.9416e-01,  9.9193e-01,\n",
            "           2.2278e-01,  1.3290e-01,  5.4610e-01,  7.6822e-01,  1.9988e-01],\n",
            "         [ 1.0582e+00, -1.5484e+00, -6.8105e-02,  6.1498e-01,  1.1154e+00,\n",
            "           2.0894e-01,  2.7407e-01,  3.9015e-01,  6.4936e-01,  3.3924e-02],\n",
            "         [ 1.7428e-01, -1.4060e+00,  3.2029e-02,  6.5802e-01,  1.2921e+00,\n",
            "           1.8781e-01,  4.8974e-01,  1.4951e-01,  4.6560e-01, -2.2216e-01],\n",
            "         [-1.3846e-02, -6.6266e-01,  1.1732e-01,  6.8085e-01,  1.4689e+00,\n",
            "           1.6604e-01,  7.0541e-01, -9.1141e-02,  2.8185e-01, -4.7823e-01]],\n",
            "\n",
            "        [[ 9.5415e-01, -7.2021e-02, -6.1708e-01,  1.0607e+00,  1.4420e+00,\n",
            "           1.6165e-01,  8.2270e-01, -2.4685e-01,  1.5920e-01, -6.4418e-01],\n",
            "         [ 1.8000e+00, -5.9197e-01, -4.6996e-01,  1.0874e+00,  1.5142e+00,\n",
            "           1.5546e-01,  8.9244e-01, -3.2160e-01,  1.0255e-01, -7.2373e-01],\n",
            "         [ 1.8696e+00, -1.5731e+00, -3.2048e-01,  1.0662e+00,  1.5587e+00,\n",
            "           1.5210e-01,  9.2339e-01, -3.5227e-01,  7.9693e-02, -7.5636e-01],\n",
            "         [ 1.1021e+00, -2.1565e+00, -1.7610e-01,  1.0113e+00,  1.5912e+00,\n",
            "           1.4960e-01,  9.3772e-01, -3.6407e-01,  7.1311e-02, -7.6888e-01],\n",
            "         [ 2.0441e-01, -1.8237e+00, -4.2148e-02,  9.3024e-01,  1.6189e+00,\n",
            "           1.4705e-01,  9.4557e-01, -3.6852e-01,  6.8575e-02, -7.7356e-01],\n",
            "         [ 2.3863e-03, -8.8766e-01,  7.7355e-02,  8.2751e-01,  1.6449e+00,\n",
            "           1.4409e-01,  9.5098e-01, -3.7022e-01,  6.7959e-02, -7.7529e-01]],\n",
            "\n",
            "        [[ 9.0802e-01,  5.6732e-01, -5.0354e-01,  6.4397e-01,  9.4172e-01,\n",
            "           2.2404e-01,  1.2494e-01,  5.4613e-01,  7.6696e-01,  1.9988e-01],\n",
            "         [ 1.7586e+00, -1.8083e-02, -3.6803e-01,  7.1337e-01,  1.0652e+00,\n",
            "           2.1146e-01,  2.6611e-01,  3.9021e-01,  6.4810e-01,  3.3925e-02],\n",
            "         [ 1.8404e+00, -1.1685e+00, -2.4861e-01,  8.0251e-01,  1.2421e+00,\n",
            "           1.9159e-01,  4.8178e-01,  1.4961e-01,  4.6434e-01, -2.2215e-01],\n",
            "         [ 1.0862e+00, -1.9363e+00, -1.3700e-01,  8.6783e-01,  1.4189e+00,\n",
            "           1.7108e-01,  6.9745e-01, -9.1015e-02,  2.8059e-01, -4.7823e-01],\n",
            "         [ 1.9734e-01, -1.7257e+00, -2.4744e-02,  8.6637e-01,  1.5423e+00,\n",
            "           1.5661e-01,  8.3862e-01, -2.4698e-01,  1.6173e-01, -6.4419e-01],\n",
            "         [-4.3070e-04, -8.4861e-01,  8.4290e-02,  8.0206e-01,  1.6144e+00,\n",
            "           1.4790e-01,  9.0836e-01, -3.2179e-01,  1.0508e-01, -7.2374e-01]],\n",
            "\n",
            "        [[ 9.0368e-01,  6.2757e-01, -4.9283e-01,  6.0470e-01,  8.9457e-01,\n",
            "           2.2992e-01,  5.9175e-02,  6.2087e-01,  8.2423e-01,  2.7943e-01],\n",
            "         [ 1.7495e+00,  1.0762e-01, -3.4571e-01,  6.3144e-01,  9.6683e-01,\n",
            "           2.2373e-01,  1.2892e-01,  5.4612e-01,  7.6759e-01,  1.9988e-01],\n",
            "         [ 1.8264e+00, -9.7453e-01, -2.1416e-01,  6.7608e-01,  1.0903e+00,\n",
            "           2.1052e-01,  2.7009e-01,  3.9019e-01,  6.4873e-01,  3.3925e-02],\n",
            "         [ 1.0722e+00, -1.7423e+00, -1.0255e-01,  7.4140e-01,  1.2671e+00,\n",
            "           1.9001e-01,  4.8576e-01,  1.4957e-01,  4.6497e-01, -2.2215e-01],\n",
            "         [ 1.8828e-01, -1.6000e+00, -2.4197e-03,  7.8444e-01,  1.4439e+00,\n",
            "           1.6888e-01,  7.0143e-01, -9.1070e-02,  2.8122e-01, -4.7823e-01],\n",
            "         [-4.7776e-03, -7.8836e-01,  9.4991e-02,  7.6278e-01,  1.5672e+00,\n",
            "           1.5378e-01,  8.4260e-01, -2.4705e-01,  1.6236e-01, -6.4419e-01]],\n",
            "\n",
            "        [[ 9.0086e-01,  6.6662e-01, -4.8590e-01,  5.7925e-01,  8.6402e-01,\n",
            "           2.3373e-01,  1.6559e-02,  6.6930e-01,  8.6135e-01,  3.3098e-01],\n",
            "         [ 1.7424e+00,  2.0561e-01, -3.2831e-01,  5.6757e-01,  8.9016e-01,\n",
            "           2.3329e-01,  2.1971e-02,  6.6766e-01,  8.6074e-01,  3.2925e-01],\n",
            "         [ 1.8105e+00, -7.5438e-01, -1.7506e-01,  5.3260e-01,  9.1803e-01,\n",
            "           2.3200e-01,  2.9819e-02,  6.6325e-01,  8.5800e-01,  3.2457e-01],\n",
            "         [ 1.0430e+00, -1.3377e+00, -3.0690e-02,  4.7767e-01,  9.5052e-01,\n",
            "           2.2950e-01,  4.4146e-02,  6.5145e-01,  8.4962e-01,  3.1205e-01],\n",
            "         [ 1.4687e-01, -1.0261e+00,  9.9504e-02,  4.1039e-01,  9.9488e-01,\n",
            "           2.2488e-01,  7.5099e-02,  6.2074e-01,  8.2676e-01,  2.7942e-01],\n",
            "         [-5.0901e-02, -1.4902e-01,  2.0854e-01,  3.4608e-01,  1.0670e+00,\n",
            "           2.1617e-01,  1.4484e-01,  5.4593e-01,  7.7011e-01,  1.9987e-01]],\n",
            "\n",
            "        [[ 9.0095e-01,  6.6531e-01, -4.8613e-01,  5.8011e-01,  8.6504e-01,\n",
            "           2.3361e-01,  1.7990e-02,  6.6767e-01,  8.6011e-01,  3.2925e-01],\n",
            "         [ 1.7427e+00,  2.0207e-01, -3.2893e-01,  5.6988e-01,  8.9293e-01,\n",
            "           2.3295e-01,  2.5838e-02,  6.6327e-01,  8.5737e-01,  3.2457e-01],\n",
            "         [ 1.8112e+00, -7.6386e-01, -1.7675e-01,  5.3878e-01,  9.2545e-01,\n",
            "           2.3107e-01,  4.0165e-02,  6.5149e-01,  8.4899e-01,  3.1205e-01],\n",
            "         [ 1.0448e+00, -1.3624e+00, -3.5079e-02,  4.9378e-01,  9.6986e-01,\n",
            "           2.2709e-01,  7.1118e-02,  6.2079e-01,  8.2613e-01,  2.7942e-01],\n",
            "         [ 1.5122e-01, -1.0863e+00,  8.8802e-02,  4.4966e-01,  1.0420e+00,\n",
            "           2.1900e-01,  1.4086e-01,  5.4600e-01,  7.6948e-01,  1.9987e-01],\n",
            "         [-4.1832e-02, -2.7472e-01,  1.8621e-01,  4.2801e-01,  1.1653e+00,\n",
            "           2.0390e-01,  2.8203e-01,  3.9002e-01,  6.5062e-01,  3.3920e-02]],\n",
            "\n",
            "        [[ 9.1709e-01,  4.4161e-01, -5.2586e-01,  7.2590e-01,  1.0401e+00,\n",
            "           2.1178e-01,  2.6212e-01,  3.9022e-01,  6.4746e-01,  3.3925e-02],\n",
            "         [ 1.7726e+00, -2.1205e-01, -4.0248e-01,  8.3979e-01,  1.2170e+00,\n",
            "           1.9253e-01,  4.7780e-01,  1.4963e-01,  4.6371e-01, -2.2215e-01],\n",
            "         [ 1.8544e+00, -1.3625e+00, -2.8306e-01,  9.2893e-01,  1.3938e+00,\n",
            "           1.7266e-01,  6.9347e-01, -9.0975e-02,  2.7996e-01, -4.7823e-01],\n",
            "         [ 1.0953e+00, -2.0620e+00, -1.5933e-01,  9.4976e-01,  1.5173e+00,\n",
            "           1.5882e-01,  8.3464e-01, -2.4692e-01,  1.6109e-01, -6.4418e-01],\n",
            "         [ 2.0169e-01, -1.7859e+00, -3.5446e-02,  9.0564e-01,  1.5894e+00,\n",
            "           1.5073e-01,  9.0438e-01, -3.2172e-01,  1.0445e-01, -7.2373e-01],\n",
            "         [ 1.3522e-03, -8.7333e-01,  7.9901e-02,  8.1816e-01,  1.6337e+00,\n",
            "           1.4548e-01,  9.3533e-01, -3.5244e-01,  8.1585e-02, -7.5636e-01]],\n",
            "\n",
            "        [[ 9.0802e-01,  5.6732e-01, -5.0354e-01,  6.4397e-01,  9.4172e-01,\n",
            "           2.2404e-01,  1.2494e-01,  5.4613e-01,  7.6696e-01,  1.9988e-01],\n",
            "         [ 1.7586e+00, -1.8083e-02, -3.6803e-01,  7.1337e-01,  1.0652e+00,\n",
            "           2.1146e-01,  2.6611e-01,  3.9021e-01,  6.4810e-01,  3.3925e-02],\n",
            "         [ 1.8404e+00, -1.1685e+00, -2.4861e-01,  8.0251e-01,  1.2421e+00,\n",
            "           1.9159e-01,  4.8178e-01,  1.4961e-01,  4.6434e-01, -2.2215e-01],\n",
            "         [ 1.0862e+00, -1.9363e+00, -1.3700e-01,  8.6783e-01,  1.4189e+00,\n",
            "           1.7108e-01,  6.9745e-01, -9.1015e-02,  2.8059e-01, -4.7823e-01],\n",
            "         [ 1.9734e-01, -1.7257e+00, -2.4744e-02,  8.6637e-01,  1.5423e+00,\n",
            "           1.5661e-01,  8.3862e-01, -2.4698e-01,  1.6173e-01, -6.4419e-01],\n",
            "         [-4.3070e-04, -8.4861e-01,  8.4290e-02,  8.0206e-01,  1.6144e+00,\n",
            "           1.4790e-01,  9.0836e-01, -3.2179e-01,  1.0508e-01, -7.2374e-01]],\n",
            "\n",
            "        [[ 9.1709e-01,  4.4161e-01, -5.2586e-01,  7.2590e-01,  1.0401e+00,\n",
            "           2.1178e-01,  2.6212e-01,  3.9022e-01,  6.4746e-01,  3.3925e-02],\n",
            "         [ 1.7726e+00, -2.1205e-01, -4.0248e-01,  8.3979e-01,  1.2170e+00,\n",
            "           1.9253e-01,  4.7780e-01,  1.4963e-01,  4.6371e-01, -2.2215e-01],\n",
            "         [ 1.8544e+00, -1.3625e+00, -2.8306e-01,  9.2893e-01,  1.3938e+00,\n",
            "           1.7266e-01,  6.9347e-01, -9.0975e-02,  2.7996e-01, -4.7823e-01],\n",
            "         [ 1.0953e+00, -2.0620e+00, -1.5933e-01,  9.4976e-01,  1.5173e+00,\n",
            "           1.5882e-01,  8.3464e-01, -2.4692e-01,  1.6109e-01, -6.4418e-01],\n",
            "         [ 2.0169e-01, -1.7859e+00, -3.5446e-02,  9.0564e-01,  1.5894e+00,\n",
            "           1.5073e-01,  9.0438e-01, -3.2172e-01,  1.0445e-01, -7.2373e-01],\n",
            "         [ 1.3522e-03, -8.7333e-01,  7.9901e-02,  8.1816e-01,  1.6337e+00,\n",
            "           1.4548e-01,  9.3533e-01, -3.5244e-01,  8.1585e-02, -7.5636e-01]],\n",
            "\n",
            "        [[ 9.0368e-01,  6.2757e-01, -4.9283e-01,  6.0470e-01,  8.9457e-01,\n",
            "           2.2992e-01,  5.9175e-02,  6.2087e-01,  8.2423e-01,  2.7943e-01],\n",
            "         [ 1.7495e+00,  1.0762e-01, -3.4571e-01,  6.3144e-01,  9.6683e-01,\n",
            "           2.2373e-01,  1.2892e-01,  5.4612e-01,  7.6759e-01,  1.9988e-01],\n",
            "         [ 1.8264e+00, -9.7453e-01, -2.1416e-01,  6.7608e-01,  1.0903e+00,\n",
            "           2.1052e-01,  2.7009e-01,  3.9019e-01,  6.4873e-01,  3.3925e-02],\n",
            "         [ 1.0722e+00, -1.7423e+00, -1.0255e-01,  7.4140e-01,  1.2671e+00,\n",
            "           1.9001e-01,  4.8576e-01,  1.4957e-01,  4.6497e-01, -2.2215e-01],\n",
            "         [ 1.8828e-01, -1.6000e+00, -2.4197e-03,  7.8444e-01,  1.4439e+00,\n",
            "           1.6888e-01,  7.0143e-01, -9.1070e-02,  2.8122e-01, -4.7823e-01],\n",
            "         [-4.7776e-03, -7.8836e-01,  9.4991e-02,  7.6278e-01,  1.5672e+00,\n",
            "           1.5378e-01,  8.4260e-01, -2.4705e-01,  1.6236e-01, -6.4419e-01]],\n",
            "\n",
            "        [[ 9.3109e-01,  2.4765e-01, -5.6031e-01,  8.5233e-01,  1.1918e+00,\n",
            "           1.9285e-01,  4.7382e-01,  1.4964e-01,  4.6308e-01, -2.2215e-01],\n",
            "         [ 1.7865e+00, -4.0602e-01, -4.3693e-01,  9.6622e-01,  1.3687e+00,\n",
            "           1.7360e-01,  6.8949e-01, -9.0951e-02,  2.7932e-01, -4.7823e-01],\n",
            "         [ 1.8634e+00, -1.4882e+00, -3.0538e-01,  1.0109e+00,  1.4922e+00,\n",
            "           1.6039e-01,  8.3066e-01, -2.4688e-01,  1.6046e-01, -6.4418e-01],\n",
            "         [ 1.0996e+00, -2.1223e+00, -1.7003e-01,  9.8903e-01,  1.5644e+00,\n",
            "           1.5294e-01,  9.0040e-01, -3.2166e-01,  1.0382e-01, -7.2373e-01],\n",
            "         [ 2.0347e-01, -1.8106e+00, -3.9835e-02,  9.2175e-01,  1.6088e+00,\n",
            "           1.4832e-01,  9.3135e-01, -3.5237e-01,  8.0954e-02, -7.5636e-01],\n",
            "         [ 2.0361e-03, -8.8281e-01,  7.8217e-02,  8.2434e-01,  1.6411e+00,\n",
            "           1.4456e-01,  9.4568e-01, -3.6420e-01,  7.2573e-02, -7.6888e-01]],\n",
            "\n",
            "        [[ 9.0121e-01,  6.6176e-01, -4.8676e-01,  5.8242e-01,  8.6781e-01,\n",
            "           2.3326e-01,  2.1856e-02,  6.6328e-01,  8.5674e-01,  3.2457e-01],\n",
            "         [ 1.7434e+00,  1.9259e-01, -3.3062e-01,  5.7606e-01,  9.0035e-01,\n",
            "           2.3202e-01,  3.6184e-02,  6.5151e-01,  8.4836e-01,  3.1205e-01],\n",
            "         [ 1.8130e+00, -7.8858e-01, -1.8114e-01,  5.5488e-01,  9.4479e-01,\n",
            "           2.2866e-01,  6.7138e-02,  6.2083e-01,  8.2550e-01,  2.7943e-01],\n",
            "         [ 1.0491e+00, -1.4227e+00, -4.5781e-02,  5.3305e-01,  1.0170e+00,\n",
            "           2.2121e-01,  1.3688e-01,  5.4606e-01,  7.6885e-01,  1.9988e-01],\n",
            "         [ 1.6029e-01, -1.2120e+00,  6.6478e-02,  5.3159e-01,  1.1404e+00,\n",
            "           2.0673e-01,  2.7805e-01,  3.9009e-01,  6.4999e-01,  3.3922e-02],\n",
            "         [-2.7839e-02, -4.6869e-01,  1.5176e-01,  5.5443e-01,  1.3171e+00,\n",
            "           1.8497e-01,  4.9372e-01,  1.4944e-01,  4.6623e-01, -2.2216e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "t tensor([[ 8],\n",
            "        [ 6],\n",
            "        [11],\n",
            "        [12],\n",
            "        [ 2],\n",
            "        [ 8],\n",
            "        [ 1],\n",
            "        [ 9],\n",
            "        [ 3],\n",
            "        [12],\n",
            "        [12],\n",
            "        [ 5],\n",
            "        [ 1],\n",
            "        [ 6],\n",
            "        [ 7]], dtype=torch.int32)\n",
            "b before tensor([[-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4]])\n",
            "b after tensor([[-2, -1,  0,  1,  2,  3,  4],\n",
            "        [-4, -3, -2, -1,  0,  1,  2],\n",
            "        [ 1,  2,  3,  4,  5,  6,  7],\n",
            "        [ 2,  3,  4,  5,  6,  7,  8],\n",
            "        [-8, -7, -6, -5, -4, -3, -2],\n",
            "        [-2, -1,  0,  1,  2,  3,  4],\n",
            "        [-9, -8, -7, -6, -5, -4, -3],\n",
            "        [-1,  0,  1,  2,  3,  4,  5],\n",
            "        [-7, -6, -5, -4, -3, -2, -1],\n",
            "        [ 2,  3,  4,  5,  6,  7,  8],\n",
            "        [ 2,  3,  4,  5,  6,  7,  8],\n",
            "        [-5, -4, -3, -2, -1,  0,  1],\n",
            "        [-9, -8, -7, -6, -5, -4, -3],\n",
            "        [-4, -3, -2, -1,  0,  1,  2],\n",
            "        [-3, -2, -1,  0,  1,  2,  3]])\n",
            "s torch.Size([15, 7])\n",
            "---------\n",
            "after positional encoding shapetensor([[[ 9.0796e-01,  5.6788e-01, -5.0359e-01,  6.4415e-01,  9.4206e-01,\n",
            "           2.2415e-01,  1.2480e-01,  5.4583e-01,  7.6705e-01,  1.9979e-01],\n",
            "         [ 1.7585e+00, -1.7487e-02, -3.6807e-01,  7.1357e-01,  1.0656e+00,\n",
            "           2.1151e-01,  2.6598e-01,  3.8990e-01,  6.4820e-01,  3.3820e-02],\n",
            "         [ 1.8404e+00, -1.1679e+00, -2.4863e-01,  8.0274e-01,  1.2425e+00,\n",
            "           1.9155e-01,  4.8166e-01,  1.4927e-01,  4.6445e-01, -2.2228e-01],\n",
            "         [ 1.0862e+00, -1.9356e+00, -1.3701e-01,  8.6809e-01,  1.4194e+00,\n",
            "           1.7096e-01,  6.9734e-01, -9.1380e-02,  2.8071e-01, -4.7839e-01],\n",
            "         [ 1.9741e-01, -1.7249e+00, -2.4736e-02,  8.6665e-01,  1.5428e+00,\n",
            "           1.5643e-01,  8.3852e-01, -2.4736e-01,  1.6185e-01, -6.4436e-01],\n",
            "         [-3.5197e-04, -8.4787e-01,  8.4303e-02,  8.0234e-01,  1.6150e+00,\n",
            "           1.4769e-01,  9.0826e-01, -3.2218e-01,  1.0521e-01, -7.2392e-01]],\n",
            "\n",
            "        [[ 9.0181e-01,  6.5283e-01, -4.8850e-01,  5.8876e-01,  8.7555e-01,\n",
            "           2.3248e-01,  3.2065e-02,  6.5123e-01,  8.4782e-01,  3.1198e-01],\n",
            "         [ 1.7451e+00,  1.6842e-01, -3.3506e-01,  5.9234e-01,  9.2001e-01,\n",
            "           2.2974e-01,  6.3019e-02,  6.2056e-01,  8.2496e-01,  2.7935e-01],\n",
            "         [ 1.8173e+00, -8.4827e-01, -1.9189e-01,  5.9433e-01,  9.9227e-01,\n",
            "           2.2289e-01,  1.3276e-01,  5.4580e-01,  7.6831e-01,  1.9979e-01],\n",
            "         [ 1.0582e+00, -1.5478e+00, -6.8144e-02,  6.1518e-01,  1.1157e+00,\n",
            "           2.0899e-01,  2.7394e-01,  3.8983e-01,  6.4946e-01,  3.3819e-02],\n",
            "         [ 1.7428e-01, -1.4053e+00,  3.2008e-02,  6.5824e-01,  1.2926e+00,\n",
            "           1.8777e-01,  4.8962e-01,  1.4917e-01,  4.6572e-01, -2.2229e-01],\n",
            "         [-1.3806e-02, -6.6196e-01,  1.1731e-01,  6.8111e-01,  1.4694e+00,\n",
            "           1.6592e-01,  7.0530e-01, -9.1507e-02,  2.8197e-01, -4.7839e-01]],\n",
            "\n",
            "        [[ 9.4512e-01,  5.4377e-02, -5.9476e-01,  9.7901e-01,  1.3441e+00,\n",
            "           1.7380e-01,  6.8540e-01, -9.1309e-02,  2.7882e-01, -4.7839e-01],\n",
            "         [ 1.7957e+00, -5.3099e-01, -4.5925e-01,  1.0484e+00,  1.4676e+00,\n",
            "           1.6116e-01,  8.2657e-01, -2.4724e-01,  1.5996e-01, -6.4436e-01],\n",
            "         [ 1.8679e+00, -1.5477e+00, -3.1607e-01,  1.0504e+00,  1.5399e+00,\n",
            "           1.5431e-01,  8.9632e-01, -3.2201e-01,  1.0332e-01, -7.2392e-01],\n",
            "         [ 1.1015e+00, -2.1462e+00, -1.7440e-01,  1.0054e+00,  1.5843e+00,\n",
            "           1.5031e-01,  9.2727e-01, -3.5270e-01,  8.0457e-02, -7.5655e-01],\n",
            "         [ 2.0424e-01, -1.8194e+00, -4.1502e-02,  9.2822e-01,  1.6168e+00,\n",
            "           1.4718e-01,  9.4160e-01, -3.6452e-01,  7.2076e-02, -7.6907e-01],\n",
            "         [ 2.3783e-03, -8.8560e-01,  7.7605e-02,  8.2695e-01,  1.6445e+00,\n",
            "           1.4400e-01,  9.4945e-01, -3.6899e-01,  6.9340e-02, -7.7375e-01]],\n",
            "\n",
            "        [[ 9.5421e-01, -7.1291e-02, -6.1707e-01,  1.0610e+00,  1.4425e+00,\n",
            "           1.6148e-01,  8.2259e-01, -2.4723e-01,  1.5933e-01, -6.4436e-01],\n",
            "         [ 1.8000e+00, -5.9123e-01, -4.6994e-01,  1.0877e+00,  1.5148e+00,\n",
            "           1.5526e-01,  8.9234e-01, -3.2199e-01,  1.0269e-01, -7.2391e-01],\n",
            "         [ 1.8697e+00, -1.5724e+00, -3.2046e-01,  1.0665e+00,  1.5593e+00,\n",
            "           1.5189e-01,  9.2329e-01, -3.5266e-01,  7.9826e-02, -7.5655e-01],\n",
            "         [ 1.1022e+00, -2.1557e+00, -1.7609e-01,  1.0116e+00,  1.5917e+00,\n",
            "           1.4938e-01,  9.3762e-01, -3.6446e-01,  7.1445e-02, -7.6906e-01],\n",
            "         [ 2.0450e-01, -1.8229e+00, -4.2131e-02,  9.3053e-01,  1.6195e+00,\n",
            "           1.4683e-01,  9.4547e-01, -3.6891e-01,  6.8709e-02, -7.7374e-01],\n",
            "         [ 2.4731e-03, -8.8691e-01,  7.7372e-02,  8.2780e-01,  1.6455e+00,\n",
            "           1.4387e-01,  9.5088e-01, -3.7061e-01,  6.8094e-02, -7.7548e-01]],\n",
            "\n",
            "        [[ 9.0074e-01,  6.6764e-01, -4.8587e-01,  5.7910e-01,  8.6395e-01,\n",
            "           2.3393e-01,  1.5893e-02,  6.6961e-01,  8.6190e-01,  3.3154e-01],\n",
            "         [ 1.7422e+00,  2.0746e-01, -3.2813e-01,  5.6688e-01,  8.8944e-01,\n",
            "           2.3357e-01,  2.0401e-02,  6.6900e-01,  8.6207e-01,  3.3090e-01],\n",
            "         [ 1.8102e+00, -7.5030e-01, -1.7449e-01,  5.3045e-01,  9.1557e-01,\n",
            "           2.3250e-01,  2.5813e-02,  6.6735e-01,  8.6146e-01,  3.2917e-01],\n",
            "         [ 1.0422e+00, -1.3277e+00, -2.9065e-02,  4.7166e-01,  9.4341e-01,\n",
            "           2.3057e-01,  3.3661e-02,  6.6292e-01,  8.5872e-01,  3.2449e-01],\n",
            "         [ 1.4501e-01, -1.0008e+00,  1.0384e-01,  3.9445e-01,  9.7585e-01,\n",
            "           2.2744e-01,  4.7989e-02,  6.5110e-01,  8.5034e-01,  3.1197e-01],\n",
            "         [-5.5327e-02, -8.8220e-02,  2.1918e-01,  3.0697e-01,  1.0202e+00,\n",
            "           2.2218e-01,  7.8942e-02,  6.2037e-01,  8.2748e-01,  2.7934e-01]],\n",
            "\n",
            "        [[ 9.0796e-01,  5.6788e-01, -5.0359e-01,  6.4415e-01,  9.4206e-01,\n",
            "           2.2415e-01,  1.2480e-01,  5.4583e-01,  7.6705e-01,  1.9979e-01],\n",
            "         [ 1.7585e+00, -1.7487e-02, -3.6807e-01,  7.1357e-01,  1.0656e+00,\n",
            "           2.1151e-01,  2.6598e-01,  3.8990e-01,  6.4820e-01,  3.3820e-02],\n",
            "         [ 1.8404e+00, -1.1679e+00, -2.4863e-01,  8.0274e-01,  1.2425e+00,\n",
            "           1.9155e-01,  4.8166e-01,  1.4927e-01,  4.6445e-01, -2.2228e-01],\n",
            "         [ 1.0862e+00, -1.9356e+00, -1.3701e-01,  8.6809e-01,  1.4194e+00,\n",
            "           1.7096e-01,  6.9734e-01, -9.1380e-02,  2.8071e-01, -4.7839e-01],\n",
            "         [ 1.9741e-01, -1.7249e+00, -2.4736e-02,  8.6665e-01,  1.5428e+00,\n",
            "           1.5643e-01,  8.3852e-01, -2.4736e-01,  1.6185e-01, -6.4436e-01],\n",
            "         [-3.5197e-04, -8.4787e-01,  8.4303e-02,  8.0234e-01,  1.6150e+00,\n",
            "           1.4769e-01,  9.0826e-01, -3.2218e-01,  1.0521e-01, -7.2392e-01]],\n",
            "\n",
            "        [[ 9.0072e-01,  6.6782e-01, -4.8584e-01,  5.7898e-01,  8.6381e-01,\n",
            "           2.3395e-01,  1.5699e-02,  6.6983e-01,  8.6207e-01,  3.3178e-01],\n",
            "         [ 1.7422e+00,  2.0794e-01, -3.2805e-01,  5.6656e-01,  8.8906e-01,\n",
            "           2.3362e-01,  1.9874e-02,  6.6960e-01,  8.6253e-01,  3.3154e-01],\n",
            "         [ 1.8101e+00, -7.4899e-01, -1.7426e-01,  5.2959e-01,  9.1454e-01,\n",
            "           2.3263e-01,  2.4382e-02,  6.6898e-01,  8.6271e-01,  3.3090e-01],\n",
            "         [ 1.0420e+00, -1.3241e+00, -2.8436e-02,  4.6935e-01,  9.4064e-01,\n",
            "           2.3092e-01,  2.9794e-02,  6.6731e-01,  8.6209e-01,  3.2917e-01],\n",
            "         [ 1.4432e-01, -9.9134e-01,  1.0552e-01,  3.8827e-01,  9.6843e-01,\n",
            "           2.2837e-01,  3.7641e-02,  6.6286e-01,  8.5935e-01,  3.2449e-01],\n",
            "         [-5.7115e-02, -6.3513e-02,  2.2357e-01,  2.9086e-01,  1.0008e+00,\n",
            "           2.2461e-01,  5.1969e-02,  6.5103e-01,  8.5097e-01,  3.1197e-01]],\n",
            "\n",
            "        [[ 9.1705e-01,  4.4221e-01, -5.2590e-01,  7.2610e-01,  1.0405e+00,\n",
            "           2.1183e-01,  2.6200e-01,  3.8990e-01,  6.4757e-01,  3.3820e-02],\n",
            "         [ 1.7726e+00, -2.1140e-01, -4.0250e-01,  8.4002e-01,  1.2174e+00,\n",
            "           1.9250e-01,  4.7768e-01,  1.4929e-01,  4.6382e-01, -2.2228e-01],\n",
            "         [ 1.8544e+00, -1.3618e+00, -2.8306e-01,  9.2919e-01,  1.3943e+00,\n",
            "           1.7254e-01,  6.9336e-01, -9.1340e-02,  2.8008e-01, -4.7839e-01],\n",
            "         [ 1.0953e+00, -2.0613e+00, -1.5932e-01,  9.5004e-01,  1.5178e+00,\n",
            "           1.5864e-01,  8.3453e-01, -2.4731e-01,  1.6122e-01, -6.4436e-01],\n",
            "         [ 2.0177e-01, -1.7852e+00, -3.5432e-02,  9.0593e-01,  1.5900e+00,\n",
            "           1.5053e-01,  9.0428e-01, -3.2210e-01,  1.0458e-01, -7.2392e-01],\n",
            "         [ 1.4361e-03, -8.7258e-01,  7.9916e-02,  8.1846e-01,  1.6343e+00,\n",
            "           1.4527e-01,  9.3523e-01, -3.5283e-01,  8.1719e-02, -7.5655e-01]],\n",
            "\n",
            "        [[ 9.0077e-01,  6.6716e-01, -4.8596e-01,  5.7941e-01,  8.6432e-01,\n",
            "           2.3389e-01,  1.6420e-02,  6.6901e-01,  8.6144e-01,  3.3090e-01],\n",
            "         [ 1.7423e+00,  2.0615e-01, -3.2836e-01,  5.6773e-01,  8.9047e-01,\n",
            "           2.3344e-01,  2.1832e-02,  6.6738e-01,  8.6083e-01,  3.2917e-01],\n",
            "         [ 1.8104e+00, -7.5384e-01, -1.7512e-01,  5.3276e-01,  9.1834e-01,\n",
            "           2.3215e-01,  2.9680e-02,  6.6296e-01,  8.5809e-01,  3.2449e-01],\n",
            "         [ 1.0429e+00, -1.3372e+00, -3.0748e-02,  4.7784e-01,  9.5083e-01,\n",
            "           2.2964e-01,  4.4008e-02,  6.5116e-01,  8.4971e-01,  3.1198e-01],\n",
            "         [ 1.4679e-01, -1.0255e+00,  9.9448e-02,  4.1056e-01,  9.9520e-01,\n",
            "           2.2502e-01,  7.4962e-02,  6.2045e-01,  8.2685e-01,  2.7934e-01],\n",
            "         [-5.0968e-02, -1.4846e-01,  2.0849e-01,  3.4626e-01,  1.0673e+00,\n",
            "           2.1628e-01,  1.4471e-01,  5.4563e-01,  7.7021e-01,  1.9978e-01]],\n",
            "\n",
            "        [[ 9.5421e-01, -7.1291e-02, -6.1707e-01,  1.0610e+00,  1.4425e+00,\n",
            "           1.6148e-01,  8.2259e-01, -2.4723e-01,  1.5933e-01, -6.4436e-01],\n",
            "         [ 1.8000e+00, -5.9123e-01, -4.6994e-01,  1.0877e+00,  1.5148e+00,\n",
            "           1.5526e-01,  8.9234e-01, -3.2199e-01,  1.0269e-01, -7.2391e-01],\n",
            "         [ 1.8697e+00, -1.5724e+00, -3.2046e-01,  1.0665e+00,  1.5593e+00,\n",
            "           1.5189e-01,  9.2329e-01, -3.5266e-01,  7.9826e-02, -7.5655e-01],\n",
            "         [ 1.1022e+00, -2.1557e+00, -1.7609e-01,  1.0116e+00,  1.5917e+00,\n",
            "           1.4938e-01,  9.3762e-01, -3.6446e-01,  7.1445e-02, -7.6906e-01],\n",
            "         [ 2.0450e-01, -1.8229e+00, -4.2131e-02,  9.3053e-01,  1.6195e+00,\n",
            "           1.4683e-01,  9.4547e-01, -3.6891e-01,  6.8709e-02, -7.7374e-01],\n",
            "         [ 2.4731e-03, -8.8691e-01,  7.7372e-02,  8.2780e-01,  1.6455e+00,\n",
            "           1.4387e-01,  9.5088e-01, -3.7061e-01,  6.8094e-02, -7.7548e-01]],\n",
            "\n",
            "        [[ 9.5421e-01, -7.1291e-02, -6.1707e-01,  1.0610e+00,  1.4425e+00,\n",
            "           1.6148e-01,  8.2259e-01, -2.4723e-01,  1.5933e-01, -6.4436e-01],\n",
            "         [ 1.8000e+00, -5.9123e-01, -4.6994e-01,  1.0877e+00,  1.5148e+00,\n",
            "           1.5526e-01,  8.9234e-01, -3.2199e-01,  1.0269e-01, -7.2391e-01],\n",
            "         [ 1.8697e+00, -1.5724e+00, -3.2046e-01,  1.0665e+00,  1.5593e+00,\n",
            "           1.5189e-01,  9.2329e-01, -3.5266e-01,  7.9826e-02, -7.5655e-01],\n",
            "         [ 1.1022e+00, -2.1557e+00, -1.7609e-01,  1.0116e+00,  1.5917e+00,\n",
            "           1.4938e-01,  9.3762e-01, -3.6446e-01,  7.1445e-02, -7.6906e-01],\n",
            "         [ 2.0450e-01, -1.8229e+00, -4.2131e-02,  9.3053e-01,  1.6195e+00,\n",
            "           1.4683e-01,  9.4547e-01, -3.6891e-01,  6.8709e-02, -7.7374e-01],\n",
            "         [ 2.4731e-03, -8.8691e-01,  7.7372e-02,  8.2780e-01,  1.6455e+00,\n",
            "           1.4387e-01,  9.5088e-01, -3.7061e-01,  6.8094e-02, -7.7548e-01]],\n",
            "\n",
            "        [[ 9.0112e-01,  6.6230e-01, -4.8682e-01,  5.8258e-01,  8.6812e-01,\n",
            "           2.3341e-01,  2.1718e-02,  6.6299e-01,  8.5683e-01,  3.2450e-01],\n",
            "         [ 1.7433e+00,  1.9313e-01, -3.3068e-01,  5.7622e-01,  9.0066e-01,\n",
            "           2.3217e-01,  3.6046e-02,  6.5122e-01,  8.4845e-01,  3.1198e-01],\n",
            "         [ 1.8129e+00, -7.8803e-01, -1.8119e-01,  5.5505e-01,  9.4511e-01,\n",
            "           2.2880e-01,  6.7000e-02,  6.2054e-01,  8.2559e-01,  2.7935e-01],\n",
            "         [ 1.0491e+00, -1.4221e+00, -4.5831e-02,  5.3323e-01,  1.0173e+00,\n",
            "           2.2131e-01,  1.3674e-01,  5.4576e-01,  7.6894e-01,  1.9979e-01],\n",
            "         [ 1.6025e-01, -1.2114e+00,  6.6439e-02,  5.3179e-01,  1.1408e+00,\n",
            "           2.0679e-01,  2.7792e-01,  3.8978e-01,  6.5009e-01,  3.3817e-02],\n",
            "         [-2.7840e-02, -4.6804e-01,  1.5174e-01,  5.5466e-01,  1.3176e+00,\n",
            "           1.8494e-01,  4.9360e-01,  1.4910e-01,  4.6635e-01, -2.2229e-01]],\n",
            "\n",
            "        [[ 9.0072e-01,  6.6782e-01, -4.8584e-01,  5.7898e-01,  8.6381e-01,\n",
            "           2.3395e-01,  1.5699e-02,  6.6983e-01,  8.6207e-01,  3.3178e-01],\n",
            "         [ 1.7422e+00,  2.0794e-01, -3.2805e-01,  5.6656e-01,  8.8906e-01,\n",
            "           2.3362e-01,  1.9874e-02,  6.6960e-01,  8.6253e-01,  3.3154e-01],\n",
            "         [ 1.8101e+00, -7.4899e-01, -1.7426e-01,  5.2959e-01,  9.1454e-01,\n",
            "           2.3263e-01,  2.4382e-02,  6.6898e-01,  8.6271e-01,  3.3090e-01],\n",
            "         [ 1.0420e+00, -1.3241e+00, -2.8436e-02,  4.6935e-01,  9.4064e-01,\n",
            "           2.3092e-01,  2.9794e-02,  6.6731e-01,  8.6209e-01,  3.2917e-01],\n",
            "         [ 1.4432e-01, -9.9134e-01,  1.0552e-01,  3.8827e-01,  9.6843e-01,\n",
            "           2.2837e-01,  3.7641e-02,  6.6286e-01,  8.5935e-01,  3.2449e-01],\n",
            "         [-5.7115e-02, -6.3513e-02,  2.2357e-01,  2.9086e-01,  1.0008e+00,\n",
            "           2.2461e-01,  5.1969e-02,  6.5103e-01,  8.5097e-01,  3.1197e-01]],\n",
            "\n",
            "        [[ 9.0181e-01,  6.5283e-01, -4.8850e-01,  5.8876e-01,  8.7555e-01,\n",
            "           2.3248e-01,  3.2065e-02,  6.5123e-01,  8.4782e-01,  3.1198e-01],\n",
            "         [ 1.7451e+00,  1.6842e-01, -3.3506e-01,  5.9234e-01,  9.2001e-01,\n",
            "           2.2974e-01,  6.3019e-02,  6.2056e-01,  8.2496e-01,  2.7935e-01],\n",
            "         [ 1.8173e+00, -8.4827e-01, -1.9189e-01,  5.9433e-01,  9.9227e-01,\n",
            "           2.2289e-01,  1.3276e-01,  5.4580e-01,  7.6831e-01,  1.9979e-01],\n",
            "         [ 1.0582e+00, -1.5478e+00, -6.8144e-02,  6.1518e-01,  1.1157e+00,\n",
            "           2.0899e-01,  2.7394e-01,  3.8983e-01,  6.4946e-01,  3.3819e-02],\n",
            "         [ 1.7428e-01, -1.4053e+00,  3.2008e-02,  6.5824e-01,  1.2926e+00,\n",
            "           1.8777e-01,  4.8962e-01,  1.4917e-01,  4.6572e-01, -2.2229e-01],\n",
            "         [-1.3806e-02, -6.6196e-01,  1.1731e-01,  6.8111e-01,  1.4694e+00,\n",
            "           1.6592e-01,  7.0530e-01, -9.1507e-02,  2.8197e-01, -4.7839e-01]],\n",
            "\n",
            "        [[ 9.0360e-01,  6.2812e-01, -4.9289e-01,  6.0487e-01,  8.9489e-01,\n",
            "           2.3006e-01,  5.9038e-02,  6.2057e-01,  8.2433e-01,  2.7935e-01],\n",
            "         [ 1.7494e+00,  1.0818e-01, -3.4576e-01,  6.3162e-01,  9.6717e-01,\n",
            "           2.2384e-01,  1.2878e-01,  5.4582e-01,  7.6768e-01,  1.9979e-01],\n",
            "         [ 1.8263e+00, -9.7394e-01, -2.1420e-01,  6.7628e-01,  1.0907e+00,\n",
            "           2.1057e-01,  2.6996e-01,  3.8987e-01,  6.4883e-01,  3.3820e-02],\n",
            "         [ 1.0722e+00, -1.7417e+00, -1.0258e-01,  7.4163e-01,  1.2676e+00,\n",
            "           1.8998e-01,  4.8564e-01,  1.4923e-01,  4.6508e-01, -2.2229e-01],\n",
            "         [ 1.8832e-01, -1.5993e+00, -2.4231e-03,  7.8470e-01,  1.4444e+00,\n",
            "           1.6876e-01,  7.0132e-01, -9.1435e-02,  2.8134e-01, -4.7839e-01],\n",
            "         [-4.7114e-03, -7.8763e-01,  9.4999e-02,  7.6306e-01,  1.5678e+00,\n",
            "           1.5360e-01,  8.4250e-01, -2.4743e-01,  1.6249e-01, -6.4436e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "t tensor([[ 7],\n",
            "        [ 7],\n",
            "        [12],\n",
            "        [10],\n",
            "        [ 3],\n",
            "        [ 1],\n",
            "        [ 2],\n",
            "        [11],\n",
            "        [ 0],\n",
            "        [ 6],\n",
            "        [ 5],\n",
            "        [ 8],\n",
            "        [ 2],\n",
            "        [ 7],\n",
            "        [ 2]], dtype=torch.int32)\n",
            "b before tensor([[-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4]])\n",
            "b after tensor([[ -3,  -2,  -1,   0,   1,   2,   3],\n",
            "        [ -3,  -2,  -1,   0,   1,   2,   3],\n",
            "        [  2,   3,   4,   5,   6,   7,   8],\n",
            "        [  0,   1,   2,   3,   4,   5,   6],\n",
            "        [ -7,  -6,  -5,  -4,  -3,  -2,  -1],\n",
            "        [ -9,  -8,  -7,  -6,  -5,  -4,  -3],\n",
            "        [ -8,  -7,  -6,  -5,  -4,  -3,  -2],\n",
            "        [  1,   2,   3,   4,   5,   6,   7],\n",
            "        [-10,  -9,  -8,  -7,  -6,  -5,  -4],\n",
            "        [ -4,  -3,  -2,  -1,   0,   1,   2],\n",
            "        [ -5,  -4,  -3,  -2,  -1,   0,   1],\n",
            "        [ -2,  -1,   0,   1,   2,   3,   4],\n",
            "        [ -8,  -7,  -6,  -5,  -4,  -3,  -2],\n",
            "        [ -3,  -2,  -1,   0,   1,   2,   3],\n",
            "        [ -8,  -7,  -6,  -5,  -4,  -3,  -2]])\n",
            "s torch.Size([15, 7])\n",
            "---------\n",
            "after positional encoding shapetensor([[[ 9.0350e-01,  6.2861e-01, -4.9297e-01,  6.0500e-01,  8.9515e-01,\n",
            "           2.3021e-01,  5.8935e-02,  6.2033e-01,  8.2444e-01,  2.7925e-01],\n",
            "         [ 1.7493e+00,  1.0869e-01, -3.4584e-01,  6.3176e-01,  9.6745e-01,\n",
            "           2.2396e-01,  1.2868e-01,  5.4557e-01,  7.6780e-01,  1.9969e-01],\n",
            "         [ 1.8263e+00, -9.7339e-01, -2.1427e-01,  6.7645e-01,  1.0910e+00,\n",
            "           2.1064e-01,  2.6987e-01,  3.8961e-01,  6.4896e-01,  3.3702e-02],\n",
            "         [ 1.0722e+00, -1.7411e+00, -1.0263e-01,  7.4183e-01,  1.2679e+00,\n",
            "           1.8997e-01,  4.8556e-01,  1.4894e-01,  4.6523e-01, -2.2243e-01],\n",
            "         [ 1.8832e-01, -1.5986e+00, -2.4641e-03,  7.8493e-01,  1.4449e+00,\n",
            "           1.6867e-01,  7.0125e-01, -9.1742e-02,  2.8150e-01, -4.7856e-01],\n",
            "         [-4.6850e-03, -7.8695e-01,  9.4967e-02,  7.6332e-01,  1.5683e+00,\n",
            "           1.5346e-01,  8.4243e-01, -2.4775e-01,  1.6266e-01, -6.4454e-01]],\n",
            "\n",
            "        [[ 9.0350e-01,  6.2861e-01, -4.9297e-01,  6.0500e-01,  8.9515e-01,\n",
            "           2.3021e-01,  5.8935e-02,  6.2033e-01,  8.2444e-01,  2.7925e-01],\n",
            "         [ 1.7493e+00,  1.0869e-01, -3.4584e-01,  6.3176e-01,  9.6745e-01,\n",
            "           2.2396e-01,  1.2868e-01,  5.4557e-01,  7.6780e-01,  1.9969e-01],\n",
            "         [ 1.8263e+00, -9.7339e-01, -2.1427e-01,  6.7645e-01,  1.0910e+00,\n",
            "           2.1064e-01,  2.6987e-01,  3.8961e-01,  6.4896e-01,  3.3702e-02],\n",
            "         [ 1.0722e+00, -1.7411e+00, -1.0263e-01,  7.4183e-01,  1.2679e+00,\n",
            "           1.8997e-01,  4.8556e-01,  1.4894e-01,  4.6523e-01, -2.2243e-01],\n",
            "         [ 1.8832e-01, -1.5986e+00, -2.4641e-03,  7.8493e-01,  1.4449e+00,\n",
            "           1.6867e-01,  7.0125e-01, -9.1742e-02,  2.8150e-01, -4.7856e-01],\n",
            "         [-4.6850e-03, -7.8695e-01,  9.4967e-02,  7.6332e-01,  1.5683e+00,\n",
            "           1.5346e-01,  8.4243e-01, -2.4775e-01,  1.6266e-01, -6.4454e-01]],\n",
            "\n",
            "        [[ 9.5424e-01, -7.0609e-02, -6.1711e-01,  1.0612e+00,  1.4430e+00,\n",
            "           1.6134e-01,  8.2253e-01, -2.4756e-01,  1.5950e-01, -6.4454e-01],\n",
            "         [ 1.8001e+00, -5.9053e-01, -4.6997e-01,  1.0880e+00,  1.5153e+00,\n",
            "           1.5509e-01,  8.9228e-01, -3.2231e-01,  1.0286e-01, -7.2410e-01],\n",
            "         [ 1.8697e+00, -1.5717e+00, -3.2049e-01,  1.0668e+00,  1.5597e+00,\n",
            "           1.5171e-01,  9.2323e-01, -3.5300e-01,  8.0002e-02, -7.5674e-01],\n",
            "         [ 1.1022e+00, -2.1550e+00, -1.7611e-01,  1.0119e+00,  1.5922e+00,\n",
            "           1.4920e-01,  9.3756e-01, -3.6480e-01,  7.1622e-02, -7.6926e-01],\n",
            "         [ 2.0454e-01, -1.8222e+00, -4.2156e-02,  9.3080e-01,  1.6200e+00,\n",
            "           1.4665e-01,  9.4541e-01, -3.6925e-01,  6.8886e-02, -7.7394e-01],\n",
            "         [ 2.5175e-03, -8.8620e-01,  7.7347e-02,  8.2807e-01,  1.6460e+00,\n",
            "           1.4368e-01,  9.5082e-01, -3.7095e-01,  6.8271e-02, -7.7567e-01]],\n",
            "\n",
            "        [[ 9.3105e-01,  2.4889e-01, -5.6038e-01,  8.5275e-01,  1.1927e+00,\n",
            "           1.9281e-01,  4.7362e-01,  1.4901e-01,  4.6334e-01, -2.2243e-01],\n",
            "         [ 1.7866e+00, -4.0467e-01, -4.3698e-01,  9.6671e-01,  1.3697e+00,\n",
            "           1.7340e-01,  6.8931e-01, -9.1623e-02,  2.7961e-01, -4.7855e-01],\n",
            "         [ 1.8635e+00, -1.4868e+00, -3.0541e-01,  1.0114e+00,  1.4932e+00,\n",
            "           1.6007e-01,  8.3049e-01, -2.4759e-01,  1.6076e-01, -6.4454e-01],\n",
            "         [ 1.0997e+00, -2.1208e+00, -1.7004e-01,  9.8958e-01,  1.5655e+00,\n",
            "           1.5257e-01,  9.0024e-01, -3.2238e-01,  1.0412e-01, -7.2411e-01],\n",
            "         [ 2.0360e-01, -1.8092e+00, -3.9845e-02,  9.2231e-01,  1.6098e+00,\n",
            "           1.4793e-01,  9.3119e-01, -3.5309e-01,  8.1264e-02, -7.5674e-01],\n",
            "         [ 2.1654e-03, -8.8135e-01,  7.8208e-02,  8.2491e-01,  1.6422e+00,\n",
            "           1.4416e-01,  9.4552e-01, -3.6492e-01,  7.2884e-02, -7.6926e-01]],\n",
            "\n",
            "        [[ 9.0067e-01,  6.6764e-01, -4.8604e-01,  5.7954e-01,  8.6457e-01,\n",
            "           2.3406e-01,  1.6315e-02,  6.6877e-01,  8.6156e-01,  3.3081e-01],\n",
            "         [ 1.7422e+00,  2.0663e-01, -3.2845e-01,  5.6786e-01,  8.9072e-01,\n",
            "           2.3361e-01,  2.1727e-02,  6.6714e-01,  8.6094e-01,  3.2908e-01],\n",
            "         [ 1.8103e+00, -7.5336e-01, -1.7521e-01,  5.3289e-01,  9.1859e-01,\n",
            "           2.3232e-01,  2.9575e-02,  6.6272e-01,  8.5821e-01,  3.2440e-01],\n",
            "         [ 1.0428e+00, -1.3367e+00, -3.0832e-02,  4.7797e-01,  9.5108e-01,\n",
            "           2.2981e-01,  4.3903e-02,  6.5092e-01,  8.4983e-01,  3.1188e-01],\n",
            "         [ 1.4669e-01, -1.0250e+00,  9.9366e-02,  4.1069e-01,  9.9546e-01,\n",
            "           2.2517e-01,  7.4859e-02,  6.2021e-01,  8.2697e-01,  2.7925e-01],\n",
            "         [-5.1057e-02, -1.4795e-01,  2.0841e-01,  3.4640e-01,  1.0676e+00,\n",
            "           2.1640e-01,  1.4461e-01,  5.4538e-01,  7.7033e-01,  1.9968e-01]],\n",
            "\n",
            "        [[ 9.0062e-01,  6.6830e-01, -4.8593e-01,  5.7911e-01,  8.6405e-01,\n",
            "           2.3412e-01,  1.5593e-02,  6.6959e-01,  8.6219e-01,  3.3169e-01],\n",
            "         [ 1.7421e+00,  2.0843e-01, -3.2813e-01,  5.6669e-01,  8.8931e-01,\n",
            "           2.3379e-01,  1.9769e-02,  6.6937e-01,  8.6265e-01,  3.3145e-01],\n",
            "         [ 1.8100e+00, -7.4851e-01, -1.7435e-01,  5.2972e-01,  9.1479e-01,\n",
            "           2.3280e-01,  2.4277e-02,  6.6874e-01,  8.6282e-01,  3.3081e-01],\n",
            "         [ 1.0419e+00, -1.3237e+00, -2.8521e-02,  4.6947e-01,  9.4088e-01,\n",
            "           2.3109e-01,  2.9689e-02,  6.6708e-01,  8.6220e-01,  3.2908e-01],\n",
            "         [ 1.4421e-01, -9.9085e-01,  1.0543e-01,  3.8839e-01,  9.6868e-01,\n",
            "           2.2854e-01,  3.7536e-02,  6.6263e-01,  8.5947e-01,  3.2440e-01],\n",
            "         [-5.7220e-02, -6.3023e-02,  2.2349e-01,  2.9099e-01,  1.0011e+00,\n",
            "           2.2477e-01,  5.1864e-02,  6.5079e-01,  8.5109e-01,  3.1188e-01]],\n",
            "\n",
            "        [[ 9.0063e-01,  6.6812e-01, -4.8596e-01,  5.7922e-01,  8.6419e-01,\n",
            "           2.3410e-01,  1.5787e-02,  6.6937e-01,  8.6202e-01,  3.3145e-01],\n",
            "         [ 1.7421e+00,  2.0794e-01, -3.2822e-01,  5.6701e-01,  8.8969e-01,\n",
            "           2.3374e-01,  2.0296e-02,  6.6877e-01,  8.6219e-01,  3.3081e-01],\n",
            "         [ 1.8101e+00, -7.4982e-01, -1.7458e-01,  5.3058e-01,  9.1582e-01,\n",
            "           2.3267e-01,  2.5708e-02,  6.6712e-01,  8.6157e-01,  3.2908e-01],\n",
            "         [ 1.0421e+00, -1.3272e+00, -2.9150e-02,  4.7178e-01,  9.4366e-01,\n",
            "           2.3074e-01,  3.3556e-02,  6.6268e-01,  8.5884e-01,  3.2440e-01],\n",
            "         [ 1.4490e-01, -1.0003e+00,  1.0375e-01,  3.9458e-01,  9.7610e-01,\n",
            "           2.2760e-01,  4.7884e-02,  6.5086e-01,  8.5046e-01,  3.1188e-01],\n",
            "         [-5.5427e-02, -8.7724e-02,  2.1910e-01,  3.0711e-01,  1.0204e+00,\n",
            "           2.2234e-01,  7.8839e-02,  6.2013e-01,  8.2760e-01,  2.7925e-01]],\n",
            "\n",
            "        [[ 9.4512e-01,  5.5026e-02, -5.9480e-01,  9.7924e-01,  1.3446e+00,\n",
            "           1.7371e-01,  6.8533e-01, -9.1615e-02,  2.7898e-01, -4.7855e-01],\n",
            "         [ 1.7957e+00, -5.3031e-01, -4.5928e-01,  1.0487e+00,  1.4681e+00,\n",
            "           1.6102e-01,  8.2651e-01, -2.4756e-01,  1.6013e-01, -6.4454e-01],\n",
            "         [ 1.8679e+00, -1.5470e+00, -3.1610e-01,  1.0507e+00,  1.5404e+00,\n",
            "           1.5414e-01,  8.9626e-01, -3.2234e-01,  1.0349e-01, -7.2410e-01],\n",
            "         [ 1.1015e+00, -2.1455e+00, -1.7443e-01,  1.0057e+00,  1.5848e+00,\n",
            "           1.5013e-01,  9.2721e-01, -3.5304e-01,  8.0633e-02, -7.5674e-01],\n",
            "         [ 2.0429e-01, -1.8187e+00, -4.1527e-02,  9.2849e-01,  1.6173e+00,\n",
            "           1.4699e-01,  9.4154e-01, -3.6485e-01,  7.2253e-02, -7.6926e-01],\n",
            "         [ 2.4224e-03, -8.8489e-01,  7.7580e-02,  8.2722e-01,  1.6450e+00,\n",
            "           1.4381e-01,  9.4939e-01, -3.6932e-01,  6.9517e-02, -7.7394e-01]],\n",
            "\n",
            "        [[ 9.0061e-01,  6.6837e-01, -4.8591e-01,  5.7907e-01,  8.6400e-01,\n",
            "           2.3413e-01,  1.5522e-02,  6.6968e-01,  8.6225e-01,  3.3177e-01],\n",
            "         [ 1.7421e+00,  2.0860e-01, -3.2810e-01,  5.6657e-01,  8.8917e-01,\n",
            "           2.3381e-01,  1.9574e-02,  6.6959e-01,  8.6282e-01,  3.3169e-01],\n",
            "         [ 1.8099e+00, -7.4802e-01, -1.7426e-01,  5.2941e-01,  9.1441e-01,\n",
            "           2.3284e-01,  2.3750e-02,  6.6934e-01,  8.6328e-01,  3.3145e-01],\n",
            "         [ 1.0418e+00, -1.3224e+00, -2.8289e-02,  4.6862e-01,  9.3986e-01,\n",
            "           2.3122e-01,  2.8258e-02,  6.6870e-01,  8.6345e-01,  3.3081e-01],\n",
            "         [ 1.4396e-01, -9.8731e-01,  1.0606e-01,  3.8608e-01,  9.6591e-01,\n",
            "           2.2888e-01,  3.3669e-02,  6.6702e-01,  8.6283e-01,  3.2908e-01],\n",
            "         [-5.7907e-02, -5.3547e-02,  2.2517e-01,  2.8481e-01,  9.9364e-01,\n",
            "           2.2570e-01,  4.1517e-02,  6.6255e-01,  8.6010e-01,  3.2440e-01]],\n",
            "\n",
            "        [[ 9.0170e-01,  6.5331e-01, -4.8859e-01,  5.8889e-01,  8.7580e-01,\n",
            "           2.3265e-01,  3.1960e-02,  6.5099e-01,  8.4793e-01,  3.1189e-01],\n",
            "         [ 1.7450e+00,  1.6892e-01, -3.3515e-01,  5.9247e-01,  9.2027e-01,\n",
            "           2.2990e-01,  6.2916e-02,  6.2032e-01,  8.2507e-01,  2.7925e-01],\n",
            "         [ 1.8172e+00, -8.4776e-01, -1.9197e-01,  5.9448e-01,  9.9255e-01,\n",
            "           2.2302e-01,  1.3266e-01,  5.4555e-01,  7.6843e-01,  1.9969e-01],\n",
            "         [ 1.0581e+00, -1.5472e+00, -6.8213e-02,  6.1534e-01,  1.1161e+00,\n",
            "           2.0907e-01,  2.7385e-01,  3.8957e-01,  6.4959e-01,  3.3701e-02],\n",
            "         [ 1.7425e-01, -1.4048e+00,  3.1953e-02,  6.5844e-01,  1.2930e+00,\n",
            "           1.8777e-01,  4.8954e-01,  1.4889e-01,  4.6586e-01, -2.2243e-01],\n",
            "         [-1.3802e-02, -6.6131e-01,  1.1727e-01,  6.8135e-01,  1.4698e+00,\n",
            "           1.6584e-01,  7.0523e-01, -9.1813e-02,  2.8213e-01, -4.7856e-01]],\n",
            "\n",
            "        [[ 9.0102e-01,  6.6279e-01, -4.8690e-01,  5.8270e-01,  8.6837e-01,\n",
            "           2.3358e-01,  2.1613e-02,  6.6275e-01,  8.5694e-01,  3.2440e-01],\n",
            "         [ 1.7432e+00,  1.9362e-01, -3.3076e-01,  5.7635e-01,  9.0091e-01,\n",
            "           2.3233e-01,  3.5941e-02,  6.5098e-01,  8.4856e-01,  3.1189e-01],\n",
            "         [ 1.8128e+00, -7.8753e-01, -1.8127e-01,  5.5518e-01,  9.4537e-01,\n",
            "           2.2895e-01,  6.6897e-02,  6.2030e-01,  8.2570e-01,  2.7925e-01],\n",
            "         [ 1.0490e+00, -1.4216e+00, -4.5909e-02,  5.3337e-01,  1.0176e+00,\n",
            "           2.2144e-01,  1.3665e-01,  5.4551e-01,  7.6907e-01,  1.9969e-01],\n",
            "         [ 1.6018e-01, -1.2109e+00,  6.6370e-02,  5.3196e-01,  1.1411e+00,\n",
            "           2.0686e-01,  2.7783e-01,  3.8952e-01,  6.5022e-01,  3.3699e-02],\n",
            "         [-2.7871e-02, -4.6745e-01,  1.5169e-01,  5.5486e-01,  1.3179e+00,\n",
            "           1.8493e-01,  4.9352e-01,  1.4882e-01,  4.6649e-01, -2.2243e-01]],\n",
            "\n",
            "        [[ 9.0787e-01,  5.6839e-01, -5.0366e-01,  6.4430e-01,  9.4233e-01,\n",
            "           2.2428e-01,  1.2470e-01,  5.4558e-01,  7.6717e-01,  1.9969e-01],\n",
            "         [ 1.7585e+00, -1.6942e-02, -3.6814e-01,  7.1373e-01,  1.0659e+00,\n",
            "           2.1159e-01,  2.6588e-01,  3.8963e-01,  6.4833e-01,  3.3702e-02],\n",
            "         [ 1.8404e+00, -1.1673e+00, -2.4869e-01,  8.0293e-01,  1.2429e+00,\n",
            "           1.9155e-01,  4.8158e-01,  1.4898e-01,  4.6460e-01, -2.2243e-01],\n",
            "         [ 1.0862e+00, -1.9350e+00, -1.3705e-01,  8.6832e-01,  1.4198e+00,\n",
            "           1.7087e-01,  6.9727e-01, -9.1687e-02,  2.8087e-01, -4.7856e-01],\n",
            "         [ 1.9744e-01, -1.7243e+00, -2.4768e-02,  8.6690e-01,  1.5433e+00,\n",
            "           1.5629e-01,  8.3845e-01, -2.4768e-01,  1.6202e-01, -6.4454e-01],\n",
            "         [-3.1471e-04, -8.4717e-01,  8.4276e-02,  8.0261e-01,  1.6154e+00,\n",
            "           1.4753e-01,  9.0820e-01, -3.2250e-01,  1.0538e-01, -7.2411e-01]],\n",
            "\n",
            "        [[ 9.0063e-01,  6.6812e-01, -4.8596e-01,  5.7922e-01,  8.6419e-01,\n",
            "           2.3410e-01,  1.5787e-02,  6.6937e-01,  8.6202e-01,  3.3145e-01],\n",
            "         [ 1.7421e+00,  2.0794e-01, -3.2822e-01,  5.6701e-01,  8.8969e-01,\n",
            "           2.3374e-01,  2.0296e-02,  6.6877e-01,  8.6219e-01,  3.3081e-01],\n",
            "         [ 1.8101e+00, -7.4982e-01, -1.7458e-01,  5.3058e-01,  9.1582e-01,\n",
            "           2.3267e-01,  2.5708e-02,  6.6712e-01,  8.6157e-01,  3.2908e-01],\n",
            "         [ 1.0421e+00, -1.3272e+00, -2.9150e-02,  4.7178e-01,  9.4366e-01,\n",
            "           2.3074e-01,  3.3556e-02,  6.6268e-01,  8.5884e-01,  3.2440e-01],\n",
            "         [ 1.4490e-01, -1.0003e+00,  1.0375e-01,  3.9458e-01,  9.7610e-01,\n",
            "           2.2760e-01,  4.7884e-02,  6.5086e-01,  8.5046e-01,  3.1188e-01],\n",
            "         [-5.5427e-02, -8.7724e-02,  2.1910e-01,  3.0711e-01,  1.0204e+00,\n",
            "           2.2234e-01,  7.8839e-02,  6.2013e-01,  8.2760e-01,  2.7925e-01]],\n",
            "\n",
            "        [[ 9.0350e-01,  6.2861e-01, -4.9297e-01,  6.0500e-01,  8.9515e-01,\n",
            "           2.3021e-01,  5.8935e-02,  6.2033e-01,  8.2444e-01,  2.7925e-01],\n",
            "         [ 1.7493e+00,  1.0869e-01, -3.4584e-01,  6.3176e-01,  9.6745e-01,\n",
            "           2.2396e-01,  1.2868e-01,  5.4557e-01,  7.6780e-01,  1.9969e-01],\n",
            "         [ 1.8263e+00, -9.7339e-01, -2.1427e-01,  6.7645e-01,  1.0910e+00,\n",
            "           2.1064e-01,  2.6987e-01,  3.8961e-01,  6.4896e-01,  3.3702e-02],\n",
            "         [ 1.0722e+00, -1.7411e+00, -1.0263e-01,  7.4183e-01,  1.2679e+00,\n",
            "           1.8997e-01,  4.8556e-01,  1.4894e-01,  4.6523e-01, -2.2243e-01],\n",
            "         [ 1.8832e-01, -1.5986e+00, -2.4641e-03,  7.8493e-01,  1.4449e+00,\n",
            "           1.6867e-01,  7.0125e-01, -9.1742e-02,  2.8150e-01, -4.7856e-01],\n",
            "         [-4.6850e-03, -7.8695e-01,  9.4967e-02,  7.6332e-01,  1.5683e+00,\n",
            "           1.5346e-01,  8.4243e-01, -2.4775e-01,  1.6266e-01, -6.4454e-01]],\n",
            "\n",
            "        [[ 9.0063e-01,  6.6812e-01, -4.8596e-01,  5.7922e-01,  8.6419e-01,\n",
            "           2.3410e-01,  1.5787e-02,  6.6937e-01,  8.6202e-01,  3.3145e-01],\n",
            "         [ 1.7421e+00,  2.0794e-01, -3.2822e-01,  5.6701e-01,  8.8969e-01,\n",
            "           2.3374e-01,  2.0296e-02,  6.6877e-01,  8.6219e-01,  3.3081e-01],\n",
            "         [ 1.8101e+00, -7.4982e-01, -1.7458e-01,  5.3058e-01,  9.1582e-01,\n",
            "           2.3267e-01,  2.5708e-02,  6.6712e-01,  8.6157e-01,  3.2908e-01],\n",
            "         [ 1.0421e+00, -1.3272e+00, -2.9150e-02,  4.7178e-01,  9.4366e-01,\n",
            "           2.3074e-01,  3.3556e-02,  6.6268e-01,  8.5884e-01,  3.2440e-01],\n",
            "         [ 1.4490e-01, -1.0003e+00,  1.0375e-01,  3.9458e-01,  9.7610e-01,\n",
            "           2.2760e-01,  4.7884e-02,  6.5086e-01,  8.5046e-01,  3.1188e-01],\n",
            "         [-5.5427e-02, -8.7724e-02,  2.1910e-01,  3.0711e-01,  1.0204e+00,\n",
            "           2.2234e-01,  7.8839e-02,  6.2013e-01,  8.2760e-01,  2.7925e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "beforeQuery-torch.Size([15, 6, 10])\n",
            "Query-torch.Size([15, 6, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 6, 6])\n",
            "attention +torch.Size([15, 6, 10])\n",
            "shape after Multihead+torch.Size([15, 6, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 6, 10])\n",
            "End Of Encoder shapetorch.Size([15, 6, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 2, 5])\n",
            "Value-+torch.Size([15, 2, 10])\n",
            "a_norm torch.Size([15, 2, 2])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "beforeQuery-torch.Size([15, 2, 10])\n",
            "Query-torch.Size([15, 2, 5])\n",
            "Key-torch.Size([15, 6, 5])\n",
            "Value-+torch.Size([15, 6, 10])\n",
            "a_norm torch.Size([15, 2, 6])\n",
            "attention +torch.Size([15, 2, 10])\n",
            "shape after Multihead+torch.Size([15, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([15, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([15, 2, 10])\n",
            "0.0011236491845920682@19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwnrSzH2bmKN"
      },
      "source": [
        "x = [torch.sigmoid(torch.arange(-10,-1).float()).unsqueeze(-1).numpy().tolist()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tAR6ftZbroO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "790d21a4-62dd-4f0b-8a29-91fa79da8ff3"
      },
      "source": [
        "torch.tensor(x).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 9, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpfacWEDPmhP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c0885e21-7c0e-41e2-d4ba-c2586a6890c7"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "plt.ion()\n",
        "\n",
        "fig.show()\n",
        "fig.canvas.draw()\n",
        "\n",
        "o = []\n",
        "x = [torch.exp(torch.arange(-10,-1).float()).unsqueeze(-1).numpy().tolist()]\n",
        "\n",
        "#Draw graph comparing to sigmoid\n",
        "for i in range(-10, 10, output_sequence_length):\n",
        "    o.append([torch.sigmoid(torch.tensor(i).float())])\n",
        "    q = torch.tensor(x).float()\n",
        "    \n",
        "    if(output_sequence_length == 1):\n",
        "        x[0].append([t(q).detach().squeeze().numpy()])\n",
        "    else:\n",
        "        for a in t(q).detach().squeeze().numpy():\n",
        "            x[0].append([a])\n",
        "            \n",
        "ax.clear()\n",
        "ax.plot(x[0], label='Network output')\n",
        "ax.plot(o, label='Sigmoid function')\n",
        "ax.set_title(\"\")\n",
        "ax.legend(loc='upper left', frameon=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "after positional encoding shapetensor([[[ 0.9005,  0.6688, -0.4860,  0.5791,  0.8642,  0.2343,  0.0154,\n",
            "           0.6695,  0.8624,  0.3317],\n",
            "         [ 1.7419,  0.2090, -0.3282,  0.5667,  0.8893,  0.2340,  0.0195,\n",
            "           0.6694,  0.8629,  0.3316],\n",
            "         [ 1.8098, -0.7476, -0.1744,  0.5295,  0.9146,  0.2331,  0.0237,\n",
            "           0.6692,  0.8634,  0.3313],\n",
            "         [ 1.0416, -1.3219, -0.0284,  0.4687,  0.9400,  0.2314,  0.0282,\n",
            "           0.6685,  0.8636,  0.3307],\n",
            "         [ 0.1438, -0.9869,  0.1059,  0.3862,  0.9661,  0.2291,  0.0336,\n",
            "           0.6668,  0.8630,  0.3290],\n",
            "         [-0.0580, -0.0531,  0.2250,  0.2849,  0.9938,  0.2259,  0.0415,\n",
            "           0.6623,  0.8602,  0.3242],\n",
            "         [ 0.6222,  0.6136,  0.3252,  0.1701,  1.0263,  0.2215,  0.0561,\n",
            "           0.6502,  0.8516,  0.3114],\n",
            "         [ 1.5605,  0.3810,  0.4020,  0.0516,  1.0718,  0.2148,  0.0889,\n",
            "           0.6173,  0.8271,  0.2765],\n",
            "         [ 1.8981, -0.5902,  0.4483, -0.0485,  1.1527,  0.2030,  0.1713,\n",
            "           0.5281,  0.7595,  0.1817]]], grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 9, 10])\n",
            "Query-torch.Size([1, 9, 5])\n",
            "Key-torch.Size([1, 9, 5])\n",
            "Value-+torch.Size([1, 9, 10])\n",
            "a_norm torch.Size([1, 9, 9])\n",
            "attention +torch.Size([1, 9, 10])\n",
            "beforeQuery-torch.Size([1, 9, 10])\n",
            "Query-torch.Size([1, 9, 5])\n",
            "Key-torch.Size([1, 9, 5])\n",
            "Value-+torch.Size([1, 9, 10])\n",
            "a_norm torch.Size([1, 9, 9])\n",
            "attention +torch.Size([1, 9, 10])\n",
            "beforeQuery-torch.Size([1, 9, 10])\n",
            "Query-torch.Size([1, 9, 5])\n",
            "Key-torch.Size([1, 9, 5])\n",
            "Value-+torch.Size([1, 9, 10])\n",
            "a_norm torch.Size([1, 9, 9])\n",
            "attention +torch.Size([1, 9, 10])\n",
            "shape after Multihead+torch.Size([1, 9, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 9, 10])\n",
            "End Of Encoder shapetorch.Size([1, 9, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 9, 10])\n",
            "Query-torch.Size([1, 9, 5])\n",
            "Key-torch.Size([1, 9, 5])\n",
            "Value-+torch.Size([1, 9, 10])\n",
            "a_norm torch.Size([1, 9, 9])\n",
            "attention +torch.Size([1, 9, 10])\n",
            "beforeQuery-torch.Size([1, 9, 10])\n",
            "Query-torch.Size([1, 9, 5])\n",
            "Key-torch.Size([1, 9, 5])\n",
            "Value-+torch.Size([1, 9, 10])\n",
            "a_norm torch.Size([1, 9, 9])\n",
            "attention +torch.Size([1, 9, 10])\n",
            "beforeQuery-torch.Size([1, 9, 10])\n",
            "Query-torch.Size([1, 9, 5])\n",
            "Key-torch.Size([1, 9, 5])\n",
            "Value-+torch.Size([1, 9, 10])\n",
            "a_norm torch.Size([1, 9, 9])\n",
            "attention +torch.Size([1, 9, 10])\n",
            "shape after Multihead+torch.Size([1, 9, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 9, 10])\n",
            "End Of Encoder shapetorch.Size([1, 9, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 9, 10])\n",
            "Query-torch.Size([1, 9, 5])\n",
            "Key-torch.Size([1, 9, 5])\n",
            "Value-+torch.Size([1, 9, 10])\n",
            "a_norm torch.Size([1, 9, 9])\n",
            "attention +torch.Size([1, 9, 10])\n",
            "beforeQuery-torch.Size([1, 9, 10])\n",
            "Query-torch.Size([1, 9, 5])\n",
            "Key-torch.Size([1, 9, 5])\n",
            "Value-+torch.Size([1, 9, 10])\n",
            "a_norm torch.Size([1, 9, 9])\n",
            "attention +torch.Size([1, 9, 10])\n",
            "beforeQuery-torch.Size([1, 9, 10])\n",
            "Query-torch.Size([1, 9, 5])\n",
            "Key-torch.Size([1, 9, 5])\n",
            "Value-+torch.Size([1, 9, 10])\n",
            "a_norm torch.Size([1, 9, 9])\n",
            "attention +torch.Size([1, 9, 10])\n",
            "shape after Multihead+torch.Size([1, 9, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 9, 10])\n",
            "End Of Encoder shapetorch.Size([1, 9, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 9, 5])\n",
            "Value-+torch.Size([1, 9, 10])\n",
            "a_norm torch.Size([1, 2, 9])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 9, 5])\n",
            "Value-+torch.Size([1, 9, 10])\n",
            "a_norm torch.Size([1, 2, 9])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 9, 5])\n",
            "Value-+torch.Size([1, 9, 10])\n",
            "a_norm torch.Size([1, 2, 9])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 9, 5])\n",
            "Value-+torch.Size([1, 9, 10])\n",
            "a_norm torch.Size([1, 2, 9])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 9, 5])\n",
            "Value-+torch.Size([1, 9, 10])\n",
            "a_norm torch.Size([1, 2, 9])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 9, 5])\n",
            "Value-+torch.Size([1, 9, 10])\n",
            "a_norm torch.Size([1, 2, 9])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 9, 5])\n",
            "Value-+torch.Size([1, 9, 10])\n",
            "a_norm torch.Size([1, 2, 9])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 9, 5])\n",
            "Value-+torch.Size([1, 9, 10])\n",
            "a_norm torch.Size([1, 2, 9])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 9, 5])\n",
            "Value-+torch.Size([1, 9, 10])\n",
            "a_norm torch.Size([1, 2, 9])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 0.9005,  0.6688, -0.4860,  0.5791,  0.8642,  0.2343,  0.0154,\n",
            "           0.6695,  0.8624,  0.3317],\n",
            "         [ 1.7419,  0.2090, -0.3282,  0.5667,  0.8893,  0.2340,  0.0195,\n",
            "           0.6694,  0.8629,  0.3316],\n",
            "         [ 1.8098, -0.7476, -0.1744,  0.5295,  0.9146,  0.2331,  0.0237,\n",
            "           0.6692,  0.8634,  0.3313],\n",
            "         [ 1.0416, -1.3219, -0.0284,  0.4687,  0.9400,  0.2314,  0.0282,\n",
            "           0.6685,  0.8636,  0.3307],\n",
            "         [ 0.1438, -0.9869,  0.1059,  0.3862,  0.9661,  0.2291,  0.0336,\n",
            "           0.6668,  0.8630,  0.3290],\n",
            "         [-0.0580, -0.0531,  0.2250,  0.2849,  0.9938,  0.2259,  0.0415,\n",
            "           0.6623,  0.8602,  0.3242],\n",
            "         [ 0.6222,  0.6136,  0.3252,  0.1701,  1.0263,  0.2215,  0.0561,\n",
            "           0.6502,  0.8516,  0.3114],\n",
            "         [ 1.5605,  0.3810,  0.4020,  0.0516,  1.0718,  0.2148,  0.0889,\n",
            "           0.6173,  0.8271,  0.2765],\n",
            "         [ 1.8981, -0.5902,  0.4483, -0.0485,  1.1527,  0.2030,  0.1713,\n",
            "           0.5281,  0.7595,  0.1817],\n",
            "         [ 1.3305, -1.4881,  0.4599, -0.1165,  1.2810,  0.1846,  0.3198,\n",
            "           0.3637,  0.6343,  0.0068]]], grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 10, 10])\n",
            "Query-torch.Size([1, 10, 5])\n",
            "Key-torch.Size([1, 10, 5])\n",
            "Value-+torch.Size([1, 10, 10])\n",
            "a_norm torch.Size([1, 10, 10])\n",
            "attention +torch.Size([1, 10, 10])\n",
            "beforeQuery-torch.Size([1, 10, 10])\n",
            "Query-torch.Size([1, 10, 5])\n",
            "Key-torch.Size([1, 10, 5])\n",
            "Value-+torch.Size([1, 10, 10])\n",
            "a_norm torch.Size([1, 10, 10])\n",
            "attention +torch.Size([1, 10, 10])\n",
            "beforeQuery-torch.Size([1, 10, 10])\n",
            "Query-torch.Size([1, 10, 5])\n",
            "Key-torch.Size([1, 10, 5])\n",
            "Value-+torch.Size([1, 10, 10])\n",
            "a_norm torch.Size([1, 10, 10])\n",
            "attention +torch.Size([1, 10, 10])\n",
            "shape after Multihead+torch.Size([1, 10, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 10, 10])\n",
            "End Of Encoder shapetorch.Size([1, 10, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 10, 10])\n",
            "Query-torch.Size([1, 10, 5])\n",
            "Key-torch.Size([1, 10, 5])\n",
            "Value-+torch.Size([1, 10, 10])\n",
            "a_norm torch.Size([1, 10, 10])\n",
            "attention +torch.Size([1, 10, 10])\n",
            "beforeQuery-torch.Size([1, 10, 10])\n",
            "Query-torch.Size([1, 10, 5])\n",
            "Key-torch.Size([1, 10, 5])\n",
            "Value-+torch.Size([1, 10, 10])\n",
            "a_norm torch.Size([1, 10, 10])\n",
            "attention +torch.Size([1, 10, 10])\n",
            "beforeQuery-torch.Size([1, 10, 10])\n",
            "Query-torch.Size([1, 10, 5])\n",
            "Key-torch.Size([1, 10, 5])\n",
            "Value-+torch.Size([1, 10, 10])\n",
            "a_norm torch.Size([1, 10, 10])\n",
            "attention +torch.Size([1, 10, 10])\n",
            "shape after Multihead+torch.Size([1, 10, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 10, 10])\n",
            "End Of Encoder shapetorch.Size([1, 10, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 10, 10])\n",
            "Query-torch.Size([1, 10, 5])\n",
            "Key-torch.Size([1, 10, 5])\n",
            "Value-+torch.Size([1, 10, 10])\n",
            "a_norm torch.Size([1, 10, 10])\n",
            "attention +torch.Size([1, 10, 10])\n",
            "beforeQuery-torch.Size([1, 10, 10])\n",
            "Query-torch.Size([1, 10, 5])\n",
            "Key-torch.Size([1, 10, 5])\n",
            "Value-+torch.Size([1, 10, 10])\n",
            "a_norm torch.Size([1, 10, 10])\n",
            "attention +torch.Size([1, 10, 10])\n",
            "beforeQuery-torch.Size([1, 10, 10])\n",
            "Query-torch.Size([1, 10, 5])\n",
            "Key-torch.Size([1, 10, 5])\n",
            "Value-+torch.Size([1, 10, 10])\n",
            "a_norm torch.Size([1, 10, 10])\n",
            "attention +torch.Size([1, 10, 10])\n",
            "shape after Multihead+torch.Size([1, 10, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 10, 10])\n",
            "End Of Encoder shapetorch.Size([1, 10, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 10, 5])\n",
            "Value-+torch.Size([1, 10, 10])\n",
            "a_norm torch.Size([1, 2, 10])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 10, 5])\n",
            "Value-+torch.Size([1, 10, 10])\n",
            "a_norm torch.Size([1, 2, 10])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 10, 5])\n",
            "Value-+torch.Size([1, 10, 10])\n",
            "a_norm torch.Size([1, 2, 10])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 10, 5])\n",
            "Value-+torch.Size([1, 10, 10])\n",
            "a_norm torch.Size([1, 2, 10])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 10, 5])\n",
            "Value-+torch.Size([1, 10, 10])\n",
            "a_norm torch.Size([1, 2, 10])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 10, 5])\n",
            "Value-+torch.Size([1, 10, 10])\n",
            "a_norm torch.Size([1, 2, 10])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 10, 5])\n",
            "Value-+torch.Size([1, 10, 10])\n",
            "a_norm torch.Size([1, 2, 10])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 10, 5])\n",
            "Value-+torch.Size([1, 10, 10])\n",
            "a_norm torch.Size([1, 2, 10])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 10, 5])\n",
            "Value-+torch.Size([1, 10, 10])\n",
            "a_norm torch.Size([1, 2, 10])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 0.9005,  0.6688, -0.4860,  0.5791,  0.8642,  0.2343,  0.0154,\n",
            "           0.6695,  0.8624,  0.3317],\n",
            "         [ 1.7419,  0.2090, -0.3282,  0.5667,  0.8893,  0.2340,  0.0195,\n",
            "           0.6694,  0.8629,  0.3316],\n",
            "         [ 1.8098, -0.7476, -0.1744,  0.5295,  0.9146,  0.2331,  0.0237,\n",
            "           0.6692,  0.8634,  0.3313],\n",
            "         [ 1.0416, -1.3219, -0.0284,  0.4687,  0.9400,  0.2314,  0.0282,\n",
            "           0.6685,  0.8636,  0.3307],\n",
            "         [ 0.1438, -0.9869,  0.1059,  0.3862,  0.9661,  0.2291,  0.0336,\n",
            "           0.6668,  0.8630,  0.3290],\n",
            "         [-0.0580, -0.0531,  0.2250,  0.2849,  0.9938,  0.2259,  0.0415,\n",
            "           0.6623,  0.8602,  0.3242],\n",
            "         [ 0.6222,  0.6136,  0.3252,  0.1701,  1.0263,  0.2215,  0.0561,\n",
            "           0.6502,  0.8516,  0.3114],\n",
            "         [ 1.5605,  0.3810,  0.4020,  0.0516,  1.0718,  0.2148,  0.0889,\n",
            "           0.6173,  0.8271,  0.2765],\n",
            "         [ 1.8981, -0.5902,  0.4483, -0.0485,  1.1527,  0.2030,  0.1713,\n",
            "           0.5281,  0.7595,  0.1817],\n",
            "         [ 1.3305, -1.4881,  0.4599, -0.1165,  1.2810,  0.1846,  0.3198,\n",
            "           0.3637,  0.6343,  0.0068],\n",
            "         [ 0.3860, -1.5769,  0.4417, -0.1695,  1.4315,  0.1627,  0.4995,\n",
            "           0.1638,  0.4819, -0.2058]]], grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 11, 10])\n",
            "Query-torch.Size([1, 11, 5])\n",
            "Key-torch.Size([1, 11, 5])\n",
            "Value-+torch.Size([1, 11, 10])\n",
            "a_norm torch.Size([1, 11, 11])\n",
            "attention +torch.Size([1, 11, 10])\n",
            "beforeQuery-torch.Size([1, 11, 10])\n",
            "Query-torch.Size([1, 11, 5])\n",
            "Key-torch.Size([1, 11, 5])\n",
            "Value-+torch.Size([1, 11, 10])\n",
            "a_norm torch.Size([1, 11, 11])\n",
            "attention +torch.Size([1, 11, 10])\n",
            "beforeQuery-torch.Size([1, 11, 10])\n",
            "Query-torch.Size([1, 11, 5])\n",
            "Key-torch.Size([1, 11, 5])\n",
            "Value-+torch.Size([1, 11, 10])\n",
            "a_norm torch.Size([1, 11, 11])\n",
            "attention +torch.Size([1, 11, 10])\n",
            "shape after Multihead+torch.Size([1, 11, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 11, 10])\n",
            "End Of Encoder shapetorch.Size([1, 11, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 11, 10])\n",
            "Query-torch.Size([1, 11, 5])\n",
            "Key-torch.Size([1, 11, 5])\n",
            "Value-+torch.Size([1, 11, 10])\n",
            "a_norm torch.Size([1, 11, 11])\n",
            "attention +torch.Size([1, 11, 10])\n",
            "beforeQuery-torch.Size([1, 11, 10])\n",
            "Query-torch.Size([1, 11, 5])\n",
            "Key-torch.Size([1, 11, 5])\n",
            "Value-+torch.Size([1, 11, 10])\n",
            "a_norm torch.Size([1, 11, 11])\n",
            "attention +torch.Size([1, 11, 10])\n",
            "beforeQuery-torch.Size([1, 11, 10])\n",
            "Query-torch.Size([1, 11, 5])\n",
            "Key-torch.Size([1, 11, 5])\n",
            "Value-+torch.Size([1, 11, 10])\n",
            "a_norm torch.Size([1, 11, 11])\n",
            "attention +torch.Size([1, 11, 10])\n",
            "shape after Multihead+torch.Size([1, 11, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 11, 10])\n",
            "End Of Encoder shapetorch.Size([1, 11, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 11, 10])\n",
            "Query-torch.Size([1, 11, 5])\n",
            "Key-torch.Size([1, 11, 5])\n",
            "Value-+torch.Size([1, 11, 10])\n",
            "a_norm torch.Size([1, 11, 11])\n",
            "attention +torch.Size([1, 11, 10])\n",
            "beforeQuery-torch.Size([1, 11, 10])\n",
            "Query-torch.Size([1, 11, 5])\n",
            "Key-torch.Size([1, 11, 5])\n",
            "Value-+torch.Size([1, 11, 10])\n",
            "a_norm torch.Size([1, 11, 11])\n",
            "attention +torch.Size([1, 11, 10])\n",
            "beforeQuery-torch.Size([1, 11, 10])\n",
            "Query-torch.Size([1, 11, 5])\n",
            "Key-torch.Size([1, 11, 5])\n",
            "Value-+torch.Size([1, 11, 10])\n",
            "a_norm torch.Size([1, 11, 11])\n",
            "attention +torch.Size([1, 11, 10])\n",
            "shape after Multihead+torch.Size([1, 11, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 11, 10])\n",
            "End Of Encoder shapetorch.Size([1, 11, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 11, 5])\n",
            "Value-+torch.Size([1, 11, 10])\n",
            "a_norm torch.Size([1, 2, 11])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 11, 5])\n",
            "Value-+torch.Size([1, 11, 10])\n",
            "a_norm torch.Size([1, 2, 11])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 11, 5])\n",
            "Value-+torch.Size([1, 11, 10])\n",
            "a_norm torch.Size([1, 2, 11])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 11, 5])\n",
            "Value-+torch.Size([1, 11, 10])\n",
            "a_norm torch.Size([1, 2, 11])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 11, 5])\n",
            "Value-+torch.Size([1, 11, 10])\n",
            "a_norm torch.Size([1, 2, 11])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 11, 5])\n",
            "Value-+torch.Size([1, 11, 10])\n",
            "a_norm torch.Size([1, 2, 11])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 11, 5])\n",
            "Value-+torch.Size([1, 11, 10])\n",
            "a_norm torch.Size([1, 2, 11])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 11, 5])\n",
            "Value-+torch.Size([1, 11, 10])\n",
            "a_norm torch.Size([1, 2, 11])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 11, 5])\n",
            "Value-+torch.Size([1, 11, 10])\n",
            "a_norm torch.Size([1, 2, 11])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 0.9005,  0.6688, -0.4860,  0.5791,  0.8642,  0.2343,  0.0154,\n",
            "           0.6695,  0.8624,  0.3317],\n",
            "         [ 1.7419,  0.2090, -0.3282,  0.5667,  0.8893,  0.2340,  0.0195,\n",
            "           0.6694,  0.8629,  0.3316],\n",
            "         [ 1.8098, -0.7476, -0.1744,  0.5295,  0.9146,  0.2331,  0.0237,\n",
            "           0.6692,  0.8634,  0.3313],\n",
            "         [ 1.0416, -1.3219, -0.0284,  0.4687,  0.9400,  0.2314,  0.0282,\n",
            "           0.6685,  0.8636,  0.3307],\n",
            "         [ 0.1438, -0.9869,  0.1059,  0.3862,  0.9661,  0.2291,  0.0336,\n",
            "           0.6668,  0.8630,  0.3290],\n",
            "         [-0.0580, -0.0531,  0.2250,  0.2849,  0.9938,  0.2259,  0.0415,\n",
            "           0.6623,  0.8602,  0.3242],\n",
            "         [ 0.6222,  0.6136,  0.3252,  0.1701,  1.0263,  0.2215,  0.0561,\n",
            "           0.6502,  0.8516,  0.3114],\n",
            "         [ 1.5605,  0.3810,  0.4020,  0.0516,  1.0718,  0.2148,  0.0889,\n",
            "           0.6173,  0.8271,  0.2765],\n",
            "         [ 1.8981, -0.5902,  0.4483, -0.0485,  1.1527,  0.2030,  0.1713,\n",
            "           0.5281,  0.7595,  0.1817],\n",
            "         [ 1.3305, -1.4881,  0.4599, -0.1165,  1.2810,  0.1846,  0.3198,\n",
            "           0.3637,  0.6343,  0.0068],\n",
            "         [ 0.3860, -1.5769,  0.4417, -0.1695,  1.4315,  0.1627,  0.4995,\n",
            "           0.1638,  0.4819, -0.2058],\n",
            "         [-0.0551, -0.9373,  0.3907, -0.1940,  1.6157,  0.1360,  0.7262,\n",
            "          -0.0896,  0.2886, -0.4753]]], grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 12, 10])\n",
            "Query-torch.Size([1, 12, 5])\n",
            "Key-torch.Size([1, 12, 5])\n",
            "Value-+torch.Size([1, 12, 10])\n",
            "a_norm torch.Size([1, 12, 12])\n",
            "attention +torch.Size([1, 12, 10])\n",
            "beforeQuery-torch.Size([1, 12, 10])\n",
            "Query-torch.Size([1, 12, 5])\n",
            "Key-torch.Size([1, 12, 5])\n",
            "Value-+torch.Size([1, 12, 10])\n",
            "a_norm torch.Size([1, 12, 12])\n",
            "attention +torch.Size([1, 12, 10])\n",
            "beforeQuery-torch.Size([1, 12, 10])\n",
            "Query-torch.Size([1, 12, 5])\n",
            "Key-torch.Size([1, 12, 5])\n",
            "Value-+torch.Size([1, 12, 10])\n",
            "a_norm torch.Size([1, 12, 12])\n",
            "attention +torch.Size([1, 12, 10])\n",
            "shape after Multihead+torch.Size([1, 12, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 12, 10])\n",
            "End Of Encoder shapetorch.Size([1, 12, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 12, 10])\n",
            "Query-torch.Size([1, 12, 5])\n",
            "Key-torch.Size([1, 12, 5])\n",
            "Value-+torch.Size([1, 12, 10])\n",
            "a_norm torch.Size([1, 12, 12])\n",
            "attention +torch.Size([1, 12, 10])\n",
            "beforeQuery-torch.Size([1, 12, 10])\n",
            "Query-torch.Size([1, 12, 5])\n",
            "Key-torch.Size([1, 12, 5])\n",
            "Value-+torch.Size([1, 12, 10])\n",
            "a_norm torch.Size([1, 12, 12])\n",
            "attention +torch.Size([1, 12, 10])\n",
            "beforeQuery-torch.Size([1, 12, 10])\n",
            "Query-torch.Size([1, 12, 5])\n",
            "Key-torch.Size([1, 12, 5])\n",
            "Value-+torch.Size([1, 12, 10])\n",
            "a_norm torch.Size([1, 12, 12])\n",
            "attention +torch.Size([1, 12, 10])\n",
            "shape after Multihead+torch.Size([1, 12, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 12, 10])\n",
            "End Of Encoder shapetorch.Size([1, 12, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 12, 10])\n",
            "Query-torch.Size([1, 12, 5])\n",
            "Key-torch.Size([1, 12, 5])\n",
            "Value-+torch.Size([1, 12, 10])\n",
            "a_norm torch.Size([1, 12, 12])\n",
            "attention +torch.Size([1, 12, 10])\n",
            "beforeQuery-torch.Size([1, 12, 10])\n",
            "Query-torch.Size([1, 12, 5])\n",
            "Key-torch.Size([1, 12, 5])\n",
            "Value-+torch.Size([1, 12, 10])\n",
            "a_norm torch.Size([1, 12, 12])\n",
            "attention +torch.Size([1, 12, 10])\n",
            "beforeQuery-torch.Size([1, 12, 10])\n",
            "Query-torch.Size([1, 12, 5])\n",
            "Key-torch.Size([1, 12, 5])\n",
            "Value-+torch.Size([1, 12, 10])\n",
            "a_norm torch.Size([1, 12, 12])\n",
            "attention +torch.Size([1, 12, 10])\n",
            "shape after Multihead+torch.Size([1, 12, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 12, 10])\n",
            "End Of Encoder shapetorch.Size([1, 12, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 12, 5])\n",
            "Value-+torch.Size([1, 12, 10])\n",
            "a_norm torch.Size([1, 2, 12])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 12, 5])\n",
            "Value-+torch.Size([1, 12, 10])\n",
            "a_norm torch.Size([1, 2, 12])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 12, 5])\n",
            "Value-+torch.Size([1, 12, 10])\n",
            "a_norm torch.Size([1, 2, 12])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 12, 5])\n",
            "Value-+torch.Size([1, 12, 10])\n",
            "a_norm torch.Size([1, 2, 12])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 12, 5])\n",
            "Value-+torch.Size([1, 12, 10])\n",
            "a_norm torch.Size([1, 2, 12])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 12, 5])\n",
            "Value-+torch.Size([1, 12, 10])\n",
            "a_norm torch.Size([1, 2, 12])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 12, 5])\n",
            "Value-+torch.Size([1, 12, 10])\n",
            "a_norm torch.Size([1, 2, 12])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 12, 5])\n",
            "Value-+torch.Size([1, 12, 10])\n",
            "a_norm torch.Size([1, 2, 12])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 12, 5])\n",
            "Value-+torch.Size([1, 12, 10])\n",
            "a_norm torch.Size([1, 2, 12])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 0.9005,  0.6688, -0.4860,  0.5791,  0.8642,  0.2343,  0.0154,\n",
            "           0.6695,  0.8624,  0.3317],\n",
            "         [ 1.7419,  0.2090, -0.3282,  0.5667,  0.8893,  0.2340,  0.0195,\n",
            "           0.6694,  0.8629,  0.3316],\n",
            "         [ 1.8098, -0.7476, -0.1744,  0.5295,  0.9146,  0.2331,  0.0237,\n",
            "           0.6692,  0.8634,  0.3313],\n",
            "         [ 1.0416, -1.3219, -0.0284,  0.4687,  0.9400,  0.2314,  0.0282,\n",
            "           0.6685,  0.8636,  0.3307],\n",
            "         [ 0.1438, -0.9869,  0.1059,  0.3862,  0.9661,  0.2291,  0.0336,\n",
            "           0.6668,  0.8630,  0.3290],\n",
            "         [-0.0580, -0.0531,  0.2250,  0.2849,  0.9938,  0.2259,  0.0415,\n",
            "           0.6623,  0.8602,  0.3242],\n",
            "         [ 0.6222,  0.6136,  0.3252,  0.1701,  1.0263,  0.2215,  0.0561,\n",
            "           0.6502,  0.8516,  0.3114],\n",
            "         [ 1.5605,  0.3810,  0.4020,  0.0516,  1.0718,  0.2148,  0.0889,\n",
            "           0.6173,  0.8271,  0.2765],\n",
            "         [ 1.8981, -0.5902,  0.4483, -0.0485,  1.1527,  0.2030,  0.1713,\n",
            "           0.5281,  0.7595,  0.1817],\n",
            "         [ 1.3305, -1.4881,  0.4599, -0.1165,  1.2810,  0.1846,  0.3198,\n",
            "           0.3637,  0.6343,  0.0068],\n",
            "         [ 0.3860, -1.5769,  0.4417, -0.1695,  1.4315,  0.1627,  0.4995,\n",
            "           0.1638,  0.4819, -0.2058],\n",
            "         [-0.0551, -0.9373,  0.3907, -0.1940,  1.6157,  0.1360,  0.7262,\n",
            "          -0.0896,  0.2886, -0.4753],\n",
            "         [ 0.4187, -0.2411,  0.3258, -0.2538,  1.7520,  0.1147,  0.8866,\n",
            "          -0.2676,  0.1530, -0.6646]]], grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 13, 10])\n",
            "Query-torch.Size([1, 13, 5])\n",
            "Key-torch.Size([1, 13, 5])\n",
            "Value-+torch.Size([1, 13, 10])\n",
            "a_norm torch.Size([1, 13, 13])\n",
            "attention +torch.Size([1, 13, 10])\n",
            "beforeQuery-torch.Size([1, 13, 10])\n",
            "Query-torch.Size([1, 13, 5])\n",
            "Key-torch.Size([1, 13, 5])\n",
            "Value-+torch.Size([1, 13, 10])\n",
            "a_norm torch.Size([1, 13, 13])\n",
            "attention +torch.Size([1, 13, 10])\n",
            "beforeQuery-torch.Size([1, 13, 10])\n",
            "Query-torch.Size([1, 13, 5])\n",
            "Key-torch.Size([1, 13, 5])\n",
            "Value-+torch.Size([1, 13, 10])\n",
            "a_norm torch.Size([1, 13, 13])\n",
            "attention +torch.Size([1, 13, 10])\n",
            "shape after Multihead+torch.Size([1, 13, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 13, 10])\n",
            "End Of Encoder shapetorch.Size([1, 13, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 13, 10])\n",
            "Query-torch.Size([1, 13, 5])\n",
            "Key-torch.Size([1, 13, 5])\n",
            "Value-+torch.Size([1, 13, 10])\n",
            "a_norm torch.Size([1, 13, 13])\n",
            "attention +torch.Size([1, 13, 10])\n",
            "beforeQuery-torch.Size([1, 13, 10])\n",
            "Query-torch.Size([1, 13, 5])\n",
            "Key-torch.Size([1, 13, 5])\n",
            "Value-+torch.Size([1, 13, 10])\n",
            "a_norm torch.Size([1, 13, 13])\n",
            "attention +torch.Size([1, 13, 10])\n",
            "beforeQuery-torch.Size([1, 13, 10])\n",
            "Query-torch.Size([1, 13, 5])\n",
            "Key-torch.Size([1, 13, 5])\n",
            "Value-+torch.Size([1, 13, 10])\n",
            "a_norm torch.Size([1, 13, 13])\n",
            "attention +torch.Size([1, 13, 10])\n",
            "shape after Multihead+torch.Size([1, 13, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 13, 10])\n",
            "End Of Encoder shapetorch.Size([1, 13, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 13, 10])\n",
            "Query-torch.Size([1, 13, 5])\n",
            "Key-torch.Size([1, 13, 5])\n",
            "Value-+torch.Size([1, 13, 10])\n",
            "a_norm torch.Size([1, 13, 13])\n",
            "attention +torch.Size([1, 13, 10])\n",
            "beforeQuery-torch.Size([1, 13, 10])\n",
            "Query-torch.Size([1, 13, 5])\n",
            "Key-torch.Size([1, 13, 5])\n",
            "Value-+torch.Size([1, 13, 10])\n",
            "a_norm torch.Size([1, 13, 13])\n",
            "attention +torch.Size([1, 13, 10])\n",
            "beforeQuery-torch.Size([1, 13, 10])\n",
            "Query-torch.Size([1, 13, 5])\n",
            "Key-torch.Size([1, 13, 5])\n",
            "Value-+torch.Size([1, 13, 10])\n",
            "a_norm torch.Size([1, 13, 13])\n",
            "attention +torch.Size([1, 13, 10])\n",
            "shape after Multihead+torch.Size([1, 13, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 13, 10])\n",
            "End Of Encoder shapetorch.Size([1, 13, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 13, 5])\n",
            "Value-+torch.Size([1, 13, 10])\n",
            "a_norm torch.Size([1, 2, 13])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 13, 5])\n",
            "Value-+torch.Size([1, 13, 10])\n",
            "a_norm torch.Size([1, 2, 13])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 13, 5])\n",
            "Value-+torch.Size([1, 13, 10])\n",
            "a_norm torch.Size([1, 2, 13])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 13, 5])\n",
            "Value-+torch.Size([1, 13, 10])\n",
            "a_norm torch.Size([1, 2, 13])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 13, 5])\n",
            "Value-+torch.Size([1, 13, 10])\n",
            "a_norm torch.Size([1, 2, 13])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 13, 5])\n",
            "Value-+torch.Size([1, 13, 10])\n",
            "a_norm torch.Size([1, 2, 13])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 13, 5])\n",
            "Value-+torch.Size([1, 13, 10])\n",
            "a_norm torch.Size([1, 2, 13])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 13, 5])\n",
            "Value-+torch.Size([1, 13, 10])\n",
            "a_norm torch.Size([1, 2, 13])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 13, 5])\n",
            "Value-+torch.Size([1, 13, 10])\n",
            "a_norm torch.Size([1, 2, 13])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 0.9005,  0.6688, -0.4860,  0.5791,  0.8642,  0.2343,  0.0154,\n",
            "           0.6695,  0.8624,  0.3317],\n",
            "         [ 1.7419,  0.2090, -0.3282,  0.5667,  0.8893,  0.2340,  0.0195,\n",
            "           0.6694,  0.8629,  0.3316],\n",
            "         [ 1.8098, -0.7476, -0.1744,  0.5295,  0.9146,  0.2331,  0.0237,\n",
            "           0.6692,  0.8634,  0.3313],\n",
            "         [ 1.0416, -1.3219, -0.0284,  0.4687,  0.9400,  0.2314,  0.0282,\n",
            "           0.6685,  0.8636,  0.3307],\n",
            "         [ 0.1438, -0.9869,  0.1059,  0.3862,  0.9661,  0.2291,  0.0336,\n",
            "           0.6668,  0.8630,  0.3290],\n",
            "         [-0.0580, -0.0531,  0.2250,  0.2849,  0.9938,  0.2259,  0.0415,\n",
            "           0.6623,  0.8602,  0.3242],\n",
            "         [ 0.6222,  0.6136,  0.3252,  0.1701,  1.0263,  0.2215,  0.0561,\n",
            "           0.6502,  0.8516,  0.3114],\n",
            "         [ 1.5605,  0.3810,  0.4020,  0.0516,  1.0718,  0.2148,  0.0889,\n",
            "           0.6173,  0.8271,  0.2765],\n",
            "         [ 1.8981, -0.5902,  0.4483, -0.0485,  1.1527,  0.2030,  0.1713,\n",
            "           0.5281,  0.7595,  0.1817],\n",
            "         [ 1.3305, -1.4881,  0.4599, -0.1165,  1.2810,  0.1846,  0.3198,\n",
            "           0.3637,  0.6343,  0.0068],\n",
            "         [ 0.3860, -1.5769,  0.4417, -0.1695,  1.4315,  0.1627,  0.4995,\n",
            "           0.1638,  0.4819, -0.2058],\n",
            "         [-0.0551, -0.9373,  0.3907, -0.1940,  1.6157,  0.1360,  0.7262,\n",
            "          -0.0896,  0.2886, -0.4753],\n",
            "         [ 0.4187, -0.2411,  0.3258, -0.2538,  1.7520,  0.1147,  0.8866,\n",
            "          -0.2676,  0.1530, -0.6646],\n",
            "         [ 1.3790, -0.2259,  0.2541, -0.3674,  1.8138,  0.1021,  0.9435,\n",
            "          -0.3278,  0.1076, -0.7285]]], grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 14, 10])\n",
            "Query-torch.Size([1, 14, 5])\n",
            "Key-torch.Size([1, 14, 5])\n",
            "Value-+torch.Size([1, 14, 10])\n",
            "a_norm torch.Size([1, 14, 14])\n",
            "attention +torch.Size([1, 14, 10])\n",
            "beforeQuery-torch.Size([1, 14, 10])\n",
            "Query-torch.Size([1, 14, 5])\n",
            "Key-torch.Size([1, 14, 5])\n",
            "Value-+torch.Size([1, 14, 10])\n",
            "a_norm torch.Size([1, 14, 14])\n",
            "attention +torch.Size([1, 14, 10])\n",
            "beforeQuery-torch.Size([1, 14, 10])\n",
            "Query-torch.Size([1, 14, 5])\n",
            "Key-torch.Size([1, 14, 5])\n",
            "Value-+torch.Size([1, 14, 10])\n",
            "a_norm torch.Size([1, 14, 14])\n",
            "attention +torch.Size([1, 14, 10])\n",
            "shape after Multihead+torch.Size([1, 14, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 14, 10])\n",
            "End Of Encoder shapetorch.Size([1, 14, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 14, 10])\n",
            "Query-torch.Size([1, 14, 5])\n",
            "Key-torch.Size([1, 14, 5])\n",
            "Value-+torch.Size([1, 14, 10])\n",
            "a_norm torch.Size([1, 14, 14])\n",
            "attention +torch.Size([1, 14, 10])\n",
            "beforeQuery-torch.Size([1, 14, 10])\n",
            "Query-torch.Size([1, 14, 5])\n",
            "Key-torch.Size([1, 14, 5])\n",
            "Value-+torch.Size([1, 14, 10])\n",
            "a_norm torch.Size([1, 14, 14])\n",
            "attention +torch.Size([1, 14, 10])\n",
            "beforeQuery-torch.Size([1, 14, 10])\n",
            "Query-torch.Size([1, 14, 5])\n",
            "Key-torch.Size([1, 14, 5])\n",
            "Value-+torch.Size([1, 14, 10])\n",
            "a_norm torch.Size([1, 14, 14])\n",
            "attention +torch.Size([1, 14, 10])\n",
            "shape after Multihead+torch.Size([1, 14, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 14, 10])\n",
            "End Of Encoder shapetorch.Size([1, 14, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 14, 10])\n",
            "Query-torch.Size([1, 14, 5])\n",
            "Key-torch.Size([1, 14, 5])\n",
            "Value-+torch.Size([1, 14, 10])\n",
            "a_norm torch.Size([1, 14, 14])\n",
            "attention +torch.Size([1, 14, 10])\n",
            "beforeQuery-torch.Size([1, 14, 10])\n",
            "Query-torch.Size([1, 14, 5])\n",
            "Key-torch.Size([1, 14, 5])\n",
            "Value-+torch.Size([1, 14, 10])\n",
            "a_norm torch.Size([1, 14, 14])\n",
            "attention +torch.Size([1, 14, 10])\n",
            "beforeQuery-torch.Size([1, 14, 10])\n",
            "Query-torch.Size([1, 14, 5])\n",
            "Key-torch.Size([1, 14, 5])\n",
            "Value-+torch.Size([1, 14, 10])\n",
            "a_norm torch.Size([1, 14, 14])\n",
            "attention +torch.Size([1, 14, 10])\n",
            "shape after Multihead+torch.Size([1, 14, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 14, 10])\n",
            "End Of Encoder shapetorch.Size([1, 14, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 14, 5])\n",
            "Value-+torch.Size([1, 14, 10])\n",
            "a_norm torch.Size([1, 2, 14])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 14, 5])\n",
            "Value-+torch.Size([1, 14, 10])\n",
            "a_norm torch.Size([1, 2, 14])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 14, 5])\n",
            "Value-+torch.Size([1, 14, 10])\n",
            "a_norm torch.Size([1, 2, 14])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 14, 5])\n",
            "Value-+torch.Size([1, 14, 10])\n",
            "a_norm torch.Size([1, 2, 14])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 14, 5])\n",
            "Value-+torch.Size([1, 14, 10])\n",
            "a_norm torch.Size([1, 2, 14])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 14, 5])\n",
            "Value-+torch.Size([1, 14, 10])\n",
            "a_norm torch.Size([1, 2, 14])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 14, 5])\n",
            "Value-+torch.Size([1, 14, 10])\n",
            "a_norm torch.Size([1, 2, 14])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 14, 5])\n",
            "Value-+torch.Size([1, 14, 10])\n",
            "a_norm torch.Size([1, 2, 14])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 14, 5])\n",
            "Value-+torch.Size([1, 14, 10])\n",
            "a_norm torch.Size([1, 2, 14])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 0.9005,  0.6688, -0.4860,  0.5791,  0.8642,  0.2343,  0.0154,\n",
            "           0.6695,  0.8624,  0.3317],\n",
            "         [ 1.7419,  0.2090, -0.3282,  0.5667,  0.8893,  0.2340,  0.0195,\n",
            "           0.6694,  0.8629,  0.3316],\n",
            "         [ 1.8098, -0.7476, -0.1744,  0.5295,  0.9146,  0.2331,  0.0237,\n",
            "           0.6692,  0.8634,  0.3313],\n",
            "         [ 1.0416, -1.3219, -0.0284,  0.4687,  0.9400,  0.2314,  0.0282,\n",
            "           0.6685,  0.8636,  0.3307],\n",
            "         [ 0.1438, -0.9869,  0.1059,  0.3862,  0.9661,  0.2291,  0.0336,\n",
            "           0.6668,  0.8630,  0.3290],\n",
            "         [-0.0580, -0.0531,  0.2250,  0.2849,  0.9938,  0.2259,  0.0415,\n",
            "           0.6623,  0.8602,  0.3242],\n",
            "         [ 0.6222,  0.6136,  0.3252,  0.1701,  1.0263,  0.2215,  0.0561,\n",
            "           0.6502,  0.8516,  0.3114],\n",
            "         [ 1.5605,  0.3810,  0.4020,  0.0516,  1.0718,  0.2148,  0.0889,\n",
            "           0.6173,  0.8271,  0.2765],\n",
            "         [ 1.8981, -0.5902,  0.4483, -0.0485,  1.1527,  0.2030,  0.1713,\n",
            "           0.5281,  0.7595,  0.1817],\n",
            "         [ 1.3305, -1.4881,  0.4599, -0.1165,  1.2810,  0.1846,  0.3198,\n",
            "           0.3637,  0.6343,  0.0068],\n",
            "         [ 0.3860, -1.5769,  0.4417, -0.1695,  1.4315,  0.1627,  0.4995,\n",
            "           0.1638,  0.4819, -0.2058],\n",
            "         [-0.0551, -0.9373,  0.3907, -0.1940,  1.6157,  0.1360,  0.7262,\n",
            "          -0.0896,  0.2886, -0.4753],\n",
            "         [ 0.4187, -0.2411,  0.3258, -0.2538,  1.7520,  0.1147,  0.8866,\n",
            "          -0.2676,  0.1530, -0.6646],\n",
            "         [ 1.3790, -0.2259,  0.2541, -0.3674,  1.8138,  0.1021,  0.9435,\n",
            "          -0.3278,  0.1076, -0.7285],\n",
            "         [ 1.9499, -1.0025,  0.1678, -0.4970,  1.8421,  0.0932,  0.9539,\n",
            "          -0.3354,  0.1026, -0.7364]]], grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 15, 10])\n",
            "Query-torch.Size([1, 15, 5])\n",
            "Key-torch.Size([1, 15, 5])\n",
            "Value-+torch.Size([1, 15, 10])\n",
            "a_norm torch.Size([1, 15, 15])\n",
            "attention +torch.Size([1, 15, 10])\n",
            "beforeQuery-torch.Size([1, 15, 10])\n",
            "Query-torch.Size([1, 15, 5])\n",
            "Key-torch.Size([1, 15, 5])\n",
            "Value-+torch.Size([1, 15, 10])\n",
            "a_norm torch.Size([1, 15, 15])\n",
            "attention +torch.Size([1, 15, 10])\n",
            "beforeQuery-torch.Size([1, 15, 10])\n",
            "Query-torch.Size([1, 15, 5])\n",
            "Key-torch.Size([1, 15, 5])\n",
            "Value-+torch.Size([1, 15, 10])\n",
            "a_norm torch.Size([1, 15, 15])\n",
            "attention +torch.Size([1, 15, 10])\n",
            "shape after Multihead+torch.Size([1, 15, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 15, 10])\n",
            "End Of Encoder shapetorch.Size([1, 15, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 15, 10])\n",
            "Query-torch.Size([1, 15, 5])\n",
            "Key-torch.Size([1, 15, 5])\n",
            "Value-+torch.Size([1, 15, 10])\n",
            "a_norm torch.Size([1, 15, 15])\n",
            "attention +torch.Size([1, 15, 10])\n",
            "beforeQuery-torch.Size([1, 15, 10])\n",
            "Query-torch.Size([1, 15, 5])\n",
            "Key-torch.Size([1, 15, 5])\n",
            "Value-+torch.Size([1, 15, 10])\n",
            "a_norm torch.Size([1, 15, 15])\n",
            "attention +torch.Size([1, 15, 10])\n",
            "beforeQuery-torch.Size([1, 15, 10])\n",
            "Query-torch.Size([1, 15, 5])\n",
            "Key-torch.Size([1, 15, 5])\n",
            "Value-+torch.Size([1, 15, 10])\n",
            "a_norm torch.Size([1, 15, 15])\n",
            "attention +torch.Size([1, 15, 10])\n",
            "shape after Multihead+torch.Size([1, 15, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 15, 10])\n",
            "End Of Encoder shapetorch.Size([1, 15, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 15, 10])\n",
            "Query-torch.Size([1, 15, 5])\n",
            "Key-torch.Size([1, 15, 5])\n",
            "Value-+torch.Size([1, 15, 10])\n",
            "a_norm torch.Size([1, 15, 15])\n",
            "attention +torch.Size([1, 15, 10])\n",
            "beforeQuery-torch.Size([1, 15, 10])\n",
            "Query-torch.Size([1, 15, 5])\n",
            "Key-torch.Size([1, 15, 5])\n",
            "Value-+torch.Size([1, 15, 10])\n",
            "a_norm torch.Size([1, 15, 15])\n",
            "attention +torch.Size([1, 15, 10])\n",
            "beforeQuery-torch.Size([1, 15, 10])\n",
            "Query-torch.Size([1, 15, 5])\n",
            "Key-torch.Size([1, 15, 5])\n",
            "Value-+torch.Size([1, 15, 10])\n",
            "a_norm torch.Size([1, 15, 15])\n",
            "attention +torch.Size([1, 15, 10])\n",
            "shape after Multihead+torch.Size([1, 15, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 15, 10])\n",
            "End Of Encoder shapetorch.Size([1, 15, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 15, 5])\n",
            "Value-+torch.Size([1, 15, 10])\n",
            "a_norm torch.Size([1, 2, 15])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 15, 5])\n",
            "Value-+torch.Size([1, 15, 10])\n",
            "a_norm torch.Size([1, 2, 15])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 15, 5])\n",
            "Value-+torch.Size([1, 15, 10])\n",
            "a_norm torch.Size([1, 2, 15])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 15, 5])\n",
            "Value-+torch.Size([1, 15, 10])\n",
            "a_norm torch.Size([1, 2, 15])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 15, 5])\n",
            "Value-+torch.Size([1, 15, 10])\n",
            "a_norm torch.Size([1, 2, 15])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 15, 5])\n",
            "Value-+torch.Size([1, 15, 10])\n",
            "a_norm torch.Size([1, 2, 15])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 15, 5])\n",
            "Value-+torch.Size([1, 15, 10])\n",
            "a_norm torch.Size([1, 2, 15])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 15, 5])\n",
            "Value-+torch.Size([1, 15, 10])\n",
            "a_norm torch.Size([1, 2, 15])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 15, 5])\n",
            "Value-+torch.Size([1, 15, 10])\n",
            "a_norm torch.Size([1, 2, 15])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 0.9005,  0.6688, -0.4860,  0.5791,  0.8642,  0.2343,  0.0154,\n",
            "           0.6695,  0.8624,  0.3317],\n",
            "         [ 1.7419,  0.2090, -0.3282,  0.5667,  0.8893,  0.2340,  0.0195,\n",
            "           0.6694,  0.8629,  0.3316],\n",
            "         [ 1.8098, -0.7476, -0.1744,  0.5295,  0.9146,  0.2331,  0.0237,\n",
            "           0.6692,  0.8634,  0.3313],\n",
            "         [ 1.0416, -1.3219, -0.0284,  0.4687,  0.9400,  0.2314,  0.0282,\n",
            "           0.6685,  0.8636,  0.3307],\n",
            "         [ 0.1438, -0.9869,  0.1059,  0.3862,  0.9661,  0.2291,  0.0336,\n",
            "           0.6668,  0.8630,  0.3290],\n",
            "         [-0.0580, -0.0531,  0.2250,  0.2849,  0.9938,  0.2259,  0.0415,\n",
            "           0.6623,  0.8602,  0.3242],\n",
            "         [ 0.6222,  0.6136,  0.3252,  0.1701,  1.0263,  0.2215,  0.0561,\n",
            "           0.6502,  0.8516,  0.3114],\n",
            "         [ 1.5605,  0.3810,  0.4020,  0.0516,  1.0718,  0.2148,  0.0889,\n",
            "           0.6173,  0.8271,  0.2765],\n",
            "         [ 1.8981, -0.5902,  0.4483, -0.0485,  1.1527,  0.2030,  0.1713,\n",
            "           0.5281,  0.7595,  0.1817],\n",
            "         [ 1.3305, -1.4881,  0.4599, -0.1165,  1.2810,  0.1846,  0.3198,\n",
            "           0.3637,  0.6343,  0.0068],\n",
            "         [ 0.3860, -1.5769,  0.4417, -0.1695,  1.4315,  0.1627,  0.4995,\n",
            "           0.1638,  0.4819, -0.2058],\n",
            "         [-0.0551, -0.9373,  0.3907, -0.1940,  1.6157,  0.1360,  0.7262,\n",
            "          -0.0896,  0.2886, -0.4753],\n",
            "         [ 0.4187, -0.2411,  0.3258, -0.2538,  1.7520,  0.1147,  0.8866,\n",
            "          -0.2676,  0.1530, -0.6646],\n",
            "         [ 1.3790, -0.2259,  0.2541, -0.3674,  1.8138,  0.1021,  0.9435,\n",
            "          -0.3278,  0.1076, -0.7285],\n",
            "         [ 1.9499, -1.0025,  0.1678, -0.4970,  1.8421,  0.0932,  0.9539,\n",
            "          -0.3354,  0.1026, -0.7364],\n",
            "         [ 1.6097, -1.9005,  0.0622, -0.6142,  1.8668,  0.0841,  0.9596,\n",
            "          -0.3376,  0.1018, -0.7384]]], grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 16, 10])\n",
            "Query-torch.Size([1, 16, 5])\n",
            "Key-torch.Size([1, 16, 5])\n",
            "Value-+torch.Size([1, 16, 10])\n",
            "a_norm torch.Size([1, 16, 16])\n",
            "attention +torch.Size([1, 16, 10])\n",
            "beforeQuery-torch.Size([1, 16, 10])\n",
            "Query-torch.Size([1, 16, 5])\n",
            "Key-torch.Size([1, 16, 5])\n",
            "Value-+torch.Size([1, 16, 10])\n",
            "a_norm torch.Size([1, 16, 16])\n",
            "attention +torch.Size([1, 16, 10])\n",
            "beforeQuery-torch.Size([1, 16, 10])\n",
            "Query-torch.Size([1, 16, 5])\n",
            "Key-torch.Size([1, 16, 5])\n",
            "Value-+torch.Size([1, 16, 10])\n",
            "a_norm torch.Size([1, 16, 16])\n",
            "attention +torch.Size([1, 16, 10])\n",
            "shape after Multihead+torch.Size([1, 16, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 16, 10])\n",
            "End Of Encoder shapetorch.Size([1, 16, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 16, 10])\n",
            "Query-torch.Size([1, 16, 5])\n",
            "Key-torch.Size([1, 16, 5])\n",
            "Value-+torch.Size([1, 16, 10])\n",
            "a_norm torch.Size([1, 16, 16])\n",
            "attention +torch.Size([1, 16, 10])\n",
            "beforeQuery-torch.Size([1, 16, 10])\n",
            "Query-torch.Size([1, 16, 5])\n",
            "Key-torch.Size([1, 16, 5])\n",
            "Value-+torch.Size([1, 16, 10])\n",
            "a_norm torch.Size([1, 16, 16])\n",
            "attention +torch.Size([1, 16, 10])\n",
            "beforeQuery-torch.Size([1, 16, 10])\n",
            "Query-torch.Size([1, 16, 5])\n",
            "Key-torch.Size([1, 16, 5])\n",
            "Value-+torch.Size([1, 16, 10])\n",
            "a_norm torch.Size([1, 16, 16])\n",
            "attention +torch.Size([1, 16, 10])\n",
            "shape after Multihead+torch.Size([1, 16, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 16, 10])\n",
            "End Of Encoder shapetorch.Size([1, 16, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 16, 10])\n",
            "Query-torch.Size([1, 16, 5])\n",
            "Key-torch.Size([1, 16, 5])\n",
            "Value-+torch.Size([1, 16, 10])\n",
            "a_norm torch.Size([1, 16, 16])\n",
            "attention +torch.Size([1, 16, 10])\n",
            "beforeQuery-torch.Size([1, 16, 10])\n",
            "Query-torch.Size([1, 16, 5])\n",
            "Key-torch.Size([1, 16, 5])\n",
            "Value-+torch.Size([1, 16, 10])\n",
            "a_norm torch.Size([1, 16, 16])\n",
            "attention +torch.Size([1, 16, 10])\n",
            "beforeQuery-torch.Size([1, 16, 10])\n",
            "Query-torch.Size([1, 16, 5])\n",
            "Key-torch.Size([1, 16, 5])\n",
            "Value-+torch.Size([1, 16, 10])\n",
            "a_norm torch.Size([1, 16, 16])\n",
            "attention +torch.Size([1, 16, 10])\n",
            "shape after Multihead+torch.Size([1, 16, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 16, 10])\n",
            "End Of Encoder shapetorch.Size([1, 16, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 16, 5])\n",
            "Value-+torch.Size([1, 16, 10])\n",
            "a_norm torch.Size([1, 2, 16])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 16, 5])\n",
            "Value-+torch.Size([1, 16, 10])\n",
            "a_norm torch.Size([1, 2, 16])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 16, 5])\n",
            "Value-+torch.Size([1, 16, 10])\n",
            "a_norm torch.Size([1, 2, 16])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 16, 5])\n",
            "Value-+torch.Size([1, 16, 10])\n",
            "a_norm torch.Size([1, 2, 16])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 16, 5])\n",
            "Value-+torch.Size([1, 16, 10])\n",
            "a_norm torch.Size([1, 2, 16])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 16, 5])\n",
            "Value-+torch.Size([1, 16, 10])\n",
            "a_norm torch.Size([1, 2, 16])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 16, 5])\n",
            "Value-+torch.Size([1, 16, 10])\n",
            "a_norm torch.Size([1, 2, 16])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 16, 5])\n",
            "Value-+torch.Size([1, 16, 10])\n",
            "a_norm torch.Size([1, 2, 16])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 16, 5])\n",
            "Value-+torch.Size([1, 16, 10])\n",
            "a_norm torch.Size([1, 2, 16])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 0.9005,  0.6688, -0.4860,  0.5791,  0.8642,  0.2343,  0.0154,\n",
            "           0.6695,  0.8624,  0.3317],\n",
            "         [ 1.7419,  0.2090, -0.3282,  0.5667,  0.8893,  0.2340,  0.0195,\n",
            "           0.6694,  0.8629,  0.3316],\n",
            "         [ 1.8098, -0.7476, -0.1744,  0.5295,  0.9146,  0.2331,  0.0237,\n",
            "           0.6692,  0.8634,  0.3313],\n",
            "         [ 1.0416, -1.3219, -0.0284,  0.4687,  0.9400,  0.2314,  0.0282,\n",
            "           0.6685,  0.8636,  0.3307],\n",
            "         [ 0.1438, -0.9869,  0.1059,  0.3862,  0.9661,  0.2291,  0.0336,\n",
            "           0.6668,  0.8630,  0.3290],\n",
            "         [-0.0580, -0.0531,  0.2250,  0.2849,  0.9938,  0.2259,  0.0415,\n",
            "           0.6623,  0.8602,  0.3242],\n",
            "         [ 0.6222,  0.6136,  0.3252,  0.1701,  1.0263,  0.2215,  0.0561,\n",
            "           0.6502,  0.8516,  0.3114],\n",
            "         [ 1.5605,  0.3810,  0.4020,  0.0516,  1.0718,  0.2148,  0.0889,\n",
            "           0.6173,  0.8271,  0.2765],\n",
            "         [ 1.8981, -0.5902,  0.4483, -0.0485,  1.1527,  0.2030,  0.1713,\n",
            "           0.5281,  0.7595,  0.1817],\n",
            "         [ 1.3305, -1.4881,  0.4599, -0.1165,  1.2810,  0.1846,  0.3198,\n",
            "           0.3637,  0.6343,  0.0068],\n",
            "         [ 0.3860, -1.5769,  0.4417, -0.1695,  1.4315,  0.1627,  0.4995,\n",
            "           0.1638,  0.4819, -0.2058],\n",
            "         [-0.0551, -0.9373,  0.3907, -0.1940,  1.6157,  0.1360,  0.7262,\n",
            "          -0.0896,  0.2886, -0.4753],\n",
            "         [ 0.4187, -0.2411,  0.3258, -0.2538,  1.7520,  0.1147,  0.8866,\n",
            "          -0.2676,  0.1530, -0.6646],\n",
            "         [ 1.3790, -0.2259,  0.2541, -0.3674,  1.8138,  0.1021,  0.9435,\n",
            "          -0.3278,  0.1076, -0.7285],\n",
            "         [ 1.9499, -1.0025,  0.1678, -0.4970,  1.8421,  0.0932,  0.9539,\n",
            "          -0.3354,  0.1026, -0.7364],\n",
            "         [ 1.6097, -1.9005,  0.0622, -0.6142,  1.8668,  0.0841,  0.9596,\n",
            "          -0.3376,  0.1018, -0.7384],\n",
            "         [ 0.6716, -2.1008, -0.0608, -0.7129,  1.8919,  0.0743,  0.9661,\n",
            "          -0.3407,  0.1002, -0.7415]]], grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 17, 10])\n",
            "Query-torch.Size([1, 17, 5])\n",
            "Key-torch.Size([1, 17, 5])\n",
            "Value-+torch.Size([1, 17, 10])\n",
            "a_norm torch.Size([1, 17, 17])\n",
            "attention +torch.Size([1, 17, 10])\n",
            "beforeQuery-torch.Size([1, 17, 10])\n",
            "Query-torch.Size([1, 17, 5])\n",
            "Key-torch.Size([1, 17, 5])\n",
            "Value-+torch.Size([1, 17, 10])\n",
            "a_norm torch.Size([1, 17, 17])\n",
            "attention +torch.Size([1, 17, 10])\n",
            "beforeQuery-torch.Size([1, 17, 10])\n",
            "Query-torch.Size([1, 17, 5])\n",
            "Key-torch.Size([1, 17, 5])\n",
            "Value-+torch.Size([1, 17, 10])\n",
            "a_norm torch.Size([1, 17, 17])\n",
            "attention +torch.Size([1, 17, 10])\n",
            "shape after Multihead+torch.Size([1, 17, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 17, 10])\n",
            "End Of Encoder shapetorch.Size([1, 17, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 17, 10])\n",
            "Query-torch.Size([1, 17, 5])\n",
            "Key-torch.Size([1, 17, 5])\n",
            "Value-+torch.Size([1, 17, 10])\n",
            "a_norm torch.Size([1, 17, 17])\n",
            "attention +torch.Size([1, 17, 10])\n",
            "beforeQuery-torch.Size([1, 17, 10])\n",
            "Query-torch.Size([1, 17, 5])\n",
            "Key-torch.Size([1, 17, 5])\n",
            "Value-+torch.Size([1, 17, 10])\n",
            "a_norm torch.Size([1, 17, 17])\n",
            "attention +torch.Size([1, 17, 10])\n",
            "beforeQuery-torch.Size([1, 17, 10])\n",
            "Query-torch.Size([1, 17, 5])\n",
            "Key-torch.Size([1, 17, 5])\n",
            "Value-+torch.Size([1, 17, 10])\n",
            "a_norm torch.Size([1, 17, 17])\n",
            "attention +torch.Size([1, 17, 10])\n",
            "shape after Multihead+torch.Size([1, 17, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 17, 10])\n",
            "End Of Encoder shapetorch.Size([1, 17, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 17, 10])\n",
            "Query-torch.Size([1, 17, 5])\n",
            "Key-torch.Size([1, 17, 5])\n",
            "Value-+torch.Size([1, 17, 10])\n",
            "a_norm torch.Size([1, 17, 17])\n",
            "attention +torch.Size([1, 17, 10])\n",
            "beforeQuery-torch.Size([1, 17, 10])\n",
            "Query-torch.Size([1, 17, 5])\n",
            "Key-torch.Size([1, 17, 5])\n",
            "Value-+torch.Size([1, 17, 10])\n",
            "a_norm torch.Size([1, 17, 17])\n",
            "attention +torch.Size([1, 17, 10])\n",
            "beforeQuery-torch.Size([1, 17, 10])\n",
            "Query-torch.Size([1, 17, 5])\n",
            "Key-torch.Size([1, 17, 5])\n",
            "Value-+torch.Size([1, 17, 10])\n",
            "a_norm torch.Size([1, 17, 17])\n",
            "attention +torch.Size([1, 17, 10])\n",
            "shape after Multihead+torch.Size([1, 17, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 17, 10])\n",
            "End Of Encoder shapetorch.Size([1, 17, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 17, 5])\n",
            "Value-+torch.Size([1, 17, 10])\n",
            "a_norm torch.Size([1, 2, 17])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 17, 5])\n",
            "Value-+torch.Size([1, 17, 10])\n",
            "a_norm torch.Size([1, 2, 17])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 17, 5])\n",
            "Value-+torch.Size([1, 17, 10])\n",
            "a_norm torch.Size([1, 2, 17])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 17, 5])\n",
            "Value-+torch.Size([1, 17, 10])\n",
            "a_norm torch.Size([1, 2, 17])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 17, 5])\n",
            "Value-+torch.Size([1, 17, 10])\n",
            "a_norm torch.Size([1, 2, 17])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 17, 5])\n",
            "Value-+torch.Size([1, 17, 10])\n",
            "a_norm torch.Size([1, 2, 17])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 17, 5])\n",
            "Value-+torch.Size([1, 17, 10])\n",
            "a_norm torch.Size([1, 2, 17])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 17, 5])\n",
            "Value-+torch.Size([1, 17, 10])\n",
            "a_norm torch.Size([1, 2, 17])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 17, 5])\n",
            "Value-+torch.Size([1, 17, 10])\n",
            "a_norm torch.Size([1, 2, 17])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 9.0047e-01,  6.6880e-01, -4.8604e-01,  5.7915e-01,  8.6418e-01,\n",
            "           2.3434e-01,  1.5448e-02,  6.6951e-01,  8.6238e-01,  3.3166e-01],\n",
            "         [ 1.7419e+00,  2.0904e-01, -3.2823e-01,  5.6666e-01,  8.8935e-01,\n",
            "           2.3402e-01,  1.9501e-02,  6.6942e-01,  8.6295e-01,  3.3158e-01],\n",
            "         [ 1.8098e+00, -7.4759e-01, -1.7439e-01,  5.2949e-01,  9.1459e-01,\n",
            "           2.3306e-01,  2.3676e-02,  6.6917e-01,  8.6341e-01,  3.3134e-01],\n",
            "         [ 1.0416e+00, -1.3219e+00, -2.8416e-02,  4.6870e-01,  9.4004e-01,\n",
            "           2.3143e-01,  2.8185e-02,  6.6853e-01,  8.6358e-01,  3.3070e-01],\n",
            "         [ 1.4382e-01, -9.8688e-01,  1.0593e-01,  3.8617e-01,  9.6609e-01,\n",
            "           2.2910e-01,  3.3601e-02,  6.6684e-01,  8.6296e-01,  3.2896e-01],\n",
            "         [-5.8043e-02, -5.3148e-02,  2.2504e-01,  2.8492e-01,  9.9385e-01,\n",
            "           2.2591e-01,  4.1485e-02,  6.6234e-01,  8.6019e-01,  3.2424e-01],\n",
            "         [ 6.2217e-01,  6.1365e-01,  3.2520e-01,  1.7007e-01,  1.0263e+00,\n",
            "           2.2149e-01,  5.6074e-02,  6.5019e-01,  8.5159e-01,  3.1140e-01],\n",
            "         [ 1.5605e+00,  3.8098e-01,  4.0199e-01,  5.1561e-02,  1.0718e+00,\n",
            "           2.1480e-01,  8.8892e-02,  6.1731e-01,  8.2711e-01,  2.7651e-01],\n",
            "         [ 1.8981e+00, -5.9018e-01,  4.4829e-01, -4.8498e-02,  1.1527e+00,\n",
            "           2.0299e-01,  1.7126e-01,  5.2809e-01,  7.5949e-01,  1.8167e-01],\n",
            "         [ 1.3305e+00, -1.4881e+00,  4.5992e-01, -1.1651e-01,  1.2810e+00,\n",
            "           1.8458e-01,  3.1977e-01,  3.6369e-01,  6.3429e-01,  6.8173e-03],\n",
            "         [ 3.8603e-01, -1.5769e+00,  4.4166e-01, -1.6947e-01,  1.4315e+00,\n",
            "           1.6273e-01,  4.9951e-01,  1.6376e-01,  4.8189e-01, -2.0583e-01],\n",
            "         [-5.5102e-02, -9.3735e-01,  3.9071e-01, -1.9399e-01,  1.6157e+00,\n",
            "           1.3600e-01,  7.2624e-01, -8.9590e-02,  2.8858e-01, -4.7533e-01],\n",
            "         [ 4.1873e-01, -2.4111e-01,  3.2584e-01, -2.5384e-01,  1.7520e+00,\n",
            "           1.1468e-01,  8.8665e-01, -2.6757e-01,  1.5301e-01, -6.6458e-01],\n",
            "         [ 1.3790e+00, -2.2588e-01,  2.5410e-01, -3.6745e-01,  1.8138e+00,\n",
            "           1.0214e-01,  9.4346e-01, -3.2782e-01,  1.0764e-01, -7.2851e-01],\n",
            "         [ 1.9499e+00, -1.0025e+00,  1.6776e-01, -4.9695e-01,  1.8421e+00,\n",
            "           9.3195e-02,  9.5394e-01, -3.3543e-01,  1.0261e-01, -7.3638e-01],\n",
            "         [ 1.6097e+00, -1.9005e+00,  6.2225e-02, -6.1421e-01,  1.8668e+00,\n",
            "           8.4095e-02,  9.5960e-01, -3.3757e-01,  1.0177e-01, -7.3843e-01],\n",
            "         [ 6.7163e-01, -2.1008e+00, -6.0797e-02, -7.1286e-01,  1.8919e+00,\n",
            "           7.4330e-02,  9.6611e-01, -3.4071e-01,  1.0019e-01, -7.4151e-01],\n",
            "         [-1.7753e-03, -1.4195e+00, -1.9788e-01, -7.9166e-01,  1.9158e+00,\n",
            "           6.4100e-02,  9.7136e-01, -3.4242e-01,  9.9716e-02, -7.4305e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 18, 10])\n",
            "Query-torch.Size([1, 18, 5])\n",
            "Key-torch.Size([1, 18, 5])\n",
            "Value-+torch.Size([1, 18, 10])\n",
            "a_norm torch.Size([1, 18, 18])\n",
            "attention +torch.Size([1, 18, 10])\n",
            "beforeQuery-torch.Size([1, 18, 10])\n",
            "Query-torch.Size([1, 18, 5])\n",
            "Key-torch.Size([1, 18, 5])\n",
            "Value-+torch.Size([1, 18, 10])\n",
            "a_norm torch.Size([1, 18, 18])\n",
            "attention +torch.Size([1, 18, 10])\n",
            "beforeQuery-torch.Size([1, 18, 10])\n",
            "Query-torch.Size([1, 18, 5])\n",
            "Key-torch.Size([1, 18, 5])\n",
            "Value-+torch.Size([1, 18, 10])\n",
            "a_norm torch.Size([1, 18, 18])\n",
            "attention +torch.Size([1, 18, 10])\n",
            "shape after Multihead+torch.Size([1, 18, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 18, 10])\n",
            "End Of Encoder shapetorch.Size([1, 18, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 18, 10])\n",
            "Query-torch.Size([1, 18, 5])\n",
            "Key-torch.Size([1, 18, 5])\n",
            "Value-+torch.Size([1, 18, 10])\n",
            "a_norm torch.Size([1, 18, 18])\n",
            "attention +torch.Size([1, 18, 10])\n",
            "beforeQuery-torch.Size([1, 18, 10])\n",
            "Query-torch.Size([1, 18, 5])\n",
            "Key-torch.Size([1, 18, 5])\n",
            "Value-+torch.Size([1, 18, 10])\n",
            "a_norm torch.Size([1, 18, 18])\n",
            "attention +torch.Size([1, 18, 10])\n",
            "beforeQuery-torch.Size([1, 18, 10])\n",
            "Query-torch.Size([1, 18, 5])\n",
            "Key-torch.Size([1, 18, 5])\n",
            "Value-+torch.Size([1, 18, 10])\n",
            "a_norm torch.Size([1, 18, 18])\n",
            "attention +torch.Size([1, 18, 10])\n",
            "shape after Multihead+torch.Size([1, 18, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 18, 10])\n",
            "End Of Encoder shapetorch.Size([1, 18, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 18, 10])\n",
            "Query-torch.Size([1, 18, 5])\n",
            "Key-torch.Size([1, 18, 5])\n",
            "Value-+torch.Size([1, 18, 10])\n",
            "a_norm torch.Size([1, 18, 18])\n",
            "attention +torch.Size([1, 18, 10])\n",
            "beforeQuery-torch.Size([1, 18, 10])\n",
            "Query-torch.Size([1, 18, 5])\n",
            "Key-torch.Size([1, 18, 5])\n",
            "Value-+torch.Size([1, 18, 10])\n",
            "a_norm torch.Size([1, 18, 18])\n",
            "attention +torch.Size([1, 18, 10])\n",
            "beforeQuery-torch.Size([1, 18, 10])\n",
            "Query-torch.Size([1, 18, 5])\n",
            "Key-torch.Size([1, 18, 5])\n",
            "Value-+torch.Size([1, 18, 10])\n",
            "a_norm torch.Size([1, 18, 18])\n",
            "attention +torch.Size([1, 18, 10])\n",
            "shape after Multihead+torch.Size([1, 18, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 18, 10])\n",
            "End Of Encoder shapetorch.Size([1, 18, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 18, 5])\n",
            "Value-+torch.Size([1, 18, 10])\n",
            "a_norm torch.Size([1, 2, 18])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 18, 5])\n",
            "Value-+torch.Size([1, 18, 10])\n",
            "a_norm torch.Size([1, 2, 18])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 18, 5])\n",
            "Value-+torch.Size([1, 18, 10])\n",
            "a_norm torch.Size([1, 2, 18])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 18, 5])\n",
            "Value-+torch.Size([1, 18, 10])\n",
            "a_norm torch.Size([1, 2, 18])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 18, 5])\n",
            "Value-+torch.Size([1, 18, 10])\n",
            "a_norm torch.Size([1, 2, 18])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 18, 5])\n",
            "Value-+torch.Size([1, 18, 10])\n",
            "a_norm torch.Size([1, 2, 18])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 18, 5])\n",
            "Value-+torch.Size([1, 18, 10])\n",
            "a_norm torch.Size([1, 2, 18])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 18, 5])\n",
            "Value-+torch.Size([1, 18, 10])\n",
            "a_norm torch.Size([1, 2, 18])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 18, 5])\n",
            "Value-+torch.Size([1, 18, 10])\n",
            "a_norm torch.Size([1, 2, 18])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 9.0047e-01,  6.6880e-01, -4.8604e-01,  5.7915e-01,  8.6418e-01,\n",
            "           2.3434e-01,  1.5448e-02,  6.6951e-01,  8.6238e-01,  3.3166e-01],\n",
            "         [ 1.7419e+00,  2.0904e-01, -3.2823e-01,  5.6666e-01,  8.8935e-01,\n",
            "           2.3402e-01,  1.9501e-02,  6.6942e-01,  8.6295e-01,  3.3158e-01],\n",
            "         [ 1.8098e+00, -7.4759e-01, -1.7439e-01,  5.2949e-01,  9.1459e-01,\n",
            "           2.3306e-01,  2.3676e-02,  6.6917e-01,  8.6341e-01,  3.3134e-01],\n",
            "         [ 1.0416e+00, -1.3219e+00, -2.8416e-02,  4.6870e-01,  9.4004e-01,\n",
            "           2.3143e-01,  2.8185e-02,  6.6853e-01,  8.6358e-01,  3.3070e-01],\n",
            "         [ 1.4382e-01, -9.8688e-01,  1.0593e-01,  3.8617e-01,  9.6609e-01,\n",
            "           2.2910e-01,  3.3601e-02,  6.6684e-01,  8.6296e-01,  3.2896e-01],\n",
            "         [-5.8043e-02, -5.3148e-02,  2.2504e-01,  2.8492e-01,  9.9385e-01,\n",
            "           2.2591e-01,  4.1485e-02,  6.6234e-01,  8.6019e-01,  3.2424e-01],\n",
            "         [ 6.2217e-01,  6.1365e-01,  3.2520e-01,  1.7007e-01,  1.0263e+00,\n",
            "           2.2149e-01,  5.6074e-02,  6.5019e-01,  8.5159e-01,  3.1140e-01],\n",
            "         [ 1.5605e+00,  3.8098e-01,  4.0199e-01,  5.1561e-02,  1.0718e+00,\n",
            "           2.1480e-01,  8.8892e-02,  6.1731e-01,  8.2711e-01,  2.7651e-01],\n",
            "         [ 1.8981e+00, -5.9018e-01,  4.4829e-01, -4.8498e-02,  1.1527e+00,\n",
            "           2.0299e-01,  1.7126e-01,  5.2809e-01,  7.5949e-01,  1.8167e-01],\n",
            "         [ 1.3305e+00, -1.4881e+00,  4.5992e-01, -1.1651e-01,  1.2810e+00,\n",
            "           1.8458e-01,  3.1977e-01,  3.6369e-01,  6.3429e-01,  6.8173e-03],\n",
            "         [ 3.8603e-01, -1.5769e+00,  4.4166e-01, -1.6947e-01,  1.4315e+00,\n",
            "           1.6273e-01,  4.9951e-01,  1.6376e-01,  4.8189e-01, -2.0583e-01],\n",
            "         [-5.5102e-02, -9.3735e-01,  3.9071e-01, -1.9399e-01,  1.6157e+00,\n",
            "           1.3600e-01,  7.2624e-01, -8.9590e-02,  2.8858e-01, -4.7533e-01],\n",
            "         [ 4.1873e-01, -2.4111e-01,  3.2584e-01, -2.5384e-01,  1.7520e+00,\n",
            "           1.1468e-01,  8.8665e-01, -2.6757e-01,  1.5301e-01, -6.6458e-01],\n",
            "         [ 1.3790e+00, -2.2588e-01,  2.5410e-01, -3.6745e-01,  1.8138e+00,\n",
            "           1.0214e-01,  9.4346e-01, -3.2782e-01,  1.0764e-01, -7.2851e-01],\n",
            "         [ 1.9499e+00, -1.0025e+00,  1.6776e-01, -4.9695e-01,  1.8421e+00,\n",
            "           9.3195e-02,  9.5394e-01, -3.3543e-01,  1.0261e-01, -7.3638e-01],\n",
            "         [ 1.6097e+00, -1.9005e+00,  6.2225e-02, -6.1421e-01,  1.8668e+00,\n",
            "           8.4095e-02,  9.5960e-01, -3.3757e-01,  1.0177e-01, -7.3843e-01],\n",
            "         [ 6.7163e-01, -2.1008e+00, -6.0797e-02, -7.1286e-01,  1.8919e+00,\n",
            "           7.4330e-02,  9.6611e-01, -3.4071e-01,  1.0019e-01, -7.4151e-01],\n",
            "         [-1.7753e-03, -1.4195e+00, -1.9788e-01, -7.9166e-01,  1.9158e+00,\n",
            "           6.4100e-02,  9.7136e-01, -3.4242e-01,  9.9716e-02, -7.4305e-01],\n",
            "         [ 2.0859e-01, -4.8338e-01, -3.4549e-01, -8.4903e-01,  1.9380e+00,\n",
            "           5.3472e-02,  9.7465e-01, -3.4192e-01,  1.0094e-01, -7.4224e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 19, 10])\n",
            "Query-torch.Size([1, 19, 5])\n",
            "Key-torch.Size([1, 19, 5])\n",
            "Value-+torch.Size([1, 19, 10])\n",
            "a_norm torch.Size([1, 19, 19])\n",
            "attention +torch.Size([1, 19, 10])\n",
            "beforeQuery-torch.Size([1, 19, 10])\n",
            "Query-torch.Size([1, 19, 5])\n",
            "Key-torch.Size([1, 19, 5])\n",
            "Value-+torch.Size([1, 19, 10])\n",
            "a_norm torch.Size([1, 19, 19])\n",
            "attention +torch.Size([1, 19, 10])\n",
            "beforeQuery-torch.Size([1, 19, 10])\n",
            "Query-torch.Size([1, 19, 5])\n",
            "Key-torch.Size([1, 19, 5])\n",
            "Value-+torch.Size([1, 19, 10])\n",
            "a_norm torch.Size([1, 19, 19])\n",
            "attention +torch.Size([1, 19, 10])\n",
            "shape after Multihead+torch.Size([1, 19, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 19, 10])\n",
            "End Of Encoder shapetorch.Size([1, 19, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 19, 10])\n",
            "Query-torch.Size([1, 19, 5])\n",
            "Key-torch.Size([1, 19, 5])\n",
            "Value-+torch.Size([1, 19, 10])\n",
            "a_norm torch.Size([1, 19, 19])\n",
            "attention +torch.Size([1, 19, 10])\n",
            "beforeQuery-torch.Size([1, 19, 10])\n",
            "Query-torch.Size([1, 19, 5])\n",
            "Key-torch.Size([1, 19, 5])\n",
            "Value-+torch.Size([1, 19, 10])\n",
            "a_norm torch.Size([1, 19, 19])\n",
            "attention +torch.Size([1, 19, 10])\n",
            "beforeQuery-torch.Size([1, 19, 10])\n",
            "Query-torch.Size([1, 19, 5])\n",
            "Key-torch.Size([1, 19, 5])\n",
            "Value-+torch.Size([1, 19, 10])\n",
            "a_norm torch.Size([1, 19, 19])\n",
            "attention +torch.Size([1, 19, 10])\n",
            "shape after Multihead+torch.Size([1, 19, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 19, 10])\n",
            "End Of Encoder shapetorch.Size([1, 19, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 19, 10])\n",
            "Query-torch.Size([1, 19, 5])\n",
            "Key-torch.Size([1, 19, 5])\n",
            "Value-+torch.Size([1, 19, 10])\n",
            "a_norm torch.Size([1, 19, 19])\n",
            "attention +torch.Size([1, 19, 10])\n",
            "beforeQuery-torch.Size([1, 19, 10])\n",
            "Query-torch.Size([1, 19, 5])\n",
            "Key-torch.Size([1, 19, 5])\n",
            "Value-+torch.Size([1, 19, 10])\n",
            "a_norm torch.Size([1, 19, 19])\n",
            "attention +torch.Size([1, 19, 10])\n",
            "beforeQuery-torch.Size([1, 19, 10])\n",
            "Query-torch.Size([1, 19, 5])\n",
            "Key-torch.Size([1, 19, 5])\n",
            "Value-+torch.Size([1, 19, 10])\n",
            "a_norm torch.Size([1, 19, 19])\n",
            "attention +torch.Size([1, 19, 10])\n",
            "shape after Multihead+torch.Size([1, 19, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 19, 10])\n",
            "End Of Encoder shapetorch.Size([1, 19, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 19, 5])\n",
            "Value-+torch.Size([1, 19, 10])\n",
            "a_norm torch.Size([1, 2, 19])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 19, 5])\n",
            "Value-+torch.Size([1, 19, 10])\n",
            "a_norm torch.Size([1, 2, 19])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 19, 5])\n",
            "Value-+torch.Size([1, 19, 10])\n",
            "a_norm torch.Size([1, 2, 19])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 19, 5])\n",
            "Value-+torch.Size([1, 19, 10])\n",
            "a_norm torch.Size([1, 2, 19])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 19, 5])\n",
            "Value-+torch.Size([1, 19, 10])\n",
            "a_norm torch.Size([1, 2, 19])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 19, 5])\n",
            "Value-+torch.Size([1, 19, 10])\n",
            "a_norm torch.Size([1, 2, 19])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 19, 5])\n",
            "Value-+torch.Size([1, 19, 10])\n",
            "a_norm torch.Size([1, 2, 19])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 19, 5])\n",
            "Value-+torch.Size([1, 19, 10])\n",
            "a_norm torch.Size([1, 2, 19])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 19, 5])\n",
            "Value-+torch.Size([1, 19, 10])\n",
            "a_norm torch.Size([1, 2, 19])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 9.0047e-01,  6.6880e-01, -4.8604e-01,  5.7915e-01,  8.6418e-01,\n",
            "           2.3434e-01,  1.5448e-02,  6.6951e-01,  8.6238e-01,  3.3166e-01],\n",
            "         [ 1.7419e+00,  2.0904e-01, -3.2823e-01,  5.6666e-01,  8.8935e-01,\n",
            "           2.3402e-01,  1.9501e-02,  6.6942e-01,  8.6295e-01,  3.3158e-01],\n",
            "         [ 1.8098e+00, -7.4759e-01, -1.7439e-01,  5.2949e-01,  9.1459e-01,\n",
            "           2.3306e-01,  2.3676e-02,  6.6917e-01,  8.6341e-01,  3.3134e-01],\n",
            "         [ 1.0416e+00, -1.3219e+00, -2.8416e-02,  4.6870e-01,  9.4004e-01,\n",
            "           2.3143e-01,  2.8185e-02,  6.6853e-01,  8.6358e-01,  3.3070e-01],\n",
            "         [ 1.4382e-01, -9.8688e-01,  1.0593e-01,  3.8617e-01,  9.6609e-01,\n",
            "           2.2910e-01,  3.3601e-02,  6.6684e-01,  8.6296e-01,  3.2896e-01],\n",
            "         [-5.8043e-02, -5.3148e-02,  2.2504e-01,  2.8492e-01,  9.9385e-01,\n",
            "           2.2591e-01,  4.1485e-02,  6.6234e-01,  8.6019e-01,  3.2424e-01],\n",
            "         [ 6.2217e-01,  6.1365e-01,  3.2520e-01,  1.7007e-01,  1.0263e+00,\n",
            "           2.2149e-01,  5.6074e-02,  6.5019e-01,  8.5159e-01,  3.1140e-01],\n",
            "         [ 1.5605e+00,  3.8098e-01,  4.0199e-01,  5.1561e-02,  1.0718e+00,\n",
            "           2.1480e-01,  8.8892e-02,  6.1731e-01,  8.2711e-01,  2.7651e-01],\n",
            "         [ 1.8981e+00, -5.9018e-01,  4.4829e-01, -4.8498e-02,  1.1527e+00,\n",
            "           2.0299e-01,  1.7126e-01,  5.2809e-01,  7.5949e-01,  1.8167e-01],\n",
            "         [ 1.3305e+00, -1.4881e+00,  4.5992e-01, -1.1651e-01,  1.2810e+00,\n",
            "           1.8458e-01,  3.1977e-01,  3.6369e-01,  6.3429e-01,  6.8173e-03],\n",
            "         [ 3.8603e-01, -1.5769e+00,  4.4166e-01, -1.6947e-01,  1.4315e+00,\n",
            "           1.6273e-01,  4.9951e-01,  1.6376e-01,  4.8189e-01, -2.0583e-01],\n",
            "         [-5.5102e-02, -9.3735e-01,  3.9071e-01, -1.9399e-01,  1.6157e+00,\n",
            "           1.3600e-01,  7.2624e-01, -8.9590e-02,  2.8858e-01, -4.7533e-01],\n",
            "         [ 4.1873e-01, -2.4111e-01,  3.2584e-01, -2.5384e-01,  1.7520e+00,\n",
            "           1.1468e-01,  8.8665e-01, -2.6757e-01,  1.5301e-01, -6.6458e-01],\n",
            "         [ 1.3790e+00, -2.2588e-01,  2.5410e-01, -3.6745e-01,  1.8138e+00,\n",
            "           1.0214e-01,  9.4346e-01, -3.2782e-01,  1.0764e-01, -7.2851e-01],\n",
            "         [ 1.9499e+00, -1.0025e+00,  1.6776e-01, -4.9695e-01,  1.8421e+00,\n",
            "           9.3195e-02,  9.5394e-01, -3.3543e-01,  1.0261e-01, -7.3638e-01],\n",
            "         [ 1.6097e+00, -1.9005e+00,  6.2225e-02, -6.1421e-01,  1.8668e+00,\n",
            "           8.4095e-02,  9.5960e-01, -3.3757e-01,  1.0177e-01, -7.3843e-01],\n",
            "         [ 6.7163e-01, -2.1008e+00, -6.0797e-02, -7.1286e-01,  1.8919e+00,\n",
            "           7.4330e-02,  9.6611e-01, -3.4071e-01,  1.0019e-01, -7.4151e-01],\n",
            "         [-1.7753e-03, -1.4195e+00, -1.9788e-01, -7.9166e-01,  1.9158e+00,\n",
            "           6.4100e-02,  9.7136e-01, -3.4242e-01,  9.9716e-02, -7.4305e-01],\n",
            "         [ 2.0859e-01, -4.8338e-01, -3.4549e-01, -8.4903e-01,  1.9380e+00,\n",
            "           5.3472e-02,  9.7465e-01, -3.4192e-01,  1.0094e-01, -7.4224e-01],\n",
            "         [ 1.1094e+00, -1.5365e-01, -5.0012e-01, -8.8284e-01,  1.9594e+00,\n",
            "           4.2348e-02,  9.7715e-01, -3.4054e-01,  1.0285e-01, -7.4047e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 20, 10])\n",
            "Query-torch.Size([1, 20, 5])\n",
            "Key-torch.Size([1, 20, 5])\n",
            "Value-+torch.Size([1, 20, 10])\n",
            "a_norm torch.Size([1, 20, 20])\n",
            "attention +torch.Size([1, 20, 10])\n",
            "beforeQuery-torch.Size([1, 20, 10])\n",
            "Query-torch.Size([1, 20, 5])\n",
            "Key-torch.Size([1, 20, 5])\n",
            "Value-+torch.Size([1, 20, 10])\n",
            "a_norm torch.Size([1, 20, 20])\n",
            "attention +torch.Size([1, 20, 10])\n",
            "beforeQuery-torch.Size([1, 20, 10])\n",
            "Query-torch.Size([1, 20, 5])\n",
            "Key-torch.Size([1, 20, 5])\n",
            "Value-+torch.Size([1, 20, 10])\n",
            "a_norm torch.Size([1, 20, 20])\n",
            "attention +torch.Size([1, 20, 10])\n",
            "shape after Multihead+torch.Size([1, 20, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 20, 10])\n",
            "End Of Encoder shapetorch.Size([1, 20, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 20, 10])\n",
            "Query-torch.Size([1, 20, 5])\n",
            "Key-torch.Size([1, 20, 5])\n",
            "Value-+torch.Size([1, 20, 10])\n",
            "a_norm torch.Size([1, 20, 20])\n",
            "attention +torch.Size([1, 20, 10])\n",
            "beforeQuery-torch.Size([1, 20, 10])\n",
            "Query-torch.Size([1, 20, 5])\n",
            "Key-torch.Size([1, 20, 5])\n",
            "Value-+torch.Size([1, 20, 10])\n",
            "a_norm torch.Size([1, 20, 20])\n",
            "attention +torch.Size([1, 20, 10])\n",
            "beforeQuery-torch.Size([1, 20, 10])\n",
            "Query-torch.Size([1, 20, 5])\n",
            "Key-torch.Size([1, 20, 5])\n",
            "Value-+torch.Size([1, 20, 10])\n",
            "a_norm torch.Size([1, 20, 20])\n",
            "attention +torch.Size([1, 20, 10])\n",
            "shape after Multihead+torch.Size([1, 20, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 20, 10])\n",
            "End Of Encoder shapetorch.Size([1, 20, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 20, 10])\n",
            "Query-torch.Size([1, 20, 5])\n",
            "Key-torch.Size([1, 20, 5])\n",
            "Value-+torch.Size([1, 20, 10])\n",
            "a_norm torch.Size([1, 20, 20])\n",
            "attention +torch.Size([1, 20, 10])\n",
            "beforeQuery-torch.Size([1, 20, 10])\n",
            "Query-torch.Size([1, 20, 5])\n",
            "Key-torch.Size([1, 20, 5])\n",
            "Value-+torch.Size([1, 20, 10])\n",
            "a_norm torch.Size([1, 20, 20])\n",
            "attention +torch.Size([1, 20, 10])\n",
            "beforeQuery-torch.Size([1, 20, 10])\n",
            "Query-torch.Size([1, 20, 5])\n",
            "Key-torch.Size([1, 20, 5])\n",
            "Value-+torch.Size([1, 20, 10])\n",
            "a_norm torch.Size([1, 20, 20])\n",
            "attention +torch.Size([1, 20, 10])\n",
            "shape after Multihead+torch.Size([1, 20, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 20, 10])\n",
            "End Of Encoder shapetorch.Size([1, 20, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 20, 5])\n",
            "Value-+torch.Size([1, 20, 10])\n",
            "a_norm torch.Size([1, 2, 20])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 20, 5])\n",
            "Value-+torch.Size([1, 20, 10])\n",
            "a_norm torch.Size([1, 2, 20])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 20, 5])\n",
            "Value-+torch.Size([1, 20, 10])\n",
            "a_norm torch.Size([1, 2, 20])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 20, 5])\n",
            "Value-+torch.Size([1, 20, 10])\n",
            "a_norm torch.Size([1, 2, 20])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 20, 5])\n",
            "Value-+torch.Size([1, 20, 10])\n",
            "a_norm torch.Size([1, 2, 20])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 20, 5])\n",
            "Value-+torch.Size([1, 20, 10])\n",
            "a_norm torch.Size([1, 2, 20])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 20, 5])\n",
            "Value-+torch.Size([1, 20, 10])\n",
            "a_norm torch.Size([1, 2, 20])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 20, 5])\n",
            "Value-+torch.Size([1, 20, 10])\n",
            "a_norm torch.Size([1, 2, 20])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 20, 5])\n",
            "Value-+torch.Size([1, 20, 10])\n",
            "a_norm torch.Size([1, 2, 20])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 9.0047e-01,  6.6880e-01, -4.8604e-01,  5.7915e-01,  8.6418e-01,\n",
            "           2.3434e-01,  1.5448e-02,  6.6951e-01,  8.6238e-01,  3.3166e-01],\n",
            "         [ 1.7419e+00,  2.0904e-01, -3.2823e-01,  5.6666e-01,  8.8935e-01,\n",
            "           2.3402e-01,  1.9501e-02,  6.6942e-01,  8.6295e-01,  3.3158e-01],\n",
            "         [ 1.8098e+00, -7.4759e-01, -1.7439e-01,  5.2949e-01,  9.1459e-01,\n",
            "           2.3306e-01,  2.3676e-02,  6.6917e-01,  8.6341e-01,  3.3134e-01],\n",
            "         [ 1.0416e+00, -1.3219e+00, -2.8416e-02,  4.6870e-01,  9.4004e-01,\n",
            "           2.3143e-01,  2.8185e-02,  6.6853e-01,  8.6358e-01,  3.3070e-01],\n",
            "         [ 1.4382e-01, -9.8688e-01,  1.0593e-01,  3.8617e-01,  9.6609e-01,\n",
            "           2.2910e-01,  3.3601e-02,  6.6684e-01,  8.6296e-01,  3.2896e-01],\n",
            "         [-5.8043e-02, -5.3148e-02,  2.2504e-01,  2.8492e-01,  9.9385e-01,\n",
            "           2.2591e-01,  4.1485e-02,  6.6234e-01,  8.6019e-01,  3.2424e-01],\n",
            "         [ 6.2217e-01,  6.1365e-01,  3.2520e-01,  1.7007e-01,  1.0263e+00,\n",
            "           2.2149e-01,  5.6074e-02,  6.5019e-01,  8.5159e-01,  3.1140e-01],\n",
            "         [ 1.5605e+00,  3.8098e-01,  4.0199e-01,  5.1561e-02,  1.0718e+00,\n",
            "           2.1480e-01,  8.8892e-02,  6.1731e-01,  8.2711e-01,  2.7651e-01],\n",
            "         [ 1.8981e+00, -5.9018e-01,  4.4829e-01, -4.8498e-02,  1.1527e+00,\n",
            "           2.0299e-01,  1.7126e-01,  5.2809e-01,  7.5949e-01,  1.8167e-01],\n",
            "         [ 1.3305e+00, -1.4881e+00,  4.5992e-01, -1.1651e-01,  1.2810e+00,\n",
            "           1.8458e-01,  3.1977e-01,  3.6369e-01,  6.3429e-01,  6.8173e-03],\n",
            "         [ 3.8603e-01, -1.5769e+00,  4.4166e-01, -1.6947e-01,  1.4315e+00,\n",
            "           1.6273e-01,  4.9951e-01,  1.6376e-01,  4.8189e-01, -2.0583e-01],\n",
            "         [-5.5102e-02, -9.3735e-01,  3.9071e-01, -1.9399e-01,  1.6157e+00,\n",
            "           1.3600e-01,  7.2624e-01, -8.9590e-02,  2.8858e-01, -4.7533e-01],\n",
            "         [ 4.1873e-01, -2.4111e-01,  3.2584e-01, -2.5384e-01,  1.7520e+00,\n",
            "           1.1468e-01,  8.8665e-01, -2.6757e-01,  1.5301e-01, -6.6458e-01],\n",
            "         [ 1.3790e+00, -2.2588e-01,  2.5410e-01, -3.6745e-01,  1.8138e+00,\n",
            "           1.0214e-01,  9.4346e-01, -3.2782e-01,  1.0764e-01, -7.2851e-01],\n",
            "         [ 1.9499e+00, -1.0025e+00,  1.6776e-01, -4.9695e-01,  1.8421e+00,\n",
            "           9.3195e-02,  9.5394e-01, -3.3543e-01,  1.0261e-01, -7.3638e-01],\n",
            "         [ 1.6097e+00, -1.9005e+00,  6.2225e-02, -6.1421e-01,  1.8668e+00,\n",
            "           8.4095e-02,  9.5960e-01, -3.3757e-01,  1.0177e-01, -7.3843e-01],\n",
            "         [ 6.7163e-01, -2.1008e+00, -6.0797e-02, -7.1286e-01,  1.8919e+00,\n",
            "           7.4330e-02,  9.6611e-01, -3.4071e-01,  1.0019e-01, -7.4151e-01],\n",
            "         [-1.7753e-03, -1.4195e+00, -1.9788e-01, -7.9166e-01,  1.9158e+00,\n",
            "           6.4100e-02,  9.7136e-01, -3.4242e-01,  9.9716e-02, -7.4305e-01],\n",
            "         [ 2.0859e-01, -4.8338e-01, -3.4549e-01, -8.4903e-01,  1.9380e+00,\n",
            "           5.3472e-02,  9.7465e-01, -3.4192e-01,  1.0094e-01, -7.4224e-01],\n",
            "         [ 1.1094e+00, -1.5365e-01, -5.0012e-01, -8.8284e-01,  1.9594e+00,\n",
            "           4.2348e-02,  9.7715e-01, -3.4054e-01,  1.0285e-01, -7.4047e-01],\n",
            "         [ 1.8724e+00, -7.3332e-01, -6.5806e-01, -8.9154e-01,  1.9809e+00,\n",
            "           3.0625e-02,  9.8008e-01, -3.3967e-01,  1.0438e-01, -7.3922e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 21, 10])\n",
            "Query-torch.Size([1, 21, 5])\n",
            "Key-torch.Size([1, 21, 5])\n",
            "Value-+torch.Size([1, 21, 10])\n",
            "a_norm torch.Size([1, 21, 21])\n",
            "attention +torch.Size([1, 21, 10])\n",
            "beforeQuery-torch.Size([1, 21, 10])\n",
            "Query-torch.Size([1, 21, 5])\n",
            "Key-torch.Size([1, 21, 5])\n",
            "Value-+torch.Size([1, 21, 10])\n",
            "a_norm torch.Size([1, 21, 21])\n",
            "attention +torch.Size([1, 21, 10])\n",
            "beforeQuery-torch.Size([1, 21, 10])\n",
            "Query-torch.Size([1, 21, 5])\n",
            "Key-torch.Size([1, 21, 5])\n",
            "Value-+torch.Size([1, 21, 10])\n",
            "a_norm torch.Size([1, 21, 21])\n",
            "attention +torch.Size([1, 21, 10])\n",
            "shape after Multihead+torch.Size([1, 21, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 21, 10])\n",
            "End Of Encoder shapetorch.Size([1, 21, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 21, 10])\n",
            "Query-torch.Size([1, 21, 5])\n",
            "Key-torch.Size([1, 21, 5])\n",
            "Value-+torch.Size([1, 21, 10])\n",
            "a_norm torch.Size([1, 21, 21])\n",
            "attention +torch.Size([1, 21, 10])\n",
            "beforeQuery-torch.Size([1, 21, 10])\n",
            "Query-torch.Size([1, 21, 5])\n",
            "Key-torch.Size([1, 21, 5])\n",
            "Value-+torch.Size([1, 21, 10])\n",
            "a_norm torch.Size([1, 21, 21])\n",
            "attention +torch.Size([1, 21, 10])\n",
            "beforeQuery-torch.Size([1, 21, 10])\n",
            "Query-torch.Size([1, 21, 5])\n",
            "Key-torch.Size([1, 21, 5])\n",
            "Value-+torch.Size([1, 21, 10])\n",
            "a_norm torch.Size([1, 21, 21])\n",
            "attention +torch.Size([1, 21, 10])\n",
            "shape after Multihead+torch.Size([1, 21, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 21, 10])\n",
            "End Of Encoder shapetorch.Size([1, 21, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 21, 10])\n",
            "Query-torch.Size([1, 21, 5])\n",
            "Key-torch.Size([1, 21, 5])\n",
            "Value-+torch.Size([1, 21, 10])\n",
            "a_norm torch.Size([1, 21, 21])\n",
            "attention +torch.Size([1, 21, 10])\n",
            "beforeQuery-torch.Size([1, 21, 10])\n",
            "Query-torch.Size([1, 21, 5])\n",
            "Key-torch.Size([1, 21, 5])\n",
            "Value-+torch.Size([1, 21, 10])\n",
            "a_norm torch.Size([1, 21, 21])\n",
            "attention +torch.Size([1, 21, 10])\n",
            "beforeQuery-torch.Size([1, 21, 10])\n",
            "Query-torch.Size([1, 21, 5])\n",
            "Key-torch.Size([1, 21, 5])\n",
            "Value-+torch.Size([1, 21, 10])\n",
            "a_norm torch.Size([1, 21, 21])\n",
            "attention +torch.Size([1, 21, 10])\n",
            "shape after Multihead+torch.Size([1, 21, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 21, 10])\n",
            "End Of Encoder shapetorch.Size([1, 21, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 21, 5])\n",
            "Value-+torch.Size([1, 21, 10])\n",
            "a_norm torch.Size([1, 2, 21])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 21, 5])\n",
            "Value-+torch.Size([1, 21, 10])\n",
            "a_norm torch.Size([1, 2, 21])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 21, 5])\n",
            "Value-+torch.Size([1, 21, 10])\n",
            "a_norm torch.Size([1, 2, 21])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 21, 5])\n",
            "Value-+torch.Size([1, 21, 10])\n",
            "a_norm torch.Size([1, 2, 21])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 21, 5])\n",
            "Value-+torch.Size([1, 21, 10])\n",
            "a_norm torch.Size([1, 2, 21])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 21, 5])\n",
            "Value-+torch.Size([1, 21, 10])\n",
            "a_norm torch.Size([1, 2, 21])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 21, 5])\n",
            "Value-+torch.Size([1, 21, 10])\n",
            "a_norm torch.Size([1, 2, 21])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 21, 5])\n",
            "Value-+torch.Size([1, 21, 10])\n",
            "a_norm torch.Size([1, 2, 21])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 21, 5])\n",
            "Value-+torch.Size([1, 21, 10])\n",
            "a_norm torch.Size([1, 2, 21])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 9.0047e-01,  6.6880e-01, -4.8604e-01,  5.7915e-01,  8.6418e-01,\n",
            "           2.3434e-01,  1.5448e-02,  6.6951e-01,  8.6238e-01,  3.3166e-01],\n",
            "         [ 1.7419e+00,  2.0904e-01, -3.2823e-01,  5.6666e-01,  8.8935e-01,\n",
            "           2.3402e-01,  1.9501e-02,  6.6942e-01,  8.6295e-01,  3.3158e-01],\n",
            "         [ 1.8098e+00, -7.4759e-01, -1.7439e-01,  5.2949e-01,  9.1459e-01,\n",
            "           2.3306e-01,  2.3676e-02,  6.6917e-01,  8.6341e-01,  3.3134e-01],\n",
            "         [ 1.0416e+00, -1.3219e+00, -2.8416e-02,  4.6870e-01,  9.4004e-01,\n",
            "           2.3143e-01,  2.8185e-02,  6.6853e-01,  8.6358e-01,  3.3070e-01],\n",
            "         [ 1.4382e-01, -9.8688e-01,  1.0593e-01,  3.8617e-01,  9.6609e-01,\n",
            "           2.2910e-01,  3.3601e-02,  6.6684e-01,  8.6296e-01,  3.2896e-01],\n",
            "         [-5.8043e-02, -5.3148e-02,  2.2504e-01,  2.8492e-01,  9.9385e-01,\n",
            "           2.2591e-01,  4.1485e-02,  6.6234e-01,  8.6019e-01,  3.2424e-01],\n",
            "         [ 6.2217e-01,  6.1365e-01,  3.2520e-01,  1.7007e-01,  1.0263e+00,\n",
            "           2.2149e-01,  5.6074e-02,  6.5019e-01,  8.5159e-01,  3.1140e-01],\n",
            "         [ 1.5605e+00,  3.8098e-01,  4.0199e-01,  5.1561e-02,  1.0718e+00,\n",
            "           2.1480e-01,  8.8892e-02,  6.1731e-01,  8.2711e-01,  2.7651e-01],\n",
            "         [ 1.8981e+00, -5.9018e-01,  4.4829e-01, -4.8498e-02,  1.1527e+00,\n",
            "           2.0299e-01,  1.7126e-01,  5.2809e-01,  7.5949e-01,  1.8167e-01],\n",
            "         [ 1.3305e+00, -1.4881e+00,  4.5992e-01, -1.1651e-01,  1.2810e+00,\n",
            "           1.8458e-01,  3.1977e-01,  3.6369e-01,  6.3429e-01,  6.8173e-03],\n",
            "         [ 3.8603e-01, -1.5769e+00,  4.4166e-01, -1.6947e-01,  1.4315e+00,\n",
            "           1.6273e-01,  4.9951e-01,  1.6376e-01,  4.8189e-01, -2.0583e-01],\n",
            "         [-5.5102e-02, -9.3735e-01,  3.9071e-01, -1.9399e-01,  1.6157e+00,\n",
            "           1.3600e-01,  7.2624e-01, -8.9590e-02,  2.8858e-01, -4.7533e-01],\n",
            "         [ 4.1873e-01, -2.4111e-01,  3.2584e-01, -2.5384e-01,  1.7520e+00,\n",
            "           1.1468e-01,  8.8665e-01, -2.6757e-01,  1.5301e-01, -6.6458e-01],\n",
            "         [ 1.3790e+00, -2.2588e-01,  2.5410e-01, -3.6745e-01,  1.8138e+00,\n",
            "           1.0214e-01,  9.4346e-01, -3.2782e-01,  1.0764e-01, -7.2851e-01],\n",
            "         [ 1.9499e+00, -1.0025e+00,  1.6776e-01, -4.9695e-01,  1.8421e+00,\n",
            "           9.3195e-02,  9.5394e-01, -3.3543e-01,  1.0261e-01, -7.3638e-01],\n",
            "         [ 1.6097e+00, -1.9005e+00,  6.2225e-02, -6.1421e-01,  1.8668e+00,\n",
            "           8.4095e-02,  9.5960e-01, -3.3757e-01,  1.0177e-01, -7.3843e-01],\n",
            "         [ 6.7163e-01, -2.1008e+00, -6.0797e-02, -7.1286e-01,  1.8919e+00,\n",
            "           7.4330e-02,  9.6611e-01, -3.4071e-01,  1.0019e-01, -7.4151e-01],\n",
            "         [-1.7753e-03, -1.4195e+00, -1.9788e-01, -7.9166e-01,  1.9158e+00,\n",
            "           6.4100e-02,  9.7136e-01, -3.4242e-01,  9.9716e-02, -7.4305e-01],\n",
            "         [ 2.0859e-01, -4.8338e-01, -3.4549e-01, -8.4903e-01,  1.9380e+00,\n",
            "           5.3472e-02,  9.7465e-01, -3.4192e-01,  1.0094e-01, -7.4224e-01],\n",
            "         [ 1.1094e+00, -1.5365e-01, -5.0012e-01, -8.8284e-01,  1.9594e+00,\n",
            "           4.2348e-02,  9.7715e-01, -3.4054e-01,  1.0285e-01, -7.4047e-01],\n",
            "         [ 1.8724e+00, -7.3332e-01, -6.5806e-01, -8.9154e-01,  1.9809e+00,\n",
            "           3.0625e-02,  9.8008e-01, -3.3967e-01,  1.0438e-01, -7.3922e-01],\n",
            "         [ 1.7961e+00, -1.6894e+00, -8.1552e-01, -8.7441e-01,  2.0029e+00,\n",
            "           1.8232e-02,  9.8430e-01, -3.4028e-01,  1.0479e-01, -7.3954e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 22, 10])\n",
            "Query-torch.Size([1, 22, 5])\n",
            "Key-torch.Size([1, 22, 5])\n",
            "Value-+torch.Size([1, 22, 10])\n",
            "a_norm torch.Size([1, 22, 22])\n",
            "attention +torch.Size([1, 22, 10])\n",
            "beforeQuery-torch.Size([1, 22, 10])\n",
            "Query-torch.Size([1, 22, 5])\n",
            "Key-torch.Size([1, 22, 5])\n",
            "Value-+torch.Size([1, 22, 10])\n",
            "a_norm torch.Size([1, 22, 22])\n",
            "attention +torch.Size([1, 22, 10])\n",
            "beforeQuery-torch.Size([1, 22, 10])\n",
            "Query-torch.Size([1, 22, 5])\n",
            "Key-torch.Size([1, 22, 5])\n",
            "Value-+torch.Size([1, 22, 10])\n",
            "a_norm torch.Size([1, 22, 22])\n",
            "attention +torch.Size([1, 22, 10])\n",
            "shape after Multihead+torch.Size([1, 22, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 22, 10])\n",
            "End Of Encoder shapetorch.Size([1, 22, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 22, 10])\n",
            "Query-torch.Size([1, 22, 5])\n",
            "Key-torch.Size([1, 22, 5])\n",
            "Value-+torch.Size([1, 22, 10])\n",
            "a_norm torch.Size([1, 22, 22])\n",
            "attention +torch.Size([1, 22, 10])\n",
            "beforeQuery-torch.Size([1, 22, 10])\n",
            "Query-torch.Size([1, 22, 5])\n",
            "Key-torch.Size([1, 22, 5])\n",
            "Value-+torch.Size([1, 22, 10])\n",
            "a_norm torch.Size([1, 22, 22])\n",
            "attention +torch.Size([1, 22, 10])\n",
            "beforeQuery-torch.Size([1, 22, 10])\n",
            "Query-torch.Size([1, 22, 5])\n",
            "Key-torch.Size([1, 22, 5])\n",
            "Value-+torch.Size([1, 22, 10])\n",
            "a_norm torch.Size([1, 22, 22])\n",
            "attention +torch.Size([1, 22, 10])\n",
            "shape after Multihead+torch.Size([1, 22, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 22, 10])\n",
            "End Of Encoder shapetorch.Size([1, 22, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 22, 10])\n",
            "Query-torch.Size([1, 22, 5])\n",
            "Key-torch.Size([1, 22, 5])\n",
            "Value-+torch.Size([1, 22, 10])\n",
            "a_norm torch.Size([1, 22, 22])\n",
            "attention +torch.Size([1, 22, 10])\n",
            "beforeQuery-torch.Size([1, 22, 10])\n",
            "Query-torch.Size([1, 22, 5])\n",
            "Key-torch.Size([1, 22, 5])\n",
            "Value-+torch.Size([1, 22, 10])\n",
            "a_norm torch.Size([1, 22, 22])\n",
            "attention +torch.Size([1, 22, 10])\n",
            "beforeQuery-torch.Size([1, 22, 10])\n",
            "Query-torch.Size([1, 22, 5])\n",
            "Key-torch.Size([1, 22, 5])\n",
            "Value-+torch.Size([1, 22, 10])\n",
            "a_norm torch.Size([1, 22, 22])\n",
            "attention +torch.Size([1, 22, 10])\n",
            "shape after Multihead+torch.Size([1, 22, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 22, 10])\n",
            "End Of Encoder shapetorch.Size([1, 22, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 22, 5])\n",
            "Value-+torch.Size([1, 22, 10])\n",
            "a_norm torch.Size([1, 2, 22])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 22, 5])\n",
            "Value-+torch.Size([1, 22, 10])\n",
            "a_norm torch.Size([1, 2, 22])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 22, 5])\n",
            "Value-+torch.Size([1, 22, 10])\n",
            "a_norm torch.Size([1, 2, 22])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 22, 5])\n",
            "Value-+torch.Size([1, 22, 10])\n",
            "a_norm torch.Size([1, 2, 22])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 22, 5])\n",
            "Value-+torch.Size([1, 22, 10])\n",
            "a_norm torch.Size([1, 2, 22])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 22, 5])\n",
            "Value-+torch.Size([1, 22, 10])\n",
            "a_norm torch.Size([1, 2, 22])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 22, 5])\n",
            "Value-+torch.Size([1, 22, 10])\n",
            "a_norm torch.Size([1, 2, 22])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 22, 5])\n",
            "Value-+torch.Size([1, 22, 10])\n",
            "a_norm torch.Size([1, 2, 22])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 22, 5])\n",
            "Value-+torch.Size([1, 22, 10])\n",
            "a_norm torch.Size([1, 2, 22])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 9.0047e-01,  6.6880e-01, -4.8604e-01,  5.7915e-01,  8.6418e-01,\n",
            "           2.3434e-01,  1.5448e-02,  6.6951e-01,  8.6238e-01,  3.3166e-01],\n",
            "         [ 1.7419e+00,  2.0904e-01, -3.2823e-01,  5.6666e-01,  8.8935e-01,\n",
            "           2.3402e-01,  1.9501e-02,  6.6942e-01,  8.6295e-01,  3.3158e-01],\n",
            "         [ 1.8098e+00, -7.4759e-01, -1.7439e-01,  5.2949e-01,  9.1459e-01,\n",
            "           2.3306e-01,  2.3676e-02,  6.6917e-01,  8.6341e-01,  3.3134e-01],\n",
            "         [ 1.0416e+00, -1.3219e+00, -2.8416e-02,  4.6870e-01,  9.4004e-01,\n",
            "           2.3143e-01,  2.8185e-02,  6.6853e-01,  8.6358e-01,  3.3070e-01],\n",
            "         [ 1.4382e-01, -9.8688e-01,  1.0593e-01,  3.8617e-01,  9.6609e-01,\n",
            "           2.2910e-01,  3.3601e-02,  6.6684e-01,  8.6296e-01,  3.2896e-01],\n",
            "         [-5.8043e-02, -5.3148e-02,  2.2504e-01,  2.8492e-01,  9.9385e-01,\n",
            "           2.2591e-01,  4.1485e-02,  6.6234e-01,  8.6019e-01,  3.2424e-01],\n",
            "         [ 6.2217e-01,  6.1365e-01,  3.2520e-01,  1.7007e-01,  1.0263e+00,\n",
            "           2.2149e-01,  5.6074e-02,  6.5019e-01,  8.5159e-01,  3.1140e-01],\n",
            "         [ 1.5605e+00,  3.8098e-01,  4.0199e-01,  5.1561e-02,  1.0718e+00,\n",
            "           2.1480e-01,  8.8892e-02,  6.1731e-01,  8.2711e-01,  2.7651e-01],\n",
            "         [ 1.8981e+00, -5.9018e-01,  4.4829e-01, -4.8498e-02,  1.1527e+00,\n",
            "           2.0299e-01,  1.7126e-01,  5.2809e-01,  7.5949e-01,  1.8167e-01],\n",
            "         [ 1.3305e+00, -1.4881e+00,  4.5992e-01, -1.1651e-01,  1.2810e+00,\n",
            "           1.8458e-01,  3.1977e-01,  3.6369e-01,  6.3429e-01,  6.8173e-03],\n",
            "         [ 3.8603e-01, -1.5769e+00,  4.4166e-01, -1.6947e-01,  1.4315e+00,\n",
            "           1.6273e-01,  4.9951e-01,  1.6376e-01,  4.8189e-01, -2.0583e-01],\n",
            "         [-5.5102e-02, -9.3735e-01,  3.9071e-01, -1.9399e-01,  1.6157e+00,\n",
            "           1.3600e-01,  7.2624e-01, -8.9590e-02,  2.8858e-01, -4.7533e-01],\n",
            "         [ 4.1873e-01, -2.4111e-01,  3.2584e-01, -2.5384e-01,  1.7520e+00,\n",
            "           1.1468e-01,  8.8665e-01, -2.6757e-01,  1.5301e-01, -6.6458e-01],\n",
            "         [ 1.3790e+00, -2.2588e-01,  2.5410e-01, -3.6745e-01,  1.8138e+00,\n",
            "           1.0214e-01,  9.4346e-01, -3.2782e-01,  1.0764e-01, -7.2851e-01],\n",
            "         [ 1.9499e+00, -1.0025e+00,  1.6776e-01, -4.9695e-01,  1.8421e+00,\n",
            "           9.3195e-02,  9.5394e-01, -3.3543e-01,  1.0261e-01, -7.3638e-01],\n",
            "         [ 1.6097e+00, -1.9005e+00,  6.2225e-02, -6.1421e-01,  1.8668e+00,\n",
            "           8.4095e-02,  9.5960e-01, -3.3757e-01,  1.0177e-01, -7.3843e-01],\n",
            "         [ 6.7163e-01, -2.1008e+00, -6.0797e-02, -7.1286e-01,  1.8919e+00,\n",
            "           7.4330e-02,  9.6611e-01, -3.4071e-01,  1.0019e-01, -7.4151e-01],\n",
            "         [-1.7753e-03, -1.4195e+00, -1.9788e-01, -7.9166e-01,  1.9158e+00,\n",
            "           6.4100e-02,  9.7136e-01, -3.4242e-01,  9.9716e-02, -7.4305e-01],\n",
            "         [ 2.0859e-01, -4.8338e-01, -3.4549e-01, -8.4903e-01,  1.9380e+00,\n",
            "           5.3472e-02,  9.7465e-01, -3.4192e-01,  1.0094e-01, -7.4224e-01],\n",
            "         [ 1.1094e+00, -1.5365e-01, -5.0012e-01, -8.8284e-01,  1.9594e+00,\n",
            "           4.2348e-02,  9.7715e-01, -3.4054e-01,  1.0285e-01, -7.4047e-01],\n",
            "         [ 1.8724e+00, -7.3332e-01, -6.5806e-01, -8.9154e-01,  1.9809e+00,\n",
            "           3.0625e-02,  9.8008e-01, -3.3967e-01,  1.0438e-01, -7.3922e-01],\n",
            "         [ 1.7961e+00, -1.6894e+00, -8.1552e-01, -8.7441e-01,  2.0029e+00,\n",
            "           1.8232e-02,  9.8430e-01, -3.4028e-01,  1.0479e-01, -7.3954e-01],\n",
            "         [ 9.5063e-01, -2.1424e+00, -9.6841e-01, -8.3229e-01,  2.0251e+00,\n",
            "           5.2394e-03,  9.8912e-01, -3.4159e-01,  1.0468e-01, -7.4058e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 23, 10])\n",
            "Query-torch.Size([1, 23, 5])\n",
            "Key-torch.Size([1, 23, 5])\n",
            "Value-+torch.Size([1, 23, 10])\n",
            "a_norm torch.Size([1, 23, 23])\n",
            "attention +torch.Size([1, 23, 10])\n",
            "beforeQuery-torch.Size([1, 23, 10])\n",
            "Query-torch.Size([1, 23, 5])\n",
            "Key-torch.Size([1, 23, 5])\n",
            "Value-+torch.Size([1, 23, 10])\n",
            "a_norm torch.Size([1, 23, 23])\n",
            "attention +torch.Size([1, 23, 10])\n",
            "beforeQuery-torch.Size([1, 23, 10])\n",
            "Query-torch.Size([1, 23, 5])\n",
            "Key-torch.Size([1, 23, 5])\n",
            "Value-+torch.Size([1, 23, 10])\n",
            "a_norm torch.Size([1, 23, 23])\n",
            "attention +torch.Size([1, 23, 10])\n",
            "shape after Multihead+torch.Size([1, 23, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 23, 10])\n",
            "End Of Encoder shapetorch.Size([1, 23, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 23, 10])\n",
            "Query-torch.Size([1, 23, 5])\n",
            "Key-torch.Size([1, 23, 5])\n",
            "Value-+torch.Size([1, 23, 10])\n",
            "a_norm torch.Size([1, 23, 23])\n",
            "attention +torch.Size([1, 23, 10])\n",
            "beforeQuery-torch.Size([1, 23, 10])\n",
            "Query-torch.Size([1, 23, 5])\n",
            "Key-torch.Size([1, 23, 5])\n",
            "Value-+torch.Size([1, 23, 10])\n",
            "a_norm torch.Size([1, 23, 23])\n",
            "attention +torch.Size([1, 23, 10])\n",
            "beforeQuery-torch.Size([1, 23, 10])\n",
            "Query-torch.Size([1, 23, 5])\n",
            "Key-torch.Size([1, 23, 5])\n",
            "Value-+torch.Size([1, 23, 10])\n",
            "a_norm torch.Size([1, 23, 23])\n",
            "attention +torch.Size([1, 23, 10])\n",
            "shape after Multihead+torch.Size([1, 23, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 23, 10])\n",
            "End Of Encoder shapetorch.Size([1, 23, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 23, 10])\n",
            "Query-torch.Size([1, 23, 5])\n",
            "Key-torch.Size([1, 23, 5])\n",
            "Value-+torch.Size([1, 23, 10])\n",
            "a_norm torch.Size([1, 23, 23])\n",
            "attention +torch.Size([1, 23, 10])\n",
            "beforeQuery-torch.Size([1, 23, 10])\n",
            "Query-torch.Size([1, 23, 5])\n",
            "Key-torch.Size([1, 23, 5])\n",
            "Value-+torch.Size([1, 23, 10])\n",
            "a_norm torch.Size([1, 23, 23])\n",
            "attention +torch.Size([1, 23, 10])\n",
            "beforeQuery-torch.Size([1, 23, 10])\n",
            "Query-torch.Size([1, 23, 5])\n",
            "Key-torch.Size([1, 23, 5])\n",
            "Value-+torch.Size([1, 23, 10])\n",
            "a_norm torch.Size([1, 23, 23])\n",
            "attention +torch.Size([1, 23, 10])\n",
            "shape after Multihead+torch.Size([1, 23, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 23, 10])\n",
            "End Of Encoder shapetorch.Size([1, 23, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 23, 5])\n",
            "Value-+torch.Size([1, 23, 10])\n",
            "a_norm torch.Size([1, 2, 23])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 23, 5])\n",
            "Value-+torch.Size([1, 23, 10])\n",
            "a_norm torch.Size([1, 2, 23])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 23, 5])\n",
            "Value-+torch.Size([1, 23, 10])\n",
            "a_norm torch.Size([1, 2, 23])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 23, 5])\n",
            "Value-+torch.Size([1, 23, 10])\n",
            "a_norm torch.Size([1, 2, 23])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 23, 5])\n",
            "Value-+torch.Size([1, 23, 10])\n",
            "a_norm torch.Size([1, 2, 23])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 23, 5])\n",
            "Value-+torch.Size([1, 23, 10])\n",
            "a_norm torch.Size([1, 2, 23])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 23, 5])\n",
            "Value-+torch.Size([1, 23, 10])\n",
            "a_norm torch.Size([1, 2, 23])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 23, 5])\n",
            "Value-+torch.Size([1, 23, 10])\n",
            "a_norm torch.Size([1, 2, 23])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 23, 5])\n",
            "Value-+torch.Size([1, 23, 10])\n",
            "a_norm torch.Size([1, 2, 23])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 9.0047e-01,  6.6880e-01, -4.8604e-01,  5.7915e-01,  8.6418e-01,\n",
            "           2.3434e-01,  1.5448e-02,  6.6951e-01,  8.6238e-01,  3.3166e-01],\n",
            "         [ 1.7419e+00,  2.0904e-01, -3.2823e-01,  5.6666e-01,  8.8935e-01,\n",
            "           2.3402e-01,  1.9501e-02,  6.6942e-01,  8.6295e-01,  3.3158e-01],\n",
            "         [ 1.8098e+00, -7.4759e-01, -1.7439e-01,  5.2949e-01,  9.1459e-01,\n",
            "           2.3306e-01,  2.3676e-02,  6.6917e-01,  8.6341e-01,  3.3134e-01],\n",
            "         [ 1.0416e+00, -1.3219e+00, -2.8416e-02,  4.6870e-01,  9.4004e-01,\n",
            "           2.3143e-01,  2.8185e-02,  6.6853e-01,  8.6358e-01,  3.3070e-01],\n",
            "         [ 1.4382e-01, -9.8688e-01,  1.0593e-01,  3.8617e-01,  9.6609e-01,\n",
            "           2.2910e-01,  3.3601e-02,  6.6684e-01,  8.6296e-01,  3.2896e-01],\n",
            "         [-5.8043e-02, -5.3148e-02,  2.2504e-01,  2.8492e-01,  9.9385e-01,\n",
            "           2.2591e-01,  4.1485e-02,  6.6234e-01,  8.6019e-01,  3.2424e-01],\n",
            "         [ 6.2217e-01,  6.1365e-01,  3.2520e-01,  1.7007e-01,  1.0263e+00,\n",
            "           2.2149e-01,  5.6074e-02,  6.5019e-01,  8.5159e-01,  3.1140e-01],\n",
            "         [ 1.5605e+00,  3.8098e-01,  4.0199e-01,  5.1561e-02,  1.0718e+00,\n",
            "           2.1480e-01,  8.8892e-02,  6.1731e-01,  8.2711e-01,  2.7651e-01],\n",
            "         [ 1.8981e+00, -5.9018e-01,  4.4829e-01, -4.8498e-02,  1.1527e+00,\n",
            "           2.0299e-01,  1.7126e-01,  5.2809e-01,  7.5949e-01,  1.8167e-01],\n",
            "         [ 1.3305e+00, -1.4881e+00,  4.5992e-01, -1.1651e-01,  1.2810e+00,\n",
            "           1.8458e-01,  3.1977e-01,  3.6369e-01,  6.3429e-01,  6.8173e-03],\n",
            "         [ 3.8603e-01, -1.5769e+00,  4.4166e-01, -1.6947e-01,  1.4315e+00,\n",
            "           1.6273e-01,  4.9951e-01,  1.6376e-01,  4.8189e-01, -2.0583e-01],\n",
            "         [-5.5102e-02, -9.3735e-01,  3.9071e-01, -1.9399e-01,  1.6157e+00,\n",
            "           1.3600e-01,  7.2624e-01, -8.9590e-02,  2.8858e-01, -4.7533e-01],\n",
            "         [ 4.1873e-01, -2.4111e-01,  3.2584e-01, -2.5384e-01,  1.7520e+00,\n",
            "           1.1468e-01,  8.8665e-01, -2.6757e-01,  1.5301e-01, -6.6458e-01],\n",
            "         [ 1.3790e+00, -2.2588e-01,  2.5410e-01, -3.6745e-01,  1.8138e+00,\n",
            "           1.0214e-01,  9.4346e-01, -3.2782e-01,  1.0764e-01, -7.2851e-01],\n",
            "         [ 1.9499e+00, -1.0025e+00,  1.6776e-01, -4.9695e-01,  1.8421e+00,\n",
            "           9.3195e-02,  9.5394e-01, -3.3543e-01,  1.0261e-01, -7.3638e-01],\n",
            "         [ 1.6097e+00, -1.9005e+00,  6.2225e-02, -6.1421e-01,  1.8668e+00,\n",
            "           8.4095e-02,  9.5960e-01, -3.3757e-01,  1.0177e-01, -7.3843e-01],\n",
            "         [ 6.7163e-01, -2.1008e+00, -6.0797e-02, -7.1286e-01,  1.8919e+00,\n",
            "           7.4330e-02,  9.6611e-01, -3.4071e-01,  1.0019e-01, -7.4151e-01],\n",
            "         [-1.7753e-03, -1.4195e+00, -1.9788e-01, -7.9166e-01,  1.9158e+00,\n",
            "           6.4100e-02,  9.7136e-01, -3.4242e-01,  9.9716e-02, -7.4305e-01],\n",
            "         [ 2.0859e-01, -4.8338e-01, -3.4549e-01, -8.4903e-01,  1.9380e+00,\n",
            "           5.3472e-02,  9.7465e-01, -3.4192e-01,  1.0094e-01, -7.4224e-01],\n",
            "         [ 1.1094e+00, -1.5365e-01, -5.0012e-01, -8.8284e-01,  1.9594e+00,\n",
            "           4.2348e-02,  9.7715e-01, -3.4054e-01,  1.0285e-01, -7.4047e-01],\n",
            "         [ 1.8724e+00, -7.3332e-01, -6.5806e-01, -8.9154e-01,  1.9809e+00,\n",
            "           3.0625e-02,  9.8008e-01, -3.3967e-01,  1.0438e-01, -7.3922e-01],\n",
            "         [ 1.7961e+00, -1.6894e+00, -8.1552e-01, -8.7441e-01,  2.0029e+00,\n",
            "           1.8232e-02,  9.8430e-01, -3.4028e-01,  1.0479e-01, -7.3954e-01],\n",
            "         [ 9.5063e-01, -2.1424e+00, -9.6841e-01, -8.3229e-01,  2.0251e+00,\n",
            "           5.2394e-03,  9.8912e-01, -3.4159e-01,  1.0468e-01, -7.4058e-01],\n",
            "         [ 1.1328e-01, -1.6755e+00, -1.1127e+00, -7.6694e-01,  2.0464e+00,\n",
            "          -8.2362e-03,  9.9334e-01, -3.4224e-01,  1.0509e-01, -7.4089e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 24, 10])\n",
            "Query-torch.Size([1, 24, 5])\n",
            "Key-torch.Size([1, 24, 5])\n",
            "Value-+torch.Size([1, 24, 10])\n",
            "a_norm torch.Size([1, 24, 24])\n",
            "attention +torch.Size([1, 24, 10])\n",
            "beforeQuery-torch.Size([1, 24, 10])\n",
            "Query-torch.Size([1, 24, 5])\n",
            "Key-torch.Size([1, 24, 5])\n",
            "Value-+torch.Size([1, 24, 10])\n",
            "a_norm torch.Size([1, 24, 24])\n",
            "attention +torch.Size([1, 24, 10])\n",
            "beforeQuery-torch.Size([1, 24, 10])\n",
            "Query-torch.Size([1, 24, 5])\n",
            "Key-torch.Size([1, 24, 5])\n",
            "Value-+torch.Size([1, 24, 10])\n",
            "a_norm torch.Size([1, 24, 24])\n",
            "attention +torch.Size([1, 24, 10])\n",
            "shape after Multihead+torch.Size([1, 24, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 24, 10])\n",
            "End Of Encoder shapetorch.Size([1, 24, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 24, 10])\n",
            "Query-torch.Size([1, 24, 5])\n",
            "Key-torch.Size([1, 24, 5])\n",
            "Value-+torch.Size([1, 24, 10])\n",
            "a_norm torch.Size([1, 24, 24])\n",
            "attention +torch.Size([1, 24, 10])\n",
            "beforeQuery-torch.Size([1, 24, 10])\n",
            "Query-torch.Size([1, 24, 5])\n",
            "Key-torch.Size([1, 24, 5])\n",
            "Value-+torch.Size([1, 24, 10])\n",
            "a_norm torch.Size([1, 24, 24])\n",
            "attention +torch.Size([1, 24, 10])\n",
            "beforeQuery-torch.Size([1, 24, 10])\n",
            "Query-torch.Size([1, 24, 5])\n",
            "Key-torch.Size([1, 24, 5])\n",
            "Value-+torch.Size([1, 24, 10])\n",
            "a_norm torch.Size([1, 24, 24])\n",
            "attention +torch.Size([1, 24, 10])\n",
            "shape after Multihead+torch.Size([1, 24, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 24, 10])\n",
            "End Of Encoder shapetorch.Size([1, 24, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 24, 10])\n",
            "Query-torch.Size([1, 24, 5])\n",
            "Key-torch.Size([1, 24, 5])\n",
            "Value-+torch.Size([1, 24, 10])\n",
            "a_norm torch.Size([1, 24, 24])\n",
            "attention +torch.Size([1, 24, 10])\n",
            "beforeQuery-torch.Size([1, 24, 10])\n",
            "Query-torch.Size([1, 24, 5])\n",
            "Key-torch.Size([1, 24, 5])\n",
            "Value-+torch.Size([1, 24, 10])\n",
            "a_norm torch.Size([1, 24, 24])\n",
            "attention +torch.Size([1, 24, 10])\n",
            "beforeQuery-torch.Size([1, 24, 10])\n",
            "Query-torch.Size([1, 24, 5])\n",
            "Key-torch.Size([1, 24, 5])\n",
            "Value-+torch.Size([1, 24, 10])\n",
            "a_norm torch.Size([1, 24, 24])\n",
            "attention +torch.Size([1, 24, 10])\n",
            "shape after Multihead+torch.Size([1, 24, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 24, 10])\n",
            "End Of Encoder shapetorch.Size([1, 24, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 24, 5])\n",
            "Value-+torch.Size([1, 24, 10])\n",
            "a_norm torch.Size([1, 2, 24])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 24, 5])\n",
            "Value-+torch.Size([1, 24, 10])\n",
            "a_norm torch.Size([1, 2, 24])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 24, 5])\n",
            "Value-+torch.Size([1, 24, 10])\n",
            "a_norm torch.Size([1, 2, 24])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 24, 5])\n",
            "Value-+torch.Size([1, 24, 10])\n",
            "a_norm torch.Size([1, 2, 24])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 24, 5])\n",
            "Value-+torch.Size([1, 24, 10])\n",
            "a_norm torch.Size([1, 2, 24])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 24, 5])\n",
            "Value-+torch.Size([1, 24, 10])\n",
            "a_norm torch.Size([1, 2, 24])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 24, 5])\n",
            "Value-+torch.Size([1, 24, 10])\n",
            "a_norm torch.Size([1, 2, 24])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 24, 5])\n",
            "Value-+torch.Size([1, 24, 10])\n",
            "a_norm torch.Size([1, 2, 24])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 24, 5])\n",
            "Value-+torch.Size([1, 24, 10])\n",
            "a_norm torch.Size([1, 2, 24])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 9.0047e-01,  6.6880e-01, -4.8604e-01,  5.7915e-01,  8.6418e-01,\n",
            "           2.3434e-01,  1.5448e-02,  6.6951e-01,  8.6238e-01,  3.3166e-01],\n",
            "         [ 1.7419e+00,  2.0904e-01, -3.2823e-01,  5.6666e-01,  8.8935e-01,\n",
            "           2.3402e-01,  1.9501e-02,  6.6942e-01,  8.6295e-01,  3.3158e-01],\n",
            "         [ 1.8098e+00, -7.4759e-01, -1.7439e-01,  5.2949e-01,  9.1459e-01,\n",
            "           2.3306e-01,  2.3676e-02,  6.6917e-01,  8.6341e-01,  3.3134e-01],\n",
            "         [ 1.0416e+00, -1.3219e+00, -2.8416e-02,  4.6870e-01,  9.4004e-01,\n",
            "           2.3143e-01,  2.8185e-02,  6.6853e-01,  8.6358e-01,  3.3070e-01],\n",
            "         [ 1.4382e-01, -9.8688e-01,  1.0593e-01,  3.8617e-01,  9.6609e-01,\n",
            "           2.2910e-01,  3.3601e-02,  6.6684e-01,  8.6296e-01,  3.2896e-01],\n",
            "         [-5.8043e-02, -5.3148e-02,  2.2504e-01,  2.8492e-01,  9.9385e-01,\n",
            "           2.2591e-01,  4.1485e-02,  6.6234e-01,  8.6019e-01,  3.2424e-01],\n",
            "         [ 6.2217e-01,  6.1365e-01,  3.2520e-01,  1.7007e-01,  1.0263e+00,\n",
            "           2.2149e-01,  5.6074e-02,  6.5019e-01,  8.5159e-01,  3.1140e-01],\n",
            "         [ 1.5605e+00,  3.8098e-01,  4.0199e-01,  5.1561e-02,  1.0718e+00,\n",
            "           2.1480e-01,  8.8892e-02,  6.1731e-01,  8.2711e-01,  2.7651e-01],\n",
            "         [ 1.8981e+00, -5.9018e-01,  4.4829e-01, -4.8498e-02,  1.1527e+00,\n",
            "           2.0299e-01,  1.7126e-01,  5.2809e-01,  7.5949e-01,  1.8167e-01],\n",
            "         [ 1.3305e+00, -1.4881e+00,  4.5992e-01, -1.1651e-01,  1.2810e+00,\n",
            "           1.8458e-01,  3.1977e-01,  3.6369e-01,  6.3429e-01,  6.8173e-03],\n",
            "         [ 3.8603e-01, -1.5769e+00,  4.4166e-01, -1.6947e-01,  1.4315e+00,\n",
            "           1.6273e-01,  4.9951e-01,  1.6376e-01,  4.8189e-01, -2.0583e-01],\n",
            "         [-5.5102e-02, -9.3735e-01,  3.9071e-01, -1.9399e-01,  1.6157e+00,\n",
            "           1.3600e-01,  7.2624e-01, -8.9590e-02,  2.8858e-01, -4.7533e-01],\n",
            "         [ 4.1873e-01, -2.4111e-01,  3.2584e-01, -2.5384e-01,  1.7520e+00,\n",
            "           1.1468e-01,  8.8665e-01, -2.6757e-01,  1.5301e-01, -6.6458e-01],\n",
            "         [ 1.3790e+00, -2.2588e-01,  2.5410e-01, -3.6745e-01,  1.8138e+00,\n",
            "           1.0214e-01,  9.4346e-01, -3.2782e-01,  1.0764e-01, -7.2851e-01],\n",
            "         [ 1.9499e+00, -1.0025e+00,  1.6776e-01, -4.9695e-01,  1.8421e+00,\n",
            "           9.3195e-02,  9.5394e-01, -3.3543e-01,  1.0261e-01, -7.3638e-01],\n",
            "         [ 1.6097e+00, -1.9005e+00,  6.2225e-02, -6.1421e-01,  1.8668e+00,\n",
            "           8.4095e-02,  9.5960e-01, -3.3757e-01,  1.0177e-01, -7.3843e-01],\n",
            "         [ 6.7163e-01, -2.1008e+00, -6.0797e-02, -7.1286e-01,  1.8919e+00,\n",
            "           7.4330e-02,  9.6611e-01, -3.4071e-01,  1.0019e-01, -7.4151e-01],\n",
            "         [-1.7753e-03, -1.4195e+00, -1.9788e-01, -7.9166e-01,  1.9158e+00,\n",
            "           6.4100e-02,  9.7136e-01, -3.4242e-01,  9.9716e-02, -7.4305e-01],\n",
            "         [ 2.0859e-01, -4.8338e-01, -3.4549e-01, -8.4903e-01,  1.9380e+00,\n",
            "           5.3472e-02,  9.7465e-01, -3.4192e-01,  1.0094e-01, -7.4224e-01],\n",
            "         [ 1.1094e+00, -1.5365e-01, -5.0012e-01, -8.8284e-01,  1.9594e+00,\n",
            "           4.2348e-02,  9.7715e-01, -3.4054e-01,  1.0285e-01, -7.4047e-01],\n",
            "         [ 1.8724e+00, -7.3332e-01, -6.5806e-01, -8.9154e-01,  1.9809e+00,\n",
            "           3.0625e-02,  9.8008e-01, -3.3967e-01,  1.0438e-01, -7.3922e-01],\n",
            "         [ 1.7961e+00, -1.6894e+00, -8.1552e-01, -8.7441e-01,  2.0029e+00,\n",
            "           1.8232e-02,  9.8430e-01, -3.4028e-01,  1.0479e-01, -7.3954e-01],\n",
            "         [ 9.5063e-01, -2.1424e+00, -9.6841e-01, -8.3229e-01,  2.0251e+00,\n",
            "           5.2394e-03,  9.8912e-01, -3.4159e-01,  1.0468e-01, -7.4058e-01],\n",
            "         [ 1.1328e-01, -1.6755e+00, -1.1127e+00, -7.6694e-01,  2.0464e+00,\n",
            "          -8.2362e-03,  9.9334e-01, -3.4224e-01,  1.0509e-01, -7.4089e-01],\n",
            "         [ 5.3866e-02, -7.1769e-01, -1.2448e+00, -6.8030e-01,  2.0667e+00,\n",
            "          -2.2140e-02,  9.9646e-01, -3.4165e-01,  1.0646e-01, -7.3988e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 25, 10])\n",
            "Query-torch.Size([1, 25, 5])\n",
            "Key-torch.Size([1, 25, 5])\n",
            "Value-+torch.Size([1, 25, 10])\n",
            "a_norm torch.Size([1, 25, 25])\n",
            "attention +torch.Size([1, 25, 10])\n",
            "beforeQuery-torch.Size([1, 25, 10])\n",
            "Query-torch.Size([1, 25, 5])\n",
            "Key-torch.Size([1, 25, 5])\n",
            "Value-+torch.Size([1, 25, 10])\n",
            "a_norm torch.Size([1, 25, 25])\n",
            "attention +torch.Size([1, 25, 10])\n",
            "beforeQuery-torch.Size([1, 25, 10])\n",
            "Query-torch.Size([1, 25, 5])\n",
            "Key-torch.Size([1, 25, 5])\n",
            "Value-+torch.Size([1, 25, 10])\n",
            "a_norm torch.Size([1, 25, 25])\n",
            "attention +torch.Size([1, 25, 10])\n",
            "shape after Multihead+torch.Size([1, 25, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 25, 10])\n",
            "End Of Encoder shapetorch.Size([1, 25, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 25, 10])\n",
            "Query-torch.Size([1, 25, 5])\n",
            "Key-torch.Size([1, 25, 5])\n",
            "Value-+torch.Size([1, 25, 10])\n",
            "a_norm torch.Size([1, 25, 25])\n",
            "attention +torch.Size([1, 25, 10])\n",
            "beforeQuery-torch.Size([1, 25, 10])\n",
            "Query-torch.Size([1, 25, 5])\n",
            "Key-torch.Size([1, 25, 5])\n",
            "Value-+torch.Size([1, 25, 10])\n",
            "a_norm torch.Size([1, 25, 25])\n",
            "attention +torch.Size([1, 25, 10])\n",
            "beforeQuery-torch.Size([1, 25, 10])\n",
            "Query-torch.Size([1, 25, 5])\n",
            "Key-torch.Size([1, 25, 5])\n",
            "Value-+torch.Size([1, 25, 10])\n",
            "a_norm torch.Size([1, 25, 25])\n",
            "attention +torch.Size([1, 25, 10])\n",
            "shape after Multihead+torch.Size([1, 25, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 25, 10])\n",
            "End Of Encoder shapetorch.Size([1, 25, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 25, 10])\n",
            "Query-torch.Size([1, 25, 5])\n",
            "Key-torch.Size([1, 25, 5])\n",
            "Value-+torch.Size([1, 25, 10])\n",
            "a_norm torch.Size([1, 25, 25])\n",
            "attention +torch.Size([1, 25, 10])\n",
            "beforeQuery-torch.Size([1, 25, 10])\n",
            "Query-torch.Size([1, 25, 5])\n",
            "Key-torch.Size([1, 25, 5])\n",
            "Value-+torch.Size([1, 25, 10])\n",
            "a_norm torch.Size([1, 25, 25])\n",
            "attention +torch.Size([1, 25, 10])\n",
            "beforeQuery-torch.Size([1, 25, 10])\n",
            "Query-torch.Size([1, 25, 5])\n",
            "Key-torch.Size([1, 25, 5])\n",
            "Value-+torch.Size([1, 25, 10])\n",
            "a_norm torch.Size([1, 25, 25])\n",
            "attention +torch.Size([1, 25, 10])\n",
            "shape after Multihead+torch.Size([1, 25, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 25, 10])\n",
            "End Of Encoder shapetorch.Size([1, 25, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 25, 5])\n",
            "Value-+torch.Size([1, 25, 10])\n",
            "a_norm torch.Size([1, 2, 25])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 25, 5])\n",
            "Value-+torch.Size([1, 25, 10])\n",
            "a_norm torch.Size([1, 2, 25])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 25, 5])\n",
            "Value-+torch.Size([1, 25, 10])\n",
            "a_norm torch.Size([1, 2, 25])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 25, 5])\n",
            "Value-+torch.Size([1, 25, 10])\n",
            "a_norm torch.Size([1, 2, 25])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 25, 5])\n",
            "Value-+torch.Size([1, 25, 10])\n",
            "a_norm torch.Size([1, 2, 25])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 25, 5])\n",
            "Value-+torch.Size([1, 25, 10])\n",
            "a_norm torch.Size([1, 2, 25])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 25, 5])\n",
            "Value-+torch.Size([1, 25, 10])\n",
            "a_norm torch.Size([1, 2, 25])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 25, 5])\n",
            "Value-+torch.Size([1, 25, 10])\n",
            "a_norm torch.Size([1, 2, 25])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 25, 5])\n",
            "Value-+torch.Size([1, 25, 10])\n",
            "a_norm torch.Size([1, 2, 25])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 9.0047e-01,  6.6880e-01, -4.8604e-01,  5.7915e-01,  8.6418e-01,\n",
            "           2.3434e-01,  1.5448e-02,  6.6951e-01,  8.6238e-01,  3.3166e-01],\n",
            "         [ 1.7419e+00,  2.0904e-01, -3.2823e-01,  5.6666e-01,  8.8935e-01,\n",
            "           2.3402e-01,  1.9501e-02,  6.6942e-01,  8.6295e-01,  3.3158e-01],\n",
            "         [ 1.8098e+00, -7.4759e-01, -1.7439e-01,  5.2949e-01,  9.1459e-01,\n",
            "           2.3306e-01,  2.3676e-02,  6.6917e-01,  8.6341e-01,  3.3134e-01],\n",
            "         [ 1.0416e+00, -1.3219e+00, -2.8416e-02,  4.6870e-01,  9.4004e-01,\n",
            "           2.3143e-01,  2.8185e-02,  6.6853e-01,  8.6358e-01,  3.3070e-01],\n",
            "         [ 1.4382e-01, -9.8688e-01,  1.0593e-01,  3.8617e-01,  9.6609e-01,\n",
            "           2.2910e-01,  3.3601e-02,  6.6684e-01,  8.6296e-01,  3.2896e-01],\n",
            "         [-5.8043e-02, -5.3148e-02,  2.2504e-01,  2.8492e-01,  9.9385e-01,\n",
            "           2.2591e-01,  4.1485e-02,  6.6234e-01,  8.6019e-01,  3.2424e-01],\n",
            "         [ 6.2217e-01,  6.1365e-01,  3.2520e-01,  1.7007e-01,  1.0263e+00,\n",
            "           2.2149e-01,  5.6074e-02,  6.5019e-01,  8.5159e-01,  3.1140e-01],\n",
            "         [ 1.5605e+00,  3.8098e-01,  4.0199e-01,  5.1561e-02,  1.0718e+00,\n",
            "           2.1480e-01,  8.8892e-02,  6.1731e-01,  8.2711e-01,  2.7651e-01],\n",
            "         [ 1.8981e+00, -5.9018e-01,  4.4829e-01, -4.8498e-02,  1.1527e+00,\n",
            "           2.0299e-01,  1.7126e-01,  5.2809e-01,  7.5949e-01,  1.8167e-01],\n",
            "         [ 1.3305e+00, -1.4881e+00,  4.5992e-01, -1.1651e-01,  1.2810e+00,\n",
            "           1.8458e-01,  3.1977e-01,  3.6369e-01,  6.3429e-01,  6.8173e-03],\n",
            "         [ 3.8603e-01, -1.5769e+00,  4.4166e-01, -1.6947e-01,  1.4315e+00,\n",
            "           1.6273e-01,  4.9951e-01,  1.6376e-01,  4.8189e-01, -2.0583e-01],\n",
            "         [-5.5102e-02, -9.3735e-01,  3.9071e-01, -1.9399e-01,  1.6157e+00,\n",
            "           1.3600e-01,  7.2624e-01, -8.9590e-02,  2.8858e-01, -4.7533e-01],\n",
            "         [ 4.1873e-01, -2.4111e-01,  3.2584e-01, -2.5384e-01,  1.7520e+00,\n",
            "           1.1468e-01,  8.8665e-01, -2.6757e-01,  1.5301e-01, -6.6458e-01],\n",
            "         [ 1.3790e+00, -2.2588e-01,  2.5410e-01, -3.6745e-01,  1.8138e+00,\n",
            "           1.0214e-01,  9.4346e-01, -3.2782e-01,  1.0764e-01, -7.2851e-01],\n",
            "         [ 1.9499e+00, -1.0025e+00,  1.6776e-01, -4.9695e-01,  1.8421e+00,\n",
            "           9.3195e-02,  9.5394e-01, -3.3543e-01,  1.0261e-01, -7.3638e-01],\n",
            "         [ 1.6097e+00, -1.9005e+00,  6.2225e-02, -6.1421e-01,  1.8668e+00,\n",
            "           8.4095e-02,  9.5960e-01, -3.3757e-01,  1.0177e-01, -7.3843e-01],\n",
            "         [ 6.7163e-01, -2.1008e+00, -6.0797e-02, -7.1286e-01,  1.8919e+00,\n",
            "           7.4330e-02,  9.6611e-01, -3.4071e-01,  1.0019e-01, -7.4151e-01],\n",
            "         [-1.7753e-03, -1.4195e+00, -1.9788e-01, -7.9166e-01,  1.9158e+00,\n",
            "           6.4100e-02,  9.7136e-01, -3.4242e-01,  9.9716e-02, -7.4305e-01],\n",
            "         [ 2.0859e-01, -4.8338e-01, -3.4549e-01, -8.4903e-01,  1.9380e+00,\n",
            "           5.3472e-02,  9.7465e-01, -3.4192e-01,  1.0094e-01, -7.4224e-01],\n",
            "         [ 1.1094e+00, -1.5365e-01, -5.0012e-01, -8.8284e-01,  1.9594e+00,\n",
            "           4.2348e-02,  9.7715e-01, -3.4054e-01,  1.0285e-01, -7.4047e-01],\n",
            "         [ 1.8724e+00, -7.3332e-01, -6.5806e-01, -8.9154e-01,  1.9809e+00,\n",
            "           3.0625e-02,  9.8008e-01, -3.3967e-01,  1.0438e-01, -7.3922e-01],\n",
            "         [ 1.7961e+00, -1.6894e+00, -8.1552e-01, -8.7441e-01,  2.0029e+00,\n",
            "           1.8232e-02,  9.8430e-01, -3.4028e-01,  1.0479e-01, -7.3954e-01],\n",
            "         [ 9.5063e-01, -2.1424e+00, -9.6841e-01, -8.3229e-01,  2.0251e+00,\n",
            "           5.2394e-03,  9.8912e-01, -3.4159e-01,  1.0468e-01, -7.4058e-01],\n",
            "         [ 1.1328e-01, -1.6755e+00, -1.1127e+00, -7.6694e-01,  2.0464e+00,\n",
            "          -8.2362e-03,  9.9334e-01, -3.4224e-01,  1.0509e-01, -7.4089e-01],\n",
            "         [ 5.3866e-02, -7.1769e-01, -1.2448e+00, -6.8030e-01,  2.0667e+00,\n",
            "          -2.2140e-02,  9.9646e-01, -3.4165e-01,  1.0646e-01, -7.3988e-01],\n",
            "         [ 8.2701e-01, -1.4956e-01, -1.3613e+00, -5.7411e-01,  2.0863e+00,\n",
            "          -3.6531e-02,  9.9921e-01, -3.4066e-01,  1.0815e-01, -7.3842e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 26, 10])\n",
            "Query-torch.Size([1, 26, 5])\n",
            "Key-torch.Size([1, 26, 5])\n",
            "Value-+torch.Size([1, 26, 10])\n",
            "a_norm torch.Size([1, 26, 26])\n",
            "attention +torch.Size([1, 26, 10])\n",
            "beforeQuery-torch.Size([1, 26, 10])\n",
            "Query-torch.Size([1, 26, 5])\n",
            "Key-torch.Size([1, 26, 5])\n",
            "Value-+torch.Size([1, 26, 10])\n",
            "a_norm torch.Size([1, 26, 26])\n",
            "attention +torch.Size([1, 26, 10])\n",
            "beforeQuery-torch.Size([1, 26, 10])\n",
            "Query-torch.Size([1, 26, 5])\n",
            "Key-torch.Size([1, 26, 5])\n",
            "Value-+torch.Size([1, 26, 10])\n",
            "a_norm torch.Size([1, 26, 26])\n",
            "attention +torch.Size([1, 26, 10])\n",
            "shape after Multihead+torch.Size([1, 26, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 26, 10])\n",
            "End Of Encoder shapetorch.Size([1, 26, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 26, 10])\n",
            "Query-torch.Size([1, 26, 5])\n",
            "Key-torch.Size([1, 26, 5])\n",
            "Value-+torch.Size([1, 26, 10])\n",
            "a_norm torch.Size([1, 26, 26])\n",
            "attention +torch.Size([1, 26, 10])\n",
            "beforeQuery-torch.Size([1, 26, 10])\n",
            "Query-torch.Size([1, 26, 5])\n",
            "Key-torch.Size([1, 26, 5])\n",
            "Value-+torch.Size([1, 26, 10])\n",
            "a_norm torch.Size([1, 26, 26])\n",
            "attention +torch.Size([1, 26, 10])\n",
            "beforeQuery-torch.Size([1, 26, 10])\n",
            "Query-torch.Size([1, 26, 5])\n",
            "Key-torch.Size([1, 26, 5])\n",
            "Value-+torch.Size([1, 26, 10])\n",
            "a_norm torch.Size([1, 26, 26])\n",
            "attention +torch.Size([1, 26, 10])\n",
            "shape after Multihead+torch.Size([1, 26, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 26, 10])\n",
            "End Of Encoder shapetorch.Size([1, 26, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 26, 10])\n",
            "Query-torch.Size([1, 26, 5])\n",
            "Key-torch.Size([1, 26, 5])\n",
            "Value-+torch.Size([1, 26, 10])\n",
            "a_norm torch.Size([1, 26, 26])\n",
            "attention +torch.Size([1, 26, 10])\n",
            "beforeQuery-torch.Size([1, 26, 10])\n",
            "Query-torch.Size([1, 26, 5])\n",
            "Key-torch.Size([1, 26, 5])\n",
            "Value-+torch.Size([1, 26, 10])\n",
            "a_norm torch.Size([1, 26, 26])\n",
            "attention +torch.Size([1, 26, 10])\n",
            "beforeQuery-torch.Size([1, 26, 10])\n",
            "Query-torch.Size([1, 26, 5])\n",
            "Key-torch.Size([1, 26, 5])\n",
            "Value-+torch.Size([1, 26, 10])\n",
            "a_norm torch.Size([1, 26, 26])\n",
            "attention +torch.Size([1, 26, 10])\n",
            "shape after Multihead+torch.Size([1, 26, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 26, 10])\n",
            "End Of Encoder shapetorch.Size([1, 26, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 26, 5])\n",
            "Value-+torch.Size([1, 26, 10])\n",
            "a_norm torch.Size([1, 2, 26])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 26, 5])\n",
            "Value-+torch.Size([1, 26, 10])\n",
            "a_norm torch.Size([1, 2, 26])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 26, 5])\n",
            "Value-+torch.Size([1, 26, 10])\n",
            "a_norm torch.Size([1, 2, 26])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 26, 5])\n",
            "Value-+torch.Size([1, 26, 10])\n",
            "a_norm torch.Size([1, 2, 26])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 26, 5])\n",
            "Value-+torch.Size([1, 26, 10])\n",
            "a_norm torch.Size([1, 2, 26])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 26, 5])\n",
            "Value-+torch.Size([1, 26, 10])\n",
            "a_norm torch.Size([1, 2, 26])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 26, 5])\n",
            "Value-+torch.Size([1, 26, 10])\n",
            "a_norm torch.Size([1, 2, 26])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 26, 5])\n",
            "Value-+torch.Size([1, 26, 10])\n",
            "a_norm torch.Size([1, 2, 26])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 26, 5])\n",
            "Value-+torch.Size([1, 26, 10])\n",
            "a_norm torch.Size([1, 2, 26])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 9.0047e-01,  6.6880e-01, -4.8604e-01,  5.7915e-01,  8.6418e-01,\n",
            "           2.3434e-01,  1.5448e-02,  6.6951e-01,  8.6238e-01,  3.3166e-01],\n",
            "         [ 1.7419e+00,  2.0904e-01, -3.2823e-01,  5.6666e-01,  8.8935e-01,\n",
            "           2.3402e-01,  1.9501e-02,  6.6942e-01,  8.6295e-01,  3.3158e-01],\n",
            "         [ 1.8098e+00, -7.4759e-01, -1.7439e-01,  5.2949e-01,  9.1459e-01,\n",
            "           2.3306e-01,  2.3676e-02,  6.6917e-01,  8.6341e-01,  3.3134e-01],\n",
            "         [ 1.0416e+00, -1.3219e+00, -2.8416e-02,  4.6870e-01,  9.4004e-01,\n",
            "           2.3143e-01,  2.8185e-02,  6.6853e-01,  8.6358e-01,  3.3070e-01],\n",
            "         [ 1.4382e-01, -9.8688e-01,  1.0593e-01,  3.8617e-01,  9.6609e-01,\n",
            "           2.2910e-01,  3.3601e-02,  6.6684e-01,  8.6296e-01,  3.2896e-01],\n",
            "         [-5.8043e-02, -5.3148e-02,  2.2504e-01,  2.8492e-01,  9.9385e-01,\n",
            "           2.2591e-01,  4.1485e-02,  6.6234e-01,  8.6019e-01,  3.2424e-01],\n",
            "         [ 6.2217e-01,  6.1365e-01,  3.2520e-01,  1.7007e-01,  1.0263e+00,\n",
            "           2.2149e-01,  5.6074e-02,  6.5019e-01,  8.5159e-01,  3.1140e-01],\n",
            "         [ 1.5605e+00,  3.8098e-01,  4.0199e-01,  5.1561e-02,  1.0718e+00,\n",
            "           2.1480e-01,  8.8892e-02,  6.1731e-01,  8.2711e-01,  2.7651e-01],\n",
            "         [ 1.8981e+00, -5.9018e-01,  4.4829e-01, -4.8498e-02,  1.1527e+00,\n",
            "           2.0299e-01,  1.7126e-01,  5.2809e-01,  7.5949e-01,  1.8167e-01],\n",
            "         [ 1.3305e+00, -1.4881e+00,  4.5992e-01, -1.1651e-01,  1.2810e+00,\n",
            "           1.8458e-01,  3.1977e-01,  3.6369e-01,  6.3429e-01,  6.8173e-03],\n",
            "         [ 3.8603e-01, -1.5769e+00,  4.4166e-01, -1.6947e-01,  1.4315e+00,\n",
            "           1.6273e-01,  4.9951e-01,  1.6376e-01,  4.8189e-01, -2.0583e-01],\n",
            "         [-5.5102e-02, -9.3735e-01,  3.9071e-01, -1.9399e-01,  1.6157e+00,\n",
            "           1.3600e-01,  7.2624e-01, -8.9590e-02,  2.8858e-01, -4.7533e-01],\n",
            "         [ 4.1873e-01, -2.4111e-01,  3.2584e-01, -2.5384e-01,  1.7520e+00,\n",
            "           1.1468e-01,  8.8665e-01, -2.6757e-01,  1.5301e-01, -6.6458e-01],\n",
            "         [ 1.3790e+00, -2.2588e-01,  2.5410e-01, -3.6745e-01,  1.8138e+00,\n",
            "           1.0214e-01,  9.4346e-01, -3.2782e-01,  1.0764e-01, -7.2851e-01],\n",
            "         [ 1.9499e+00, -1.0025e+00,  1.6776e-01, -4.9695e-01,  1.8421e+00,\n",
            "           9.3195e-02,  9.5394e-01, -3.3543e-01,  1.0261e-01, -7.3638e-01],\n",
            "         [ 1.6097e+00, -1.9005e+00,  6.2225e-02, -6.1421e-01,  1.8668e+00,\n",
            "           8.4095e-02,  9.5960e-01, -3.3757e-01,  1.0177e-01, -7.3843e-01],\n",
            "         [ 6.7163e-01, -2.1008e+00, -6.0797e-02, -7.1286e-01,  1.8919e+00,\n",
            "           7.4330e-02,  9.6611e-01, -3.4071e-01,  1.0019e-01, -7.4151e-01],\n",
            "         [-1.7753e-03, -1.4195e+00, -1.9788e-01, -7.9166e-01,  1.9158e+00,\n",
            "           6.4100e-02,  9.7136e-01, -3.4242e-01,  9.9716e-02, -7.4305e-01],\n",
            "         [ 2.0859e-01, -4.8338e-01, -3.4549e-01, -8.4903e-01,  1.9380e+00,\n",
            "           5.3472e-02,  9.7465e-01, -3.4192e-01,  1.0094e-01, -7.4224e-01],\n",
            "         [ 1.1094e+00, -1.5365e-01, -5.0012e-01, -8.8284e-01,  1.9594e+00,\n",
            "           4.2348e-02,  9.7715e-01, -3.4054e-01,  1.0285e-01, -7.4047e-01],\n",
            "         [ 1.8724e+00, -7.3332e-01, -6.5806e-01, -8.9154e-01,  1.9809e+00,\n",
            "           3.0625e-02,  9.8008e-01, -3.3967e-01,  1.0438e-01, -7.3922e-01],\n",
            "         [ 1.7961e+00, -1.6894e+00, -8.1552e-01, -8.7441e-01,  2.0029e+00,\n",
            "           1.8232e-02,  9.8430e-01, -3.4028e-01,  1.0479e-01, -7.3954e-01],\n",
            "         [ 9.5063e-01, -2.1424e+00, -9.6841e-01, -8.3229e-01,  2.0251e+00,\n",
            "           5.2394e-03,  9.8912e-01, -3.4159e-01,  1.0468e-01, -7.4058e-01],\n",
            "         [ 1.1328e-01, -1.6755e+00, -1.1127e+00, -7.6694e-01,  2.0464e+00,\n",
            "          -8.2362e-03,  9.9334e-01, -3.4224e-01,  1.0509e-01, -7.4089e-01],\n",
            "         [ 5.3866e-02, -7.1769e-01, -1.2448e+00, -6.8030e-01,  2.0667e+00,\n",
            "          -2.2140e-02,  9.9646e-01, -3.4165e-01,  1.0646e-01, -7.3988e-01],\n",
            "         [ 8.2701e-01, -1.4956e-01, -1.3613e+00, -5.7411e-01,  2.0863e+00,\n",
            "          -3.6531e-02,  9.9921e-01, -3.4066e-01,  1.0815e-01, -7.3842e-01],\n",
            "         [ 1.7219e+00, -4.9326e-01, -1.4597e+00, -4.5048e-01,  2.1060e+00,\n",
            "          -5.1485e-02,  1.0025e+00, -3.4034e-01,  1.0933e-01, -7.3766e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 27, 10])\n",
            "Query-torch.Size([1, 27, 5])\n",
            "Key-torch.Size([1, 27, 5])\n",
            "Value-+torch.Size([1, 27, 10])\n",
            "a_norm torch.Size([1, 27, 27])\n",
            "attention +torch.Size([1, 27, 10])\n",
            "beforeQuery-torch.Size([1, 27, 10])\n",
            "Query-torch.Size([1, 27, 5])\n",
            "Key-torch.Size([1, 27, 5])\n",
            "Value-+torch.Size([1, 27, 10])\n",
            "a_norm torch.Size([1, 27, 27])\n",
            "attention +torch.Size([1, 27, 10])\n",
            "beforeQuery-torch.Size([1, 27, 10])\n",
            "Query-torch.Size([1, 27, 5])\n",
            "Key-torch.Size([1, 27, 5])\n",
            "Value-+torch.Size([1, 27, 10])\n",
            "a_norm torch.Size([1, 27, 27])\n",
            "attention +torch.Size([1, 27, 10])\n",
            "shape after Multihead+torch.Size([1, 27, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 27, 10])\n",
            "End Of Encoder shapetorch.Size([1, 27, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 27, 10])\n",
            "Query-torch.Size([1, 27, 5])\n",
            "Key-torch.Size([1, 27, 5])\n",
            "Value-+torch.Size([1, 27, 10])\n",
            "a_norm torch.Size([1, 27, 27])\n",
            "attention +torch.Size([1, 27, 10])\n",
            "beforeQuery-torch.Size([1, 27, 10])\n",
            "Query-torch.Size([1, 27, 5])\n",
            "Key-torch.Size([1, 27, 5])\n",
            "Value-+torch.Size([1, 27, 10])\n",
            "a_norm torch.Size([1, 27, 27])\n",
            "attention +torch.Size([1, 27, 10])\n",
            "beforeQuery-torch.Size([1, 27, 10])\n",
            "Query-torch.Size([1, 27, 5])\n",
            "Key-torch.Size([1, 27, 5])\n",
            "Value-+torch.Size([1, 27, 10])\n",
            "a_norm torch.Size([1, 27, 27])\n",
            "attention +torch.Size([1, 27, 10])\n",
            "shape after Multihead+torch.Size([1, 27, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 27, 10])\n",
            "End Of Encoder shapetorch.Size([1, 27, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 27, 10])\n",
            "Query-torch.Size([1, 27, 5])\n",
            "Key-torch.Size([1, 27, 5])\n",
            "Value-+torch.Size([1, 27, 10])\n",
            "a_norm torch.Size([1, 27, 27])\n",
            "attention +torch.Size([1, 27, 10])\n",
            "beforeQuery-torch.Size([1, 27, 10])\n",
            "Query-torch.Size([1, 27, 5])\n",
            "Key-torch.Size([1, 27, 5])\n",
            "Value-+torch.Size([1, 27, 10])\n",
            "a_norm torch.Size([1, 27, 27])\n",
            "attention +torch.Size([1, 27, 10])\n",
            "beforeQuery-torch.Size([1, 27, 10])\n",
            "Query-torch.Size([1, 27, 5])\n",
            "Key-torch.Size([1, 27, 5])\n",
            "Value-+torch.Size([1, 27, 10])\n",
            "a_norm torch.Size([1, 27, 27])\n",
            "attention +torch.Size([1, 27, 10])\n",
            "shape after Multihead+torch.Size([1, 27, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 27, 10])\n",
            "End Of Encoder shapetorch.Size([1, 27, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 27, 5])\n",
            "Value-+torch.Size([1, 27, 10])\n",
            "a_norm torch.Size([1, 2, 27])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 27, 5])\n",
            "Value-+torch.Size([1, 27, 10])\n",
            "a_norm torch.Size([1, 2, 27])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 27, 5])\n",
            "Value-+torch.Size([1, 27, 10])\n",
            "a_norm torch.Size([1, 2, 27])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 27, 5])\n",
            "Value-+torch.Size([1, 27, 10])\n",
            "a_norm torch.Size([1, 2, 27])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 27, 5])\n",
            "Value-+torch.Size([1, 27, 10])\n",
            "a_norm torch.Size([1, 2, 27])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 27, 5])\n",
            "Value-+torch.Size([1, 27, 10])\n",
            "a_norm torch.Size([1, 2, 27])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 27, 5])\n",
            "Value-+torch.Size([1, 27, 10])\n",
            "a_norm torch.Size([1, 2, 27])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 27, 5])\n",
            "Value-+torch.Size([1, 27, 10])\n",
            "a_norm torch.Size([1, 2, 27])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 27, 5])\n",
            "Value-+torch.Size([1, 27, 10])\n",
            "a_norm torch.Size([1, 2, 27])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "after positional encoding shapetensor([[[ 9.0047e-01,  6.6880e-01, -4.8604e-01,  5.7915e-01,  8.6418e-01,\n",
            "           2.3434e-01,  1.5448e-02,  6.6951e-01,  8.6238e-01,  3.3166e-01],\n",
            "         [ 1.7419e+00,  2.0904e-01, -3.2823e-01,  5.6666e-01,  8.8935e-01,\n",
            "           2.3402e-01,  1.9501e-02,  6.6942e-01,  8.6295e-01,  3.3158e-01],\n",
            "         [ 1.8098e+00, -7.4759e-01, -1.7439e-01,  5.2949e-01,  9.1459e-01,\n",
            "           2.3306e-01,  2.3676e-02,  6.6917e-01,  8.6341e-01,  3.3134e-01],\n",
            "         [ 1.0416e+00, -1.3219e+00, -2.8416e-02,  4.6870e-01,  9.4004e-01,\n",
            "           2.3143e-01,  2.8185e-02,  6.6853e-01,  8.6358e-01,  3.3070e-01],\n",
            "         [ 1.4382e-01, -9.8688e-01,  1.0593e-01,  3.8617e-01,  9.6609e-01,\n",
            "           2.2910e-01,  3.3601e-02,  6.6684e-01,  8.6296e-01,  3.2896e-01],\n",
            "         [-5.8043e-02, -5.3148e-02,  2.2504e-01,  2.8492e-01,  9.9385e-01,\n",
            "           2.2591e-01,  4.1485e-02,  6.6234e-01,  8.6019e-01,  3.2424e-01],\n",
            "         [ 6.2217e-01,  6.1365e-01,  3.2520e-01,  1.7007e-01,  1.0263e+00,\n",
            "           2.2149e-01,  5.6074e-02,  6.5019e-01,  8.5159e-01,  3.1140e-01],\n",
            "         [ 1.5605e+00,  3.8098e-01,  4.0199e-01,  5.1561e-02,  1.0718e+00,\n",
            "           2.1480e-01,  8.8892e-02,  6.1731e-01,  8.2711e-01,  2.7651e-01],\n",
            "         [ 1.8981e+00, -5.9018e-01,  4.4829e-01, -4.8498e-02,  1.1527e+00,\n",
            "           2.0299e-01,  1.7126e-01,  5.2809e-01,  7.5949e-01,  1.8167e-01],\n",
            "         [ 1.3305e+00, -1.4881e+00,  4.5992e-01, -1.1651e-01,  1.2810e+00,\n",
            "           1.8458e-01,  3.1977e-01,  3.6369e-01,  6.3429e-01,  6.8173e-03],\n",
            "         [ 3.8603e-01, -1.5769e+00,  4.4166e-01, -1.6947e-01,  1.4315e+00,\n",
            "           1.6273e-01,  4.9951e-01,  1.6376e-01,  4.8189e-01, -2.0583e-01],\n",
            "         [-5.5102e-02, -9.3735e-01,  3.9071e-01, -1.9399e-01,  1.6157e+00,\n",
            "           1.3600e-01,  7.2624e-01, -8.9590e-02,  2.8858e-01, -4.7533e-01],\n",
            "         [ 4.1873e-01, -2.4111e-01,  3.2584e-01, -2.5384e-01,  1.7520e+00,\n",
            "           1.1468e-01,  8.8665e-01, -2.6757e-01,  1.5301e-01, -6.6458e-01],\n",
            "         [ 1.3790e+00, -2.2588e-01,  2.5410e-01, -3.6745e-01,  1.8138e+00,\n",
            "           1.0214e-01,  9.4346e-01, -3.2782e-01,  1.0764e-01, -7.2851e-01],\n",
            "         [ 1.9499e+00, -1.0025e+00,  1.6776e-01, -4.9695e-01,  1.8421e+00,\n",
            "           9.3195e-02,  9.5394e-01, -3.3543e-01,  1.0261e-01, -7.3638e-01],\n",
            "         [ 1.6097e+00, -1.9005e+00,  6.2225e-02, -6.1421e-01,  1.8668e+00,\n",
            "           8.4095e-02,  9.5960e-01, -3.3757e-01,  1.0177e-01, -7.3843e-01],\n",
            "         [ 6.7163e-01, -2.1008e+00, -6.0797e-02, -7.1286e-01,  1.8919e+00,\n",
            "           7.4330e-02,  9.6611e-01, -3.4071e-01,  1.0019e-01, -7.4151e-01],\n",
            "         [-1.7753e-03, -1.4195e+00, -1.9788e-01, -7.9166e-01,  1.9158e+00,\n",
            "           6.4100e-02,  9.7136e-01, -3.4242e-01,  9.9716e-02, -7.4305e-01],\n",
            "         [ 2.0859e-01, -4.8338e-01, -3.4549e-01, -8.4903e-01,  1.9380e+00,\n",
            "           5.3472e-02,  9.7465e-01, -3.4192e-01,  1.0094e-01, -7.4224e-01],\n",
            "         [ 1.1094e+00, -1.5365e-01, -5.0012e-01, -8.8284e-01,  1.9594e+00,\n",
            "           4.2348e-02,  9.7715e-01, -3.4054e-01,  1.0285e-01, -7.4047e-01],\n",
            "         [ 1.8724e+00, -7.3332e-01, -6.5806e-01, -8.9154e-01,  1.9809e+00,\n",
            "           3.0625e-02,  9.8008e-01, -3.3967e-01,  1.0438e-01, -7.3922e-01],\n",
            "         [ 1.7961e+00, -1.6894e+00, -8.1552e-01, -8.7441e-01,  2.0029e+00,\n",
            "           1.8232e-02,  9.8430e-01, -3.4028e-01,  1.0479e-01, -7.3954e-01],\n",
            "         [ 9.5063e-01, -2.1424e+00, -9.6841e-01, -8.3229e-01,  2.0251e+00,\n",
            "           5.2394e-03,  9.8912e-01, -3.4159e-01,  1.0468e-01, -7.4058e-01],\n",
            "         [ 1.1328e-01, -1.6755e+00, -1.1127e+00, -7.6694e-01,  2.0464e+00,\n",
            "          -8.2362e-03,  9.9334e-01, -3.4224e-01,  1.0509e-01, -7.4089e-01],\n",
            "         [ 5.3866e-02, -7.1769e-01, -1.2448e+00, -6.8030e-01,  2.0667e+00,\n",
            "          -2.2140e-02,  9.9646e-01, -3.4165e-01,  1.0646e-01, -7.3988e-01],\n",
            "         [ 8.2701e-01, -1.4956e-01, -1.3613e+00, -5.7411e-01,  2.0863e+00,\n",
            "          -3.6531e-02,  9.9921e-01, -3.4066e-01,  1.0815e-01, -7.3842e-01],\n",
            "         [ 1.7219e+00, -4.9326e-01, -1.4597e+00, -4.5048e-01,  2.1060e+00,\n",
            "          -5.1485e-02,  1.0025e+00, -3.4034e-01,  1.0933e-01, -7.3766e-01],\n",
            "         [ 1.9157e+00, -1.4325e+00, -1.5373e+00, -3.1235e-01,  2.1260e+00,\n",
            "          -6.7018e-02,  1.0067e+00, -3.4102e-01,  1.0976e-01, -7.3795e-01]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 28, 10])\n",
            "Query-torch.Size([1, 28, 5])\n",
            "Key-torch.Size([1, 28, 5])\n",
            "Value-+torch.Size([1, 28, 10])\n",
            "a_norm torch.Size([1, 28, 28])\n",
            "attention +torch.Size([1, 28, 10])\n",
            "beforeQuery-torch.Size([1, 28, 10])\n",
            "Query-torch.Size([1, 28, 5])\n",
            "Key-torch.Size([1, 28, 5])\n",
            "Value-+torch.Size([1, 28, 10])\n",
            "a_norm torch.Size([1, 28, 28])\n",
            "attention +torch.Size([1, 28, 10])\n",
            "beforeQuery-torch.Size([1, 28, 10])\n",
            "Query-torch.Size([1, 28, 5])\n",
            "Key-torch.Size([1, 28, 5])\n",
            "Value-+torch.Size([1, 28, 10])\n",
            "a_norm torch.Size([1, 28, 28])\n",
            "attention +torch.Size([1, 28, 10])\n",
            "shape after Multihead+torch.Size([1, 28, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 28, 10])\n",
            "End Of Encoder shapetorch.Size([1, 28, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 28, 10])\n",
            "Query-torch.Size([1, 28, 5])\n",
            "Key-torch.Size([1, 28, 5])\n",
            "Value-+torch.Size([1, 28, 10])\n",
            "a_norm torch.Size([1, 28, 28])\n",
            "attention +torch.Size([1, 28, 10])\n",
            "beforeQuery-torch.Size([1, 28, 10])\n",
            "Query-torch.Size([1, 28, 5])\n",
            "Key-torch.Size([1, 28, 5])\n",
            "Value-+torch.Size([1, 28, 10])\n",
            "a_norm torch.Size([1, 28, 28])\n",
            "attention +torch.Size([1, 28, 10])\n",
            "beforeQuery-torch.Size([1, 28, 10])\n",
            "Query-torch.Size([1, 28, 5])\n",
            "Key-torch.Size([1, 28, 5])\n",
            "Value-+torch.Size([1, 28, 10])\n",
            "a_norm torch.Size([1, 28, 28])\n",
            "attention +torch.Size([1, 28, 10])\n",
            "shape after Multihead+torch.Size([1, 28, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 28, 10])\n",
            "End Of Encoder shapetorch.Size([1, 28, 10])\n",
            "---------------ENCODER STARTING-------------------\n",
            "beforeQuery-torch.Size([1, 28, 10])\n",
            "Query-torch.Size([1, 28, 5])\n",
            "Key-torch.Size([1, 28, 5])\n",
            "Value-+torch.Size([1, 28, 10])\n",
            "a_norm torch.Size([1, 28, 28])\n",
            "attention +torch.Size([1, 28, 10])\n",
            "beforeQuery-torch.Size([1, 28, 10])\n",
            "Query-torch.Size([1, 28, 5])\n",
            "Key-torch.Size([1, 28, 5])\n",
            "Value-+torch.Size([1, 28, 10])\n",
            "a_norm torch.Size([1, 28, 28])\n",
            "attention +torch.Size([1, 28, 10])\n",
            "beforeQuery-torch.Size([1, 28, 10])\n",
            "Query-torch.Size([1, 28, 5])\n",
            "Key-torch.Size([1, 28, 5])\n",
            "Value-+torch.Size([1, 28, 10])\n",
            "a_norm torch.Size([1, 28, 28])\n",
            "attention +torch.Size([1, 28, 10])\n",
            "shape after Multihead+torch.Size([1, 28, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 28, 10])\n",
            "End Of Encoder shapetorch.Size([1, 28, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 28, 5])\n",
            "Value-+torch.Size([1, 28, 10])\n",
            "a_norm torch.Size([1, 2, 28])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 28, 5])\n",
            "Value-+torch.Size([1, 28, 10])\n",
            "a_norm torch.Size([1, 2, 28])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 28, 5])\n",
            "Value-+torch.Size([1, 28, 10])\n",
            "a_norm torch.Size([1, 2, 28])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 28, 5])\n",
            "Value-+torch.Size([1, 28, 10])\n",
            "a_norm torch.Size([1, 2, 28])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 28, 5])\n",
            "Value-+torch.Size([1, 28, 10])\n",
            "a_norm torch.Size([1, 2, 28])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 28, 5])\n",
            "Value-+torch.Size([1, 28, 10])\n",
            "a_norm torch.Size([1, 2, 28])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n",
            "---------------DECODER STARTING-------------------\n",
            "Start of decoder shape torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 2, 5])\n",
            "Value-+torch.Size([1, 2, 10])\n",
            "a_norm torch.Size([1, 2, 2])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "Mid decoder shaper after 1st Attention and Normalizationtorch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 28, 5])\n",
            "Value-+torch.Size([1, 28, 10])\n",
            "a_norm torch.Size([1, 2, 28])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 28, 5])\n",
            "Value-+torch.Size([1, 28, 10])\n",
            "a_norm torch.Size([1, 2, 28])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "beforeQuery-torch.Size([1, 2, 10])\n",
            "Query-torch.Size([1, 2, 5])\n",
            "Key-torch.Size([1, 28, 5])\n",
            "Value-+torch.Size([1, 28, 10])\n",
            "a_norm torch.Size([1, 2, 28])\n",
            "attention +torch.Size([1, 2, 10])\n",
            "shape after Multihead+torch.Size([1, 2, 30])\n",
            "shape after  linear layer in Multihead+torch.Size([1, 2, 10])\n",
            "After 2nd Attention Decoder(Mixed Attention)\n",
            "End of decoder shape torch.Size([1, 2, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe3483994a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XR0uLhUbohK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIifhvWLbHqD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}